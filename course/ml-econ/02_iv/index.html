<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="# Remove warnings import warnings warnings.filterwarnings(&#39;ignore&#39;) # Import everything import pandas as pd import numpy as np import seaborn as sns import statsmodels.api as sm from numpy.linalg import inv from statsmodels." />

  
  <link rel="alternate" hreflang="en-us" href="https://matteocourthoud.github.io/course/ml-econ/02_iv/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#003f5c" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.4f7182ca394d705ee32d9d7750e9aa1d.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-144780600-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-144780600-1', { 'anonymize_ip': true });
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://matteocourthoud.github.io/course/ml-econ/02_iv/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Matteo Courthoud" />
  <meta property="og:url" content="https://matteocourthoud.github.io/course/ml-econ/02_iv/" />
  <meta property="og:title" content="Instrumental Variables | Matteo Courthoud" />
  <meta property="og:description" content="# Remove warnings import warnings warnings.filterwarnings(&#39;ignore&#39;) # Import everything import pandas as pd import numpy as np import seaborn as sns import statsmodels.api as sm from numpy.linalg import inv from statsmodels." /><meta property="og:image" content="https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-03-09T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-03-09T00:00:00&#43;00:00">
  

  



  

  
  
  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js" integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css" integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#003f5c",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#003f5c"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "/privacy/"
      }
    })});
  </script>


  





  <title>Instrumental Variables | Matteo Courthoud</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="1d1a4399e0bf93a4fbd939183d1d975f" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.66d3e0fff6d32c4ece05adee927fbd96.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Courses</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/course/ml-econ/"><span>Machine Learning for Economics</span></a>
            
              <a class="dropdown-item" href="/course/data-science/"><span>Data Science with Python</span></a>
            
              <a class="dropdown-item" href="/course/empirical-io/"><span>PhD Industrial Organization</span></a>
            
              <a class="dropdown-item" href="/course/metrics/"><span>PhD Econometrics</span></a>
            
              <a class="dropdown-item" href="https://pp4rs.github.io/"><span>Programming Practices for Research</span></a>
            
          </div>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/cv"><span>CV</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      

      
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      
<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      <ul class="nav docs-sidenav">
        <li><a href="/course/"><i class="fas fa-arrow-left pr-1"></i>Courses</a></li>
      </ul>

      
      
        
          
        
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/course/ml-econ/">ML for Economics</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/course/ml-econ/01_regression/">Linear Regression</a></li>



  <li class="active"><a href="/course/ml-econ/02_iv/">Instrumental Variables</a></li>



  <li class=""><a href="/course/ml-econ/03_nonparametric/">Non-Parametric Regression</a></li>



  <li class=""><a href="/course/ml-econ/04_crossvalidation/">Resampling Methods</a></li>



  <li class=""><a href="/course/ml-econ/05_regularization/">Model Selection and Regularization</a></li>



  <li class=""><a href="/course/ml-econ/06_convexity/">Convexity and Optimization</a></li>



  <li class=""><a href="/course/ml-econ/07_trees/">Tree-based Methods</a></li>



  <li class=""><a href="/course/ml-econ/08_neuralnets/">Neural Networks</a></li>



  <li class=""><a href="/course/ml-econ/09_postdoubleselection/">Post-Double Selection</a></li>



  <li class=""><a href="/course/ml-econ/10_unsupervised/">Unsupervised Learning</a></li>

      
        </ul>
      
    

    
      </div>
    

    
  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#21-simple-linear-regression">2.1 Simple Linear Regression</a></li>
    <li><a href="#22-extending-the-linear-regression-model">2.2 Extending the Linear Regression Model</a></li>
    <li><a href="#23-endogeneity">2.3 Endogeneity</a>
      <ul>
        <li><a href="#first-stage">First stage</a></li>
        <li><a href="#second-stage">Second stage</a></li>
      </ul>
    </li>
    <li><a href="#24-matrix-algebra">2.4 Matrix Algebra</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">

          <h1>Instrumental Variables</h1>

          <p>Last updated on Mar 9, 2022</p>

          <div class="article-style">
            <pre><code class="language-python"># Remove warnings
import warnings
warnings.filterwarnings('ignore')
</code></pre>
<pre><code class="language-python"># Import everything
import pandas as pd
import numpy as np
import seaborn as sns
import statsmodels.api as sm

from numpy.linalg import inv
from statsmodels.iolib.summary2 import summary_col
from linearmodels.iv import IV2SLS
</code></pre>
<pre><code class="language-python"># Import matplotlib for graphs
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import axes3d

# Set global parameters
%matplotlib inline
plt.style.use('seaborn-white')
plt.rcParams['lines.linewidth'] = 3
plt.rcParams['figure.figsize'] = (10,6)
plt.rcParams['figure.titlesize'] = 20
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['legend.fontsize'] = 14
</code></pre>
<h2 id="21-simple-linear-regression">2.1 Simple Linear Regression</h2>
<p>In <a href="https://economics.mit.edu/files/4123" target="_blank" rel="noopener">Acemoglu, Johnson, Robinson (2002), &ldquo;<em>The Colonial Origins of Comparative Development</em>&rdquo;</a> the authors wish to determine whether or not differences in institutions can help to explain observed economic outcomes.</p>
<p>How do we measure <em>institutional differences</em> and <em>economic outcomes</em>?</p>
<p>In this paper,</p>
<ul>
<li>economic outcomes are proxied by log GDP per capita in 1995, adjusted for exchange rates.</li>
<li>institutional differences are proxied by an index of protection against expropriation on average over 1985-95, constructed by the <a href="https://www.prsgroup.com/" target="_blank" rel="noopener">Political Risk Services Group</a>.</li>
</ul>
<p>These variables and other data used in the paper are available for download on Daron Acemoglu’s <a href="https://economics.mit.edu/faculty/acemoglu/data/ajr2001" target="_blank" rel="noopener">webpage</a>.</p>
<p>The original dataset in in Stata <code>.dta</code> format but has been converted to <code>.csv</code>.</p>
<p>First, let&rsquo;s load the data and have a look at it.</p>
<pre><code class="language-python"># Load Acemoglu Johnson Robinson Dataset
df = pd.read_csv('data/AJR02.csv',index_col=0)
df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GDP</th>
      <th>Exprop</th>
      <th>Mort</th>
      <th>Latitude</th>
      <th>Neo</th>
      <th>Africa</th>
      <th>Asia</th>
      <th>Namer</th>
      <th>Samer</th>
      <th>logMort</th>
      <th>Latitude2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>8.39</td>
      <td>6.50</td>
      <td>78.20</td>
      <td>0.3111</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4.359270</td>
      <td>0.096783</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.77</td>
      <td>5.36</td>
      <td>280.00</td>
      <td>0.1367</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>5.634790</td>
      <td>0.018687</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.13</td>
      <td>6.39</td>
      <td>68.90</td>
      <td>0.3778</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>4.232656</td>
      <td>0.142733</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.90</td>
      <td>9.32</td>
      <td>8.55</td>
      <td>0.3000</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2.145931</td>
      <td>0.090000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>9.29</td>
      <td>7.50</td>
      <td>85.00</td>
      <td>0.2683</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>4.442651</td>
      <td>0.071985</td>
    </tr>
  </tbody>
</table>
</div>
<p>Let’s use a scatterplot to see whether any obvious relationship exists between GDP per capita and the protection against expropriation.</p>
<pre><code class="language-python"># Plot relationship between GDP and expropriation rate
fig, ax = plt.subplots(1,1)
ax.set_title('Figure 1: joint distribution of GDP and expropriation')
df.plot(x='Exprop', y='GDP', kind='scatter', s=50, ax=ax);
</code></pre>
<p><img src="../img/02_iv_9_0.png" alt="png"></p>
<p>The plot shows a fairly strong positive relationship between
protection against expropriation and log GDP per capita.</p>
<p>Specifically, if higher protection against expropriation is a measure of
institutional quality, then better institutions appear to be positively
correlated with better economic outcomes (higher GDP per capita).</p>
<p>Given the plot, choosing a linear model to describe this relationship
seems like a reasonable assumption.</p>
<p>We can write our model as</p>
<p>$$
{GDP}_i = \beta_0 + \beta_1 {Exprop}_i + \varepsilon_i
$$</p>
<p>where:</p>
<ul>
<li>$ \beta_0 $ is the intercept of the linear trend line on the
y-axis</li>
<li>$ \beta_1 $ is the slope of the linear trend line, representing
the <em>marginal effect</em> of protection against risk on log GDP per
capita</li>
<li>$ \varepsilon_i $ is a random error term (deviations of observations from
the linear trend due to factors not included in the model)</li>
</ul>
<p>The most common technique to estimate the parameters ($ \beta $’s)
of the linear model is Ordinary Least Squares (OLS).</p>
<p>As the name implies, an OLS model is solved by finding the parameters
that minimize <em>the sum of squared residuals</em>, i.e.</p>
<p>$$
\underset{\hat{\beta}}{\min} \sum^N_{i=1}{\hat{u}^2_i}
$$</p>
<p>where $ \hat{u}_i $ is the difference between the observation and
the predicted value of the dependent variable.</p>
<p>To estimate the constant term $ \beta_0 $, we need to add a column
of 1’s to our dataset (consider the equation if $ \beta_0 $ was
replaced with $ \beta_0 x_i $ and $ x_i = 1 $)</p>
<p>Now we can construct our model in <code>statsmodels</code> using the OLS function.</p>
<p>We will use <code>pandas</code> dataframes with <code>statsmodels</code>, however standard arrays can also be used as arguments</p>
<pre><code class="language-python"># Regress GDP on Expropriation Rate
reg1 = sm.OLS.from_formula('GDP ~ Exprop', df)
type(reg1)
</code></pre>
<pre><code>statsmodels.regression.linear_model.OLS
</code></pre>
<p>So far we have simply constructed our model.</p>
<p>We need to use <code>.fit()</code> to obtain parameter estimates
$ \hat{\beta}_0 $ and $ \hat{\beta}_1 $</p>
<pre><code class="language-python"># Fit regression
results = reg1.fit()
type(results)
</code></pre>
<pre><code>statsmodels.regression.linear_model.RegressionResultsWrapper
</code></pre>
<p>We now have the fitted regression model stored in <code>results</code>.</p>
<p>To view the OLS regression results, we can call the <code>.summary()</code>
method.</p>
<p>Note that an observation was mistakenly dropped from the results in the
original paper (see the note located in maketable2.do from Acemoglu’s webpage), and thus the
coefficients differ slightly.</p>
<pre><code class="language-python">results.summary()
</code></pre>
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>GDP</td>       <th>  R-squared:         </th> <td>   0.540</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.532</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   72.71</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 03 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>4.84e-12</td>
</tr>
<tr>
  <th>Time:</th>                 <td>18:31:09</td>     <th>  Log-Likelihood:    </th> <td> -68.214</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    64</td>      <th>  AIC:               </th> <td>   140.4</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    62</td>      <th>  BIC:               </th> <td>   144.7</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    4.6609</td> <td>    0.409</td> <td>   11.402</td> <td> 0.000</td> <td>    3.844</td> <td>    5.478</td>
</tr>
<tr>
  <th>Exprop</th>    <td>    0.5220</td> <td>    0.061</td> <td>    8.527</td> <td> 0.000</td> <td>    0.400</td> <td>    0.644</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 7.134</td> <th>  Durbin-Watson:     </th> <td>   2.081</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.028</td> <th>  Jarque-Bera (JB):  </th> <td>   6.698</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.784</td> <th>  Prob(JB):          </th> <td>  0.0351</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.234</td> <th>  Cond. No.          </th> <td>    31.2</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
<p>From our results, we see that</p>
<ul>
<li>The intercept $ \hat{\beta}_0 = 4.63 $.</li>
<li>The slope $ \hat{\beta}_1 = 0.53 $.</li>
<li>The positive $ \hat{\beta}_1 $ parameter estimate implies that.
institutional quality has a positive effect on economic outcomes, as
we saw in the figure.</li>
<li>The p-value of 0.000 for $ \hat{\beta}_1 $ implies that the
effect of institutions on GDP is statistically significant (using p &lt;
0.05 as a rejection rule).</li>
<li>The R-squared value of 0.611 indicates that around 61% of variation
in log GDP per capita is explained by protection against
expropriation.</li>
</ul>
<p>Using our parameter estimates, we can now write our estimated
relationship as</p>
<p>$$
\widehat{GDP}_i = 4.63 + 0.53 \ {Exprop}_i
$$</p>
<p>This equation describes the line that best fits our data, as shown in
Figure 2.</p>
<p>We can use this equation to predict the level of log GDP per capita for
a value of the index of expropriation protection.</p>
<p>For example, for a country with an index value of 6.51 (the average for
the dataset), we find that their predicted level of log GDP per capita
in 1995 is 8.09.</p>
<pre><code class="language-python">mean_expr = np.mean(df['Exprop'])
mean_expr
</code></pre>
<pre><code>6.5160937500000005
</code></pre>
<pre><code class="language-python">predicted_logpdp95 = results.params[0] + results.params[1] * mean_expr
predicted_logpdp95
</code></pre>
<pre><code>8.062499999999995
</code></pre>
<p>An easier (and more accurate) way to obtain this result is to use
<code>.predict()</code> and set $ constant = 1 $ and
$ {Exprop}_i = mean_expr $</p>
<pre><code class="language-python">results.predict(exog=[1, mean_expr])
</code></pre>
<p>We can obtain an array of predicted $ {GDP}_i $ for every value
of $ {Exprop}_i $ in our dataset by calling <code>.predict()</code> on our
results.</p>
<p>Plotting the predicted values against $ {Exprop}_i $ shows that the
predicted values lie along the linear line that we fitted above.</p>
<p>The observed values of $ {GDP}_i $ are also plotted for
comparison purposes</p>
<pre><code class="language-python"># Make first new figure
def make_new_fig_2():

    # Init figure
    fig, ax = plt.subplots(1,1)
    ax.set_title('Figure 2: OLS predicted values')

    # Drop missing observations from whole sample
    df_plot = df.dropna(subset=['GDP', 'Exprop'])
    sns.regplot(x=df_plot['Exprop'], y=df_plot['GDP'], ax=ax, order=1, ci=None, line_kws={'color':'r'})

    ax.legend(['predicted', 'observed'])
    ax.set_xlabel('Exprop')
    ax.set_ylabel('GDP')
    plt.show()
</code></pre>
<pre><code class="language-python">make_new_fig_2()
</code></pre>
<pre><code>ERROR! Session/line number was not unique in database. History logging moved to new session 305
</code></pre>
<p><img src="../img/02_iv_28_1.png" alt="png"></p>
<h2 id="22-extending-the-linear-regression-model">2.2 Extending the Linear Regression Model</h2>
<p>So far we have only accounted for institutions affecting economic performance - almost certainly there are numerous other factors affecting GDP that are not included in our model.</p>
<p>Leaving out variables that affect $ GDP_i $ will result in <strong>omitted variable bias</strong>, yielding biased and inconsistent parameter estimates.</p>
<p>We can extend our bivariate regression model to a <strong>multivariate regression model</strong> by adding in other factors that may affect $ GDP_i $.</p>
<p><a href="https://python-programming.quantecon.org/zreferences.html#acemoglu2001" target="_blank" rel="noopener">[AJR01]</a> consider other factors such as:</p>
<ul>
<li>the effect of climate on economic outcomes; latitude is used to proxy
this</li>
<li>differences that affect both economic performance and institutions,
eg. cultural, historical, etc.; controlled for with the use of
continent dummies</li>
</ul>
<p>Let’s estimate some of the extended models considered in the paper
(Table 2) using data from <code>maketable2.dta</code></p>
<pre><code class="language-python"># Add constant term to dataset
df['const'] = 1

# Create lists of variables to be used in each regression
X1 = df[['const', 'Exprop']]
X2 = df[['const', 'Exprop', 'Latitude', 'Latitude2']]
X3 = df[['const', 'Exprop', 'Latitude', 'Latitude2', 'Asia', 'Africa', 'Namer', 'Samer']]

# Estimate an OLS regression for each set of variables
reg1 = sm.OLS(df['GDP'], X1, missing='drop').fit()
reg2 = sm.OLS(df['GDP'], X2, missing='drop').fit()
reg3 = sm.OLS(df['GDP'], X3, missing='drop').fit()
</code></pre>
<p>Now that we have fitted our model, we will use <code>summary_col</code> to
display the results in a single table (model numbers correspond to those
in the paper)</p>
<pre><code class="language-python">info_dict={'No. observations' : lambda x: f&quot;{int(x.nobs):d}&quot;}

results_table = summary_col(results=[reg1,reg2,reg3],
                            float_format='%0.2f',
                            stars = True,
                            model_names=['Model 1','Model 2','Model 3'],
                            info_dict=info_dict,
                            regressor_order=['const','Exprop','Latitude','Latitude2'])

results_table
</code></pre>
<table class="simpletable">
<tr>
          <td></td>         <th>Model 1</th> <th>Model 2</th> <th>Model 3</th>
</tr>
<tr>
  <th>const</th>            <td>4.66***</td> <td>4.55***</td> <td>5.95***</td>
</tr>
<tr>
  <th></th>                 <td>(0.41)</td>  <td>(0.45)</td>  <td>(0.68)</td> 
</tr>
<tr>
  <th>Exprop</th>           <td>0.52***</td> <td>0.49***</td> <td>0.40***</td>
</tr>
<tr>
  <th></th>                 <td>(0.06)</td>  <td>(0.07)</td>  <td>(0.06)</td> 
</tr>
<tr>
  <th>Latitude</th>            <td></td>      <td>2.16</td>    <td>0.42</td>  
</tr>
<tr>
  <th></th>                    <td></td>     <td>(1.68)</td>  <td>(1.47)</td> 
</tr>
<tr>
  <th>Latitude2</th>           <td></td>      <td>-2.12</td>   <td>0.44</td>  
</tr>
<tr>
  <th></th>                    <td></td>     <td>(2.86)</td>  <td>(2.48)</td> 
</tr>
<tr>
  <th>Africa</th>              <td></td>        <td></td>     <td>-1.06**</td>
</tr>
<tr>
  <th></th>                    <td></td>        <td></td>     <td>(0.41)</td> 
</tr>
<tr>
  <th>Asia</th>                <td></td>        <td></td>     <td>-0.74*</td> 
</tr>
<tr>
  <th></th>                    <td></td>        <td></td>     <td>(0.42)</td> 
</tr>
<tr>
  <th>Namer</th>               <td></td>        <td></td>      <td>-0.17</td> 
</tr>
<tr>
  <th></th>                    <td></td>        <td></td>     <td>(0.40)</td> 
</tr>
<tr>
  <th>Samer</th>               <td></td>        <td></td>      <td>-0.12</td> 
</tr>
<tr>
  <th></th>                    <td></td>        <td></td>     <td>(0.42)</td> 
</tr>
<tr>
  <th>No. observations</th>   <td>64</td>      <td>64</td>      <td>64</td>   
</tr>
</table>
<h2 id="23-endogeneity">2.3 Endogeneity</h2>
<p>As <a href="https://python-programming.quantecon.org/zreferences.html#acemoglu2001" target="_blank" rel="noopener">[AJR01]</a> discuss, the OLS models likely suffer from <strong>endogeneity</strong> issues, resulting in biased and inconsistent model estimates.</p>
<p>Namely, there is likely a two-way relationship between institutions an economic outcomes:</p>
<ul>
<li>richer countries may be able to afford or prefer better institutions</li>
<li>variables that affect income may also be correlated with institutional differences</li>
<li>the construction of the index may be biased; analysts may be biased towards seeing countries with higher income having better institutions</li>
</ul>
<p>To deal with endogeneity, we can use <strong>two-stage least squares (2SLS) regression</strong>, which is an extension of OLS regression.</p>
<p>This method requires replacing the endogenous variable $ {Exprop}_i $ with a variable that is:</p>
<ol>
<li>correlated with $ {Exprop}_i $</li>
<li>not correlated with the error term (ie. it should not directly affect the dependent variable, otherwise it would be correlated with $ u_i $ due to omitted variable bias)</li>
</ol>
<p>We can write our model as</p>
<p>$$
{GDP}_i = \beta_0 + \beta_1 {Exprop}_i + \varepsilon_i \
{Exprop}_i = \delta_0 + \delta_1 {logMort}_i + v_i
$$</p>
<p>The new set of regressors <code>logMort</code> is called an <strong>instrument</strong>, which aims to remove endogeneity in our proxy of institutional differences.</p>
<p>The main contribution of <a href="https://python-programming.quantecon.org/zreferences.html#acemoglu2001" target="_blank" rel="noopener">[AJR01]</a> is the use of settler mortality rates to instrument for institutional differences.</p>
<p>They hypothesize that higher mortality rates of colonizers led to the establishment of institutions that were more extractive in nature (less protection against expropriation), and these institutions still persist today.</p>
<p>Using a scatterplot (Figure 3 in <a href="https://python-programming.quantecon.org/zreferences.html#acemoglu2001" target="_blank" rel="noopener">[AJR01]</a>), we can see protection against expropriation is negatively correlated with settler mortality rates, coinciding with the authors’ hypothesis and satisfying the first condition of a valid instrument.</p>
<pre><code class="language-python"># Dropping NA's is required to use numpy's polyfit
df2 = df.dropna(subset=['logMort', 'Exprop'])
X = df2['logMort']
y = df2['Exprop']
</code></pre>
<pre><code class="language-python"># Make new figure 2
def make_new_figure_2():

    # Init figure
    fig, ax = plt.subplots(1,1)
    ax.set_title('Figure 3: First-stage')

    # Fit a linear trend line
    sns.regplot(x=X, y=y, ax=ax, order=1, scatter=True, ci=None, line_kws={&quot;color&quot;: &quot;r&quot;})

    ax.set_xlim([1.8,8.4])
    ax.set_ylim([3.3,10.4])
    ax.set_xlabel('Log of Settler Mortality')
    ax.set_ylabel('Average Expropriation Risk 1985-95');
</code></pre>
<pre><code class="language-python">make_new_figure_2()
</code></pre>
<p><img src="../img/02_iv_43_0.png" alt="png"></p>
<p>The second condition may not be satisfied if settler mortality rates in the 17th to 19th centuries have a direct effect on current GDP (in addition to their indirect effect through institutions).</p>
<p>For example, settler mortality rates may be related to the current disease environment in a country, which could affect current economic performance.</p>
<p><a href="https://python-programming.quantecon.org/zreferences.html#acemoglu2001" target="_blank" rel="noopener">[AJR01]</a> argue this is unlikely because:</p>
<ul>
<li>The majority of settler deaths were due to malaria and yellow fever
and had a limited effect on local people.</li>
<li>The disease burden on local people in Africa or India, for example,
did not appear to be higher than average, supported by relatively
high population densities in these areas before colonization.</li>
</ul>
<p>As we appear to have a valid instrument, we can use 2SLS regression to
obtain consistent and unbiased parameter estimates.</p>
<h3 id="first-stage">First stage</h3>
<p>The first stage involves regressing the endogenous variable
($ {Exprop}_i $) on the instrument.</p>
<p>The instrument is the set of all exogenous variables in our model (and
not just the variable we have replaced).</p>
<p>Using model 1 as an example, our instrument is simply a constant and
settler mortality rates $ {logMort}_i $.</p>
<p>Therefore, we will estimate the first-stage regression as</p>
<p>$$
{Exprop}_i = \delta_0 + \delta_1 {logMort}_i + v_i
$$</p>
<pre><code class="language-python"># Add a constant variable
df['const'] = 1

# Fit the first stage regression and print summary
results_fs = sm.OLS(df['Exprop'],
                    df.loc[:,['const', 'logMort']],
                    missing='drop').fit()
results_fs.summary()
</code></pre>
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>Exprop</td>      <th>  R-squared:         </th> <td>   0.274</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.262</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   23.34</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 03 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>9.27e-06</td>
</tr>
<tr>
  <th>Time:</th>                 <td>18:31:10</td>     <th>  Log-Likelihood:    </th> <td> -104.69</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    64</td>      <th>  AIC:               </th> <td>   213.4</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    62</td>      <th>  BIC:               </th> <td>   217.7</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>   <td>    9.3659</td> <td>    0.611</td> <td>   15.339</td> <td> 0.000</td> <td>    8.145</td> <td>   10.586</td>
</tr>
<tr>
  <th>logMort</th> <td>   -0.6133</td> <td>    0.127</td> <td>   -4.831</td> <td> 0.000</td> <td>   -0.867</td> <td>   -0.360</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.047</td> <th>  Durbin-Watson:     </th> <td>   1.592</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.977</td> <th>  Jarque-Bera (JB):  </th> <td>   0.154</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.060</td> <th>  Prob(JB):          </th> <td>   0.926</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.792</td> <th>  Cond. No.          </th> <td>    19.4</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
<p>We need to retrieve the predicted values of $ {Exprop}_i $ using
<code>.predict()</code>.</p>
<p>We then replace the endogenous variable $ {Exprop}_i $ with the
predicted values $ \widehat{Exprop}_i $ in the original linear model.</p>
<p>Our second stage regression is thus</p>
<p>$$
{GDP}_i = \beta_0 + \beta_1 \widehat{Exprop}_i + u_i
$$</p>
<h3 id="second-stage">Second stage</h3>
<pre><code class="language-python"># Second stage
df['predicted_Exprop'] = results_fs.predict()
results_ss = sm.OLS.from_formula('GDP ~ predicted_Exprop', df).fit()

# Print
results_ss.summary()
</code></pre>
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>GDP</td>       <th>  R-squared:         </th> <td>   0.462</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.453</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   53.24</td>
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 03 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>6.58e-10</td>
</tr>
<tr>
  <th>Time:</th>                 <td>18:31:10</td>     <th>  Log-Likelihood:    </th> <td> -73.208</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    64</td>      <th>  AIC:               </th> <td>   150.4</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    62</td>      <th>  BIC:               </th> <td>   154.7</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>        <td>    2.0448</td> <td>    0.830</td> <td>    2.463</td> <td> 0.017</td> <td>    0.385</td> <td>    3.705</td>
</tr>
<tr>
  <th>predicted_Exprop</th> <td>    0.9235</td> <td>    0.127</td> <td>    7.297</td> <td> 0.000</td> <td>    0.671</td> <td>    1.177</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>10.463</td> <th>  Durbin-Watson:     </th> <td>   2.052</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.005</td> <th>  Jarque-Bera (JB):  </th> <td>  10.693</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.806</td> <th>  Prob(JB):          </th> <td> 0.00476</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.188</td> <th>  Cond. No.          </th> <td>    57.8</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
<p>The second-stage regression results give us an unbiased and consistent
estimate of the effect of institutions on economic outcomes.</p>
<p>The result suggests a stronger positive relationship than what the OLS
results indicated.</p>
<p>Note that while our parameter estimates are correct, our standard errors
are not and for this reason, computing 2SLS ‘manually’ (in stages with
OLS) is not recommended.</p>
<p>We can correctly estimate a 2SLS regression in one step using the
<a href="https://github.com/bashtage/linearmodels" target="_blank" rel="noopener">linearmodels</a> package, an extension of <code>statsmodels</code></p>
<p>Note that when using <code>IV2SLS</code>, the exogenous and instrument variables
are split up in the function arguments (whereas before the instrument
included exogenous variables)</p>
<pre><code class="language-python"># IV regression
iv = IV2SLS(dependent=df['GDP'],
            exog=df['const'],
            endog=df['Exprop'],
            instruments=df['logMort']).fit()

# Print
iv.summary
</code></pre>
<table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>           <td>GDP</td>       <th>  R-squared:         </th> <td>0.2205</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.2079</td> 
</tr>
<tr>
  <th>No. Observations:</th>        <td>64</td>        <th>  F-statistic:       </th> <td>29.811</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, Jan 03 2022</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>18:31:10</td>     <th>  Distribution:      </th> <td>chi2(1)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
     <td></td>    <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>const</th>   <td>2.0448</td>    <td>1.1273</td>   <td>1.8139</td> <td>0.0697</td>   <td>-0.1647</td>  <td>4.2542</td> 
</tr>
<tr>
  <th>Exprop</th>  <td>0.9235</td>    <td>0.1691</td>   <td>5.4599</td> <td>0.0000</td>   <td>0.5920</td>   <td>1.2550</td> 
</tr>
</table><br/><br/>Endogenous: Exprop<br/>Instruments: logMort<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False
<p>Given that we now have consistent and unbiased estimates, we can infer
from the model we have estimated that institutional differences
(stemming from institutions set up during colonization) can help
to explain differences in income levels across countries today.</p>
<p><a href="https://python-programming.quantecon.org/zreferences.html#acemoglu2001" target="_blank" rel="noopener">[AJR01]</a> use a marginal effect of 0.94 to calculate that the
difference in the index between Chile and Nigeria (ie. institutional
quality) implies up to a 7-fold difference in income, emphasizing the
significance of institutions in economic development.</p>
<h2 id="24-matrix-algebra">2.4 Matrix Algebra</h2>
<p>The OLS parameter $ \beta $ can also be estimated using matrix
algebra and <code>numpy</code>.</p>
<p>The linear equation we want to estimate is (written in matrix form)</p>
<p>$$
y = X\beta + \varepsilon
$$</p>
<pre><code class="language-python"># Init 
X = df[['const', 'Exprop']].values
Z = df[['const', 'logMort']].values
y = df['GDP'].values
</code></pre>
<p>To solve for the unknown parameter $ \beta $, we want to minimize
the sum of squared residuals</p>
<p>$$
\underset{\hat{\beta}}{\min} \ \hat{\varepsilon}&rsquo;\hat{\varepsilon}
$$</p>
<p>Rearranging the first equation and substituting into the second
equation, we can write</p>
<p>$$
\underset{\hat{\beta}}{\min} \ (Y - X\hat{\beta})&rsquo; (Y - X\hat{\beta})
$$</p>
<p>Solving this optimization problem gives the solution for the
$ \hat{\beta} $ coefficients</p>
<p>$$
\hat{\beta} = (X&rsquo;X)^{-1}X&rsquo;y
$$</p>
<pre><code class="language-python"># Compute beta OLS
beta_OLS = inv(X.T @ X) @ X.T @ y

print(beta_OLS)
</code></pre>
<pre><code>[4.66087966 0.52203367]
</code></pre>
<p>As we as see above, the OLS coefficient might suffer from endogeneity bias. We can solve the issue by instrumenting the predicted average expropriation rate with the average settler mortality.</p>
<p>If we define settler mortality as $Z$, our full model is</p>
<p>$$
y = X\beta + \varepsilon \
X = Z\gamma + \mu
$$</p>
<p>Where we refer to the second equation as second stage and to the first equation as the reduced form equation. In our case, since the number of endogenous varaibles is equal to the number of insturments, there are two equivalent estimators that do not suffer from endogeneity bias: 2SLS and IV.</p>
<p>IV, the one stage estimator</p>
<p>$$
\hat \beta_{IV} = (Z&rsquo;X)^{-1} Z&rsquo; y
$$</p>
<pre><code class="language-python"># Compute beta IV
beta_IV = inv(Z.T @ X) @ Z.T @ y

print(beta_IV)
</code></pre>
<pre><code>[2.0447613  0.92351936]
</code></pre>
<p>One of the hypothesis behind the IV estimator is the <em>relevance</em> of the instrument, i.e. we have a strong predictor in the first stage. This is the only hypothesis that we can empirically assess by checking the significance of the first stage coefficient.</p>
<p>$$
\hat \gamma = (Z&rsquo; Z)^{-1} Z&rsquo;X \
\hat Var (\hat \gamma) = \sigma_u^2 (Z&rsquo; Z)^{-1}
$$</p>
<p>where</p>
<p>$$
u = X - Z \hat \gamma
$$</p>
<pre><code class="language-python"># Estimate first stage coefficient
gamma_hat = (inv(Z.T @ Z) @ Z.T @ X)

print(gamma_hat[1,1])
</code></pre>
<pre><code>-0.613289272386864
</code></pre>
<pre><code class="language-python"># Compute variance of the estimator
u = X - Z @ gamma_hat
var_gamma_hat = np.var(u) * inv(Z.T @ Z)

# Compute standard errors
std_gamma_hat = var_gamma_hat[1,1]**.5
print(std_gamma_hat)
</code></pre>
<pre><code>0.08834733362858548
</code></pre>
<pre><code class="language-python"># Compute 95% confidence interval
CI = [gamma_hat[1,1] - 1.96*std_gamma_hat, gamma_hat[1,1] + 1.96*std_gamma_hat]

print(CI)
</code></pre>
<pre><code>[-0.7864500462988916, -0.4401284984748365]
</code></pre>
<p>The first stage coefficient is negative and significant, i.e. settler mortality is negatively correlated with the expropriation rate.</p>
<p>How does it work when we have more instruments than endogenous variables? Two-State Least Squares.</p>
<ol>
<li>Regress $X$ on $Z$ and obtain $\hat X$:
$$
\hat X = Z (Z&rsquo; Z)^{-1} Z&rsquo;X
$$</li>
<li>Regress $Y$ on $\hat X$ and obtain $\hat \beta_{2SLS}$
$$
\hat \beta_{2SLS} = (\hat X&rsquo; \hat X)^{-1} \hat X&rsquo; y
$$</li>
</ol>
<p>In our case, just for the sake of exposition, let&rsquo;s generate a second instrument: the settler mortality squared, <code>logMort_2</code> = <code>logMort</code>^2.</p>
<pre><code class="language-python">df['logMort_2'] = df['logMort']**2
</code></pre>
<pre><code class="language-python"># Define Z
Z1 = df[['const', 'logMort', 'logMort_2']].values

# Compute beta 2SLS in two steps
X_hat = Z1 @ inv(Z1.T @ Z1) @ Z1.T @ X
beta_2SLS = inv(X_hat.T @ X_hat) @ X_hat.T @ y

print(beta_2SLS)
</code></pre>
<pre><code>[3.08817432 0.76339075]
</code></pre>
<p>The 2SLS estimator does not have to be actually estimated in two stages. Combining the two formulas above, we get</p>
<p>$$
\hat{\beta} _ {2SLS} =  \Big( X&rsquo;Z (Z&rsquo;Z)^{-1} Z&rsquo;X \Big)^{-1} \Big( X&rsquo;Z (Z&rsquo;Z)^{-1} Z&rsquo;y \Big)
$$</p>
<p>which can be computed in one step.</p>
<pre><code class="language-python"># Compute beta 2SLS in one step
beta_2SLS = inv(X_hat.T @ Z1 @ inv(Z1.T @ Z1) @ Z1.T @ X_hat) @ X_hat.T @ Z1 @ inv(Z1.T @ Z1) @ Z1.T @ y
    
print(beta_2SLS)
</code></pre>
<pre><code>[3.08817432 0.76339075]
</code></pre>

          </div>

          



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/course/ml-econ/01_regression/" rel="next">Linear Regression</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/course/ml-econ/03_nonparametric/" rel="prev">Non-Parametric Regression</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">

          





          




          


  
  



        </div>

      </article>

      <footer class="site-footer">

  

  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  

  
  







</footer>


    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/julia.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.4ea9cc8d09c5c158656ac1a804743b34.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
