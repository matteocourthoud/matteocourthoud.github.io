<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="# Remove warnings import warnings warnings.filterwarnings(&#39;ignore&#39;)  # Import import pandas as pd import numpy as np import seaborn as sns import time from numpy.linalg import inv from numpy.random import normal from sklearn." />

  
  <link rel="alternate" hreflang="en-us" href="https://matteocourthoud.github.io/course/ml-econ/04_crossvalidation/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#003f5c" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.5c4def4f00a521426f4eb098155f3342.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-144780600-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-144780600-1', { 'anonymize_ip': true });
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://matteocourthoud.github.io/course/ml-econ/04_crossvalidation/" />

  
  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Matteo Courthoud" />
  <meta property="og:url" content="https://matteocourthoud.github.io/course/ml-econ/04_crossvalidation/" />
  <meta property="og:title" content="Resampling Methods | Matteo Courthoud" />
  <meta property="og:description" content="# Remove warnings import warnings warnings.filterwarnings(&#39;ignore&#39;)  # Import import pandas as pd import numpy as np import seaborn as sns import time from numpy.linalg import inv from numpy.random import normal from sklearn." /><meta property="og:image" content="https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-03-09T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-03-09T00:00:00&#43;00:00">
  

  



  

  
  
  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js" integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css" integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#003f5c",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#003f5c"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "/privacy/"
      }
    })});
  </script>


  





  <title>Resampling Methods | Matteo Courthoud</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="55557b8d76a9ab6ec9e78a74df31ab53" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.6edaf3b475ce43de30d98828aea698be.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Courses</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/course/ml-econ/"><span>Machine Learning for Economics</span></a>
            
              <a class="dropdown-item" href="/course/data-science/"><span>Data Science with Python</span></a>
            
              <a class="dropdown-item" href="/course/empirical-io/"><span>PhD Industrial Organization</span></a>
            
              <a class="dropdown-item" href="/course/metrics/"><span>PhD Econometrics</span></a>
            
              <a class="dropdown-item" href="https://pp4rs.github.io/"><span>Programming Practices for Research</span></a>
            
          </div>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/post/"><span>Posts</span></a>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/cv"><span>CV</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      

      
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      
<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      <ul class="nav docs-sidenav">
        <li><a href="/course/"><i class="fas fa-arrow-left pr-1"></i>Courses</a></li>
      </ul>

      
      
        
          
        
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/course/ml-econ/">ML for Economics</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/course/ml-econ/01_regression/">Linear Regression</a></li>



  <li class=""><a href="/course/ml-econ/02_iv/">Instrumental Variables</a></li>



  <li class=""><a href="/course/ml-econ/03_nonparametric/">Non-Parametric Regression</a></li>



  <li class="active"><a href="/course/ml-econ/04_crossvalidation/">Resampling Methods</a></li>



  <li class=""><a href="/course/ml-econ/05_regularization/">Model Selection and Regularization</a></li>



  <li class=""><a href="/course/ml-econ/06_convexity/">Convexity and Optimization</a></li>



  <li class=""><a href="/course/ml-econ/07_trees/">Tree-based Methods</a></li>



  <li class=""><a href="/course/ml-econ/08_neuralnets/">Neural Networks</a></li>



  <li class=""><a href="/course/ml-econ/09_postdoubleselection/">Post-Double Selection</a></li>



  <li class=""><a href="/course/ml-econ/10_unsupervised/">Unsupervised Learning</a></li>

      
        </ul>
      
    

    
      </div>
    

    
  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#41-cross-validation">4.1 Cross-Validation</a>
      <ul>
        <li><a href="#the-validation-set-approach">The Validation Set Approach</a></li>
        <li><a href="#leave-one-out-cross-validation">Leave-One-Out Cross-Validation</a></li>
        <li><a href="#k-fold-cross-validation">k-Fold Cross-Validation</a></li>
      </ul>
    </li>
    <li><a href="#42-the-bootstrap">4.2 The Bootstrap</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">

          <h1>Resampling Methods</h1>

          <p>Last updated on Mar 9, 2022</p>

          <div class="article-style">
            <pre><code class="language-python"># Remove warnings
import warnings
warnings.filterwarnings('ignore')
</code></pre>
<pre><code class="language-python"># Import
import pandas as pd
import numpy as np
import seaborn as sns
import time

from numpy.linalg import inv
from numpy.random import normal
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score
from sklearn.preprocessing import PolynomialFeatures
from sklearn.utils import resample
</code></pre>
<pre><code class="language-python"># Import matplotlib for graphs
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import axes3d

# Set global parameters
%matplotlib inline
plt.style.use('seaborn-white')
plt.rcParams['lines.linewidth'] = 3
plt.rcParams['figure.figsize'] = (10,6)
plt.rcParams['figure.titlesize'] = 20
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['legend.fontsize'] = 14
</code></pre>
<p>Resampling methods involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model.</p>
<h2 id="41-cross-validation">4.1 Cross-Validation</h2>
<p>Cross-validation can be used to estimate the test error associated with a given statistical learning method in order to evaluate its performance, or to select the appropriate level of flexibility. The process of evaluating a model’s performance is known as <strong>model assessment</strong>, whereas the process of selecting the proper level of flexibility for a model is known as <strong>model selection</strong>.</p>
<p>Let&rsquo;s use the <code>auto</code> dataset we have used for nonparametric models.</p>
<pre><code class="language-python"># Load car dataset
df1 = pd.read_csv('data/Auto.csv', na_values='?').dropna()
df1.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cylinders</th>
      <th>displacement</th>
      <th>horsepower</th>
      <th>weight</th>
      <th>acceleration</th>
      <th>year</th>
      <th>origin</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18.0</td>
      <td>8</td>
      <td>307.0</td>
      <td>130</td>
      <td>3504</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>chevrolet chevelle malibu</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15.0</td>
      <td>8</td>
      <td>350.0</td>
      <td>165</td>
      <td>3693</td>
      <td>11.5</td>
      <td>70</td>
      <td>1</td>
      <td>buick skylark 320</td>
    </tr>
    <tr>
      <th>2</th>
      <td>18.0</td>
      <td>8</td>
      <td>318.0</td>
      <td>150</td>
      <td>3436</td>
      <td>11.0</td>
      <td>70</td>
      <td>1</td>
      <td>plymouth satellite</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16.0</td>
      <td>8</td>
      <td>304.0</td>
      <td>150</td>
      <td>3433</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>amc rebel sst</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.0</td>
      <td>8</td>
      <td>302.0</td>
      <td>140</td>
      <td>3449</td>
      <td>10.5</td>
      <td>70</td>
      <td>1</td>
      <td>ford torino</td>
    </tr>
  </tbody>
</table>
</div>
<h3 id="the-validation-set-approach">The Validation Set Approach</h3>
<p>Suppose that we would like to estimate the test error associated with fitting a particular statistical learning method on a set of observations. The validation set approach is a very simple strategy for this task. It involves randomly dividing the available set of observations into two parts</p>
<ol>
<li>a <strong>training set</strong> and</li>
<li>a <strong>validation set</strong> or hold-out set</li>
</ol>
<p>The model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set. The resulting validation set error rate-typically assessed using MSE in the case of a quantitative response—provides an estimate of the test error rate.</p>
<p>In the following example we are are going to compute the MSE fit polynomial of different order (one to ten). We are going to split the data 50-50 across training and test set.</p>
<pre><code class="language-python"># Cross-validation function for polynomials
def cv_poly(X, y, p_order, r_states, t_prop):
    start = time.time()
    
    # Init scores
    scores = np.zeros((p_order.size,r_states.size))
    
    # Generate 10 random splits of the dataset
    for j in r_states:
        
        # Split sample in train and test
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_prop, random_state=j)
        
            
        # For every polynomial degree
        for i in p_order:

            # Generate polynomial
            X_train_poly = PolynomialFeatures(i+1).fit_transform(X_train)
            X_test_poly = PolynomialFeatures(i+1).fit_transform(X_test)

            # Fit regression                                                                    
            ols = LinearRegression().fit(X_train_poly, y_train)
            pred = ols.predict(X_test_poly)
            scores[i,j]= mean_squared_error(y_test, pred)
    print('Time elapsed: %.4f seconds' % (time.time()-start))
    return scores
</code></pre>
<pre><code class="language-python"># Init
t_prop = 0.5
p_order = np.arange(10)
r_states = np.arange(10)

# Get X,y 
X = df1.horsepower.values.reshape(-1,1)
y = df1.mpg.ravel()

# Compute scores
cv_scores = cv_poly(X, y, p_order, r_states, t_prop)
</code></pre>
<pre><code>Time elapsed: 0.0277 seconds
</code></pre>
<p>Let&rsquo;s test the score for polynomials of different orders.</p>
<pre><code class="language-python"># Figure 5.2
def make_figure_5_2():
    
    # Init
    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,6))
    fig.suptitle('Figure 5.2')

    # Left plot (first split)
    ax1.plot(p_order+1,cv_scores[:,0], '-o')
    ax1.set_title('Random split of the data set')

    # Right plot (all splits)
    ax2.plot(p_order+1,cv_scores)
    ax2.set_title('10 random splits of the data set')

    for ax in fig.axes:
        ax.set_ylabel('Mean Squared Error')
        ax.set_ylim(15,30)
        ax.set_xlabel('Degree of Polynomial')
        ax.set_xlim(0.5,10.5)
        ax.set_xticks(range(2,11,2));
</code></pre>
<pre><code class="language-python">make_figure_5_2()
</code></pre>
<p><img src="../img/04_crossvalidation_15_0.png" alt="png"></p>
<p>This figure illustrates a <strong>first drawback</strong> of the validation approach: the estimate of the test error rate can be highly variable, depending on precisely which observations are included in the training set and which observations are included in the validation set.</p>
<p>The <strong>second drawback</strong> of the validation approach is that only a subset of the observations—those that are included in the training set rather than in the validation set—are used to fit the model. Since statistical methods tend to per- form worse when trained on fewer observations, this suggests that the validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set.</p>
<h3 id="leave-one-out-cross-validation">Leave-One-Out Cross-Validation</h3>
<p>Leave-one-out cross-validation (LOOCV) attempts to address that method’s drawbacks.</p>
<p>Like the validation set approach, LOOCV involves splitting the set of observations into two parts. However, instead of creating two subsets of comparable size, a single observation $i$ is used for the validation set, and the remaining $n-1$ observations make up the training set. The statistical learning method is fit on the $n−1$ training observations and the MSE is computed using the excluded observation $i$. The procedure is repeated $n$ times, for $i=1,&hellip;,n$.</p>
<p>The LOOCV estimate for the test MSE is the average of these $n$ test error estimates:</p>
<p>$$
\mathrm{CV}<em>{(n)}=\frac{1}{n} \sum</em>{i=1}^{n} \mathrm{MSE}_{i}
$$</p>
<p>LOOCV has a couple of major <strong>advantages</strong> over the validation set approach.</p>
<p>First, it has far less bias. In LOOCV, we repeatedly fit the statistical learning method using training sets that contain $n − 1$ observations, almost as many as are in the entire data set. However, this also means that LOOCV is more computationally intense.</p>
<p>Second, in contrast to the validation approach which will yield different results when applied repeatedly due to randomness in the training/validation set splits, performing LOOCV multiple times will always yield the same results: there is no randomness in the training/validation set splits.</p>
<pre><code class="language-python"># LeaveOneOut CV function for polynomials
def loo_cv_poly(X, y, p_order):
    start = time.time()
    
    # Init
    loo = LeaveOneOut().get_n_splits(y)
    loo_scores = np.zeros((p_order.size,1))
    
    # For every polynomial degree
    for i in p_order:
        # Generate polynomial
        X_poly = PolynomialFeatures(i+1).fit_transform(X)

        # Get score
        loo_scores[i] = cross_val_score(LinearRegression(), X_poly, y, cv=loo, scoring='neg_mean_squared_error').mean()
        
    print('Time elapsed: %.4f seconds' % (time.time()-start))
    return loo_scores
</code></pre>
<p>Let&rsquo;s compare the validation set approach against LOO in terms of computational time.</p>
<pre><code class="language-python"># Validation set approach
cv_scores = cv_poly(X, y, p_order, r_states, t_prop)
    
# Leave One Out CV
loo_scores = loo_cv_poly(X, y, p_order)
</code></pre>
<pre><code>Time elapsed: 0.0270 seconds
Time elapsed: 1.1495 seconds
</code></pre>
<p>As expected, LOOCV is much more computationally intense. Even accounting for the fact that we repeat every the validation set approach 10 times.</p>
<p>Let&rsquo;s now compare them in terms of accuracy in minimizing the MSE.</p>
<pre><code class="language-python"># Make new figure 1
def make_new_figure_1():

    # Init
    fig, ax = plt.subplots(1,1, figsize=(7,6))

    # Left plot
    ax.plot(p_order+1, np.array(loo_scores)*-1, '-o', label='LOOCV')
    ax.plot(p_order+1, np.mean(cv_scores, axis=1), '-o', c='orange', label='Standard CV')
    ax.set_ylabel('Mean Squared Error'); ax.set_xlabel('Degree of Polynomial');
    ax.set_ylim(15,30); ax.set_xlim(0.5,10.5);
    ax.set_xticks(range(2,11,2));
    ax.legend();
</code></pre>
<pre><code class="language-python">make_new_figure_1()
</code></pre>
<p><img src="../img/04_crossvalidation_26_0.png" alt="png"></p>
<p>With least squares linear or polynomial regression, an amazing shortcut makes the cost of LOOCV the same as that of a single model fit! The following formula holds:</p>
<p>$$
\mathrm{CV}<em>{(n)}=\frac{1}{n} \sum</em>{i=1}^{n}\left(\frac{y_{i}-\hat{y}<em>{i}}{1-h</em>{i}}\right)^{2}
$$</p>
<p>where $\hat y_i$ is the $i^{th}$ fitted value from the original least squares fit, and $h_i$ is the leverage of observation $i$.</p>
<h3 id="k-fold-cross-validation">k-Fold Cross-Validation</h3>
<p>An alternative to LOOCV is k-fold CV. This approach involves the following steps:</p>
<ol>
<li>Randomly dividing the set of observations into $k$ groups, or folds, of approximately equal size.</li>
<li>The first fold is treated as a validation set, and the method is fit on the remaining $k − 1$ folds.</li>
<li>The mean squared error, MSE1, is then computed on the observations in the held-out fold.</li>
<li>Steps (1)-(3) are repeated $k$ times; each time, a different group of observations is treated as a validation set.</li>
</ol>
<p>The k-fold CV estimate is computed by averaging these values</p>
<p>$$
\mathrm{CV}<em>{(k)}=\frac{1}{k} \sum</em>{i=1}^{k} \mathrm{MSE}_{i}
$$</p>
<p>LOOCV is a special case of k-fold CV in which $k$ is set to equal $n$. In practice, one typically performs k-fold CV using $k = 5$ or $k = 10$.</p>
<p>The most obvious <strong>advantage</strong> is computational. LOOCV requires fitting the statistical learning method $n$ times, while k-fold CV only requires $k$ splits.</p>
<pre><code class="language-python"># 10fold CV function for polynomials
def k10_cv_poly(X, y, p_order, r_states, folds):
    start = time.time()
    
    # Init
    k10_scores = np.zeros((p_order.size,r_states.size))

    # Generate 10 random splits of the dataset
    for j in r_states:

        # For every polynomial degree
        for i in p_order:

            # Generate polynomial
            X_poly = PolynomialFeatures(i+1).fit_transform(X)

            # Split sample in train and test
            kf10 = KFold(n_splits=folds, shuffle=True, random_state=j)
            k10_scores[i,j] = cross_val_score(LinearRegression(), X_poly, y, cv=kf10, 
                                               scoring='neg_mean_squared_error').mean()  
    
    print('Time elapsed: %.4f seconds' % (time.time()-start))
    return k10_scores
</code></pre>
<p>Let&rsquo;s now compare 10 fold cross-validation with LOO in terms of computational time.</p>
<pre><code class="language-python"># Leave One Out CV
loo_scores = loo_cv_poly(X, y, p_order)
    
# 10-fold CV
folds = 10
k10_scores = k10_cv_poly(X, y, p_order, r_states, folds)
</code></pre>
<pre><code>Time elapsed: 1.1153 seconds
Time elapsed: 0.3078 seconds
</code></pre>
<p>Indeed we see that the LOOCV approach is more computationally intense. Even accounting for the fact that we repeat every 10-fold cross-validation 10 times.</p>
<p>We can now compare all the methods in terms of accuracy.</p>
<pre><code class="language-python"># Figure 5.4
def make_figure_5_4():

    fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(17,5))
    fig.suptitle('Figure 5.4')

    # Left plot
    ax1.plot(p_order+1, np.array(loo_scores)*-1, '-o')
    ax1.set_title('LOOCV', fontsize=12)

    # Center plot
    ax2.plot(p_order+1,k10_scores*-1)
    ax2.set_title('10-fold CV', fontsize=12)

    # Right plot
    ax3.plot(p_order+1, np.array(loo_scores)*-1, '-o', label='LOOCV')
    ax3.plot(p_order+1, np.mean(cv_scores, axis=1), label='Standard CV')
    ax3.plot(p_order+1,np.mean(k10_scores,axis=1)*-1, label='10-fold CV')
    ax3.set_title('Comparison', fontsize=12);
    ax3.legend();

    for ax in fig.axes:
        ax.set_ylabel('Mean Squared Error')
        ax.set_ylim(15,30)
        ax.set_xlabel('Degree of Polynomial')
        ax.set_xlim(0.5,10.5)
        ax.set_xticks(range(2,11,2));
</code></pre>
<pre><code class="language-python">make_figure_5_4()
</code></pre>
<p><img src="../img/04_crossvalidation_37_0.png" alt="png"></p>
<p>10-fold cross-validation outputs a very similar MSE with respect to LOOCV, but with considerably less computational time.</p>
<h2 id="42-the-bootstrap">4.2 The Bootstrap</h2>
<p>The bootstrap is a widely applicable and extremely powerful statistical tool that can be used to <strong>quantify the uncertainty</strong> associated with a given estimator or statistical learning method. In the specific case of linear regression, this is not particularly useful since there exist a formula for the standard errors. However, there are many models (almost all actually) for which there exists no closed for solution to the estimator variance.</p>
<p>In pricinple, we would like to draw independent samples from the true data generating process and assessing the uncertainty of an estimator by comparing its values across the different samples. However, this is clearly unfeasible since we do not know the true data generating process.</p>
<p>With the bootstrap, rather than repeatedly obtaining independent data sets from the population, we instead obtain distinct data sets by repeatedly sampling observations from the original data set. The power of the bootstrap lies in the fact that it can be easily applied to a wide range of statistical learning methods, including some for which a measure of variability is otherwise difficult to obtain and is not automatically output by statistical software.</p>
<p>We are now going to assess its usefulness through simulation. Take the following model:</p>
<p>$$
y_i = \beta_0 \cdot x_i + \varepsilon_i
$$</p>
<p>where $\beta_0 = 0.6$ and $\varepsilon \sim N(0,1)$. We are now going to assess the variance of the OLS estimator $\hat \beta$ with the standard formula, simulating different samples and with bootstrap.</p>
<pre><code class="language-python"># Set seed
np.random.seed(1)

# Init
simulations = 1000
N = 1000
beta_0 = 0.6
beta_sim = np.zeros((simulations,1))

# Generate X
X = normal(0,3,N).reshape(-1,1)

# Loop over simulations
for i in range(simulations):
    
    # Generate y
    e = normal(0,1,N).reshape(-1,1)
    y = beta_0*X + e
    
    # Estimate beta OLS
    beta_sim[i] = inv(X.T @ X) @ X.T @ y
</code></pre>
<pre><code class="language-python"># Init Bootstrap
beta_boot = np.zeros((simulations,1))

# Loop over simulations
for i in range(simulations):
    
    # Sample y
    X_sample, y_sample = resample(X, y, random_state=i)
    
    # Estimate beta OLS
    beta_boot[i] = inv(X_sample.T @ X_sample) @ X_sample.T @ y_sample
</code></pre>
<p>We can first compare the means.</p>
<pre><code class="language-python"># Print means
print('True value      : %.4f' % beta_0)
print('Mean Simulations: %.4f' % np.mean(beta_sim))
print('Mean One Sample : %.4f' % beta_sim[-1])
print('Mean Boostrap   : %.4f' % np.mean(beta_boot))
</code></pre>
<pre><code>True value      : 0.6000
Mean Simulations: 0.6003
Mean One Sample : 0.5815
Mean Boostrap   : 0.5816
</code></pre>
<p>The mean of the bootstrap estimtor is quite off. But this is not its actual purpose: it is designed to assess the uncertainty of an estimator, not its value.</p>
<p>Now we compare the variances.</p>
<pre><code class="language-python"># Print variances
print('True std       : %.6f' % np.sqrt(inv(X.T @ X)))
print('Std Simulations: %.6f' % np.std(beta_sim))
print('Std One Sample : %.6f' % np.sqrt(inv(X.T @ X) * np.var(y - beta_sim[-1]*X)))
print('Std Boostrap   : %.6f' % np.std(beta_boot))
</code></pre>
<pre><code>True std       : 0.010737
Std Simulations: 0.010830
Std One Sample : 0.010536
Std Boostrap   : 0.010812
</code></pre>
<p>Bootstrap gets as close to the true standard deviation of the estimator as the simulation with the true data generating process. Impressive!</p>
<p>We can now have a visual inspection.</p>
<pre><code class="language-python"># Figure 5.10
def make_figure_5_10():

    fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(14,6))
    fig.suptitle('Figure 5.10')

    # Left plot
    ax1.hist(beta_sim, bins=10, edgecolor='black');
    ax1.axvline(x=beta_0, color='r', label='beta_0')
    ax1.set_xlabel('beta simulated');

    # Center plot
    ax2.hist(beta_boot, bins=10, color='orange', edgecolor='black');
    ax2.axvline(x=beta_0, color='r', label='beta_0')
    ax2.set_xlabel('beta bootstrap');

    # Right plot
    df_bootstrap = pd.DataFrame({'simulated': beta_sim.ravel(), 'bootstrap':beta_boot.ravel()}, 
                                index=range(simulations))
    ax3 = sns.boxplot(data=df_bootstrap, width=0.5, linewidth=2);
    ax3.axhline(y=beta_0, color='r', label='beta_0');
</code></pre>
<pre><code class="language-python">make_figure_5_10()
</code></pre>
<p><img src="../img/04_crossvalidation_52_0.png" alt="png"></p>
<p>As we can see, the bootstrap is a powerful tool to assess the uncertainty of an estimator.</p>

          </div>

          



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/course/ml-econ/03_nonparametric/" rel="next">Non-Parametric Regression</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/course/ml-econ/05_regularization/" rel="prev">Model Selection and Regularization</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">

          





          




          


  
  



        </div>

      </article>

      <footer class="site-footer">

  

  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  

  
  







</footer>


    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/julia.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.cf8ca859a9b74f8b1cd804621b13e5f1.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
