<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PhD Industrial Organization | Matteo Courthoud</title>
    <link>https://matteocourthoud.github.io/course/empirical-io/</link>
      <atom:link href="https://matteocourthoud.github.io/course/empirical-io/index.xml" rel="self" type="application/rss+xml" />
    <description>PhD Industrial Organization</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Theme edited by Matteo Courthoud© - Want to have a similar website? [Guide here](https://matteocourthoud.github.io/post/website/).</copyright><lastBuildDate>Wed, 10 Nov 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_512x512_fill_lanczos_center_3.png</url>
      <title>PhD Industrial Organization</title>
      <link>https://matteocourthoud.github.io/course/empirical-io/</link>
    </image>
    
    <item>
      <title>Demand Estimation</title>
      <link>https://matteocourthoud.github.io/course/empirical-io/02_demand_estimation/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/course/empirical-io/02_demand_estimation/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;setting&#34;&gt;Setting&lt;/h3&gt;
&lt;p&gt;Oligopoly Supply&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;firms produce differentiated goods/products&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;selling to consumers with heterogeneous preferences&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;static model, complete information&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;products are given&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;equilibrium: NE for each product/market&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h3&gt;
&lt;p&gt;Variable cost of product $j$:
$C_j (Q_j , w_{jt} , \mathbb \omega_{jt}, \gamma)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$Q_j$: total quantity of good $j$ sold&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$w_{jt}$ observable cost shifters; may include product
characteristics $x_{jt}$ that will affect demand (later)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\omega_{jt}$ unobserved cost shifters (“cost shocks”); may be
correlated with latent demand shocks (later)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\gamma$: parameters&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;for multi-product firms, we’ll assume variable cost additive across
products for simplicity&lt;/li&gt;
&lt;li&gt;we ignore fixed costs: these affect entry/exit/innovation but not
pricing, &lt;em&gt;conditional on these things&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;notation&#34;&gt;Notation&lt;/h3&gt;
&lt;p&gt;Some other variables&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$J_t$: products/goods/choices in market $t$ (for now $J_t = J$)&lt;/li&gt;
&lt;li&gt;$P_t = (p_{1t},&amp;hellip;,p_{Jt})$: prices of all goods&lt;/li&gt;
&lt;li&gt;$\boldsymbol X_t = ( \boldsymbol x_{1t} , … , \boldsymbol x_{Jt})$ :
other characteristics of goods affecting demand (observed and
unobserved to us)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In general&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I use &lt;strong&gt;bold&lt;/strong&gt; for arrays in dimensions that are not $i$
(consumers), $j$ (firms) or $t$ (markets)
&lt;ul&gt;
&lt;li&gt;For example product characteristics
$\boldsymbol x_{jt} = \lbrace x_{jt}^1,, &amp;hellip;, x_{jt}^K \rbrace$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;I use CAPS for variables aggregated over $j$ (firms)
&lt;ul&gt;
&lt;li&gt;For example vector of prices in market $t$:
$P_t = (p_{1t},&amp;hellip;,p_{Jt})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;equilibrium-pricing&#34;&gt;Equilibrium Pricing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Demand system:&lt;/p&gt;
&lt;p&gt;$$
q_{jt} = Q_j ( P_t, \boldsymbol X_t) \quad \text{for} \quad j = 1,&amp;hellip;,J.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Profit function&lt;/p&gt;
&lt;p&gt;$$
\pi_{jt} = Q_j (P_t, \boldsymbol X_t) \Big[p_{jt} − mc_j (w_{jt}, \omega_{jt}, \gamma) \Big]
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;FOC wrt to $p_{jt}$:&lt;/p&gt;
&lt;p&gt;$$
p_{jt} = mc_{jt} - Q_j (P_t, \boldsymbol X_t) \left(\frac{\partial Q_j}{\partial p_{jt}}\right)^{-1}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inverse elasticity pricing (i.e., monopoly pricing) against the
“residual demand curve” $Q_j (P_t, \boldsymbol X_t)$:&lt;/p&gt;
&lt;p&gt;$$
\frac{p_{jt} - mc_{jt}}{p_{jt}} = - \frac{Q_j (P_t, \boldsymbol X_t)}{p_{jt}} \left(\frac{\partial Q_j}{\partial p_{jt}}\right)^{-1}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-do-we-get&#34;&gt;What do we get?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Holding all else fixed, markups/prices depend on the own-price
elasticities of residual demand. Equilibrium depends, further, on
how a change in price of one good affects the quantities sold of
others, i.e., on cross-price demand elasticities&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we known demand, we can also perform a &lt;strong&gt;small miracle&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Re-arrange FOC&lt;/p&gt;
&lt;p&gt;$$
mc_{jt} = p_{jt} + Q_j (P_t, \boldsymbol X_t)\left(\frac{\partial Q_j}{\partial p_{jt}}\right)^{-1}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Supply model + estimated demand $\to$ estimates of marginal
costs!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we know demand and marginal costs, we can”predict” a lot of
stuff - i.e., give the quantitative implications of the model for
counterfactual worlds&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;issues&#34;&gt;Issues&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Typically we need to know levels/elasticities of demand at
particular points; i.e., effects of one price change holding all
else fixed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The main challenge: unobserved demand shifters (“demand shocks”) at
the level of the good×market (e.g., unobserved product char or
market-specific variation in mean tastes for products)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;demand shocks are among the things that must be held fixed to
measure the relevant demand elasticities etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;explicit modeling of these demand shocks central in the applied IO
literature following S. Berry, Levinsohn, and Pakes
(&lt;a href=&#34;#ref-berry1995automobile&#34;&gt;1995&lt;/a&gt;) (often ignored outside this
literature).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;key-challenge&#34;&gt;Key Challenge&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;demand&lt;/strong&gt; of product $j$&lt;/p&gt;
&lt;p&gt;$$
q_{jt} (\boldsymbol X_{t}, P_t, \Xi_t)
$$&lt;/p&gt;
&lt;p&gt;depends on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$P_t$: $J$-vector of &lt;em&gt;all&lt;/em&gt; goods’ prices in market $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\boldsymbol X_t$: $J \times k$ matrix of &lt;em&gt;all&lt;/em&gt; non-price
observables in market $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\Xi_t$: J-vector of demand shocks for &lt;em&gt;all&lt;/em&gt; goods in market $t$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Key insight&lt;/strong&gt;: we have an endogeneity problem even if prices were
exogenous!&lt;/p&gt;
&lt;h3 id=&#34;price-endogeneity-adds-to-the-challenge&#34;&gt;Price Endogeneity Adds to the Challenge&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;all $J$ endogenous prices are on RHS of demand for each good&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;equilibrium pricing implies that each price depends on all demand
shocks and all cost shocks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;prices endogenous&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;control function generally is not a valid solution&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;clear that we need sources of exogenous price variation, but&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;what exactly is required?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;how do we proceed?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;blp-model&#34;&gt;BLP: Model&lt;/h2&gt;
&lt;h3 id=&#34;goals-of-blp&#34;&gt;Goals of BLP&lt;/h3&gt;
&lt;p&gt;Model of S. Berry, Levinsohn, and Pakes
(&lt;a href=&#34;#ref-berry1995automobile&#34;&gt;1995&lt;/a&gt;)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;parsimonious specification to generate the distribution
$F_U (\cdot| P, \Xi)$ of random utilities&lt;/li&gt;
&lt;li&gt;sufficiently rich heterogeneity in preferences to permit
reasonable/flexible substitution patterns&lt;/li&gt;
&lt;li&gt;be explicit about unobservables, including the nature of endogeneity
“problem(s)”&lt;/li&gt;
&lt;li&gt;use the model to reveal solutions to the identification problem,
including appropriate instruments&lt;/li&gt;
&lt;li&gt;computationally feasible (in early 1990s!) algorithm for consistent
estimation of the model and standard errors.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;utility-specification&#34;&gt;Utility Specification&lt;/h3&gt;
&lt;p&gt;Utility of consumer $i$ for product $j$&lt;/p&gt;
&lt;p&gt;$$
u_{ijt} = \boldsymbol x_{jt} \boldsymbol \beta_{it} - \alpha p_{jt} + \xi_{jt} + \epsilon_{ijt}
$$&lt;/p&gt;
&lt;p&gt;Where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\boldsymbol x_{jt}$: $K$-vector of characteristics of product $j$
in market $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\boldsymbol \beta_{it} = (\beta_{it}^{1}, &amp;hellip;, \beta_{it}^K)$:
vector of tastes for characteristics $1,…,K$ in market $t$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\beta_{it}^k = \beta_0^k + \sigma_k \zeta_{it}^k$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\beta_0^k$: fixed taste for characteristic $k$ (the usual
$\beta$)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\zeta_{it}^k$: random taste, i.i.d. across consumers and
markets $t$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\alpha$: price elasticity&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$p_{jt}$ price of product $j$ in market $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\xi_{jt}$: unobservable product shock at the level of products $j$
$\times$ market $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\epsilon_{ijt}$: idiosyncratic (and latent) taste&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;exogenous-and-endogenous-product-characteristics&#34;&gt;Exogenous and Endogenous Product Characteristics&lt;/h3&gt;
&lt;p&gt;Utility of consumer $i$ for product $j$&lt;/p&gt;
&lt;p&gt;$$
u_{ijt} = \boldsymbol x_{jt} \beta_{it} - \alpha p_{jt} + \xi_{jt} + \epsilon_{ijt}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;exogenous characteristics: $\boldsymbol x_{jt} \perp \xi_{jt}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;endogenous characteristics: $p_{jt}$ (usually a scalar, price)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;typically each $p_{jt}$ will depend on whole vector
$\Xi_t = (\xi_{1t} , . . . , \xi_{Jt} )$
&lt;ul&gt;
&lt;li&gt;and on own costs $mc_{jt}$ and others’ costs $mc_{-jt}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;we need to distinguish true effects of prices on demand from the&lt;/li&gt;
&lt;li&gt;effects of $\Xi_t$ ; this will require &lt;strong&gt;instruments&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;of course the equation above is not an estimating equation
($u_{ijt}$ not observed)&lt;/li&gt;
&lt;li&gt;because prices and quantities are all endogenous - indeed
determined - simultaneously, you may suspect (correctly) that
instruments for prices alone may not suffice.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;utility-specification-rewritten&#34;&gt;Utility Specification, Rewritten&lt;/h3&gt;
&lt;p&gt;Rewrite&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
u_{ijt} &amp;amp;= \boldsymbol x_{jt} \boldsymbol \beta_{it} - \alpha p_{jt} + \xi_{jt} + \epsilon_{ijt} = \newline
&amp;amp;= \delta_{jt} + \nu_{ijt}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\delta_{jt} = \boldsymbol x_{jt} \boldsymbol \beta_0 - \alpha p_{jt} + \xi_{jt}$
&lt;ul&gt;
&lt;li&gt;mean utility of good $j$ in market $t$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\nu_{ijt} = \sum_{k} x_{jt}^{k} \sigma^{k} \zeta_{i t}^{k} + \epsilon_{ijt} \equiv \boldsymbol x_{jt} \tilde{\boldsymbol \beta}&lt;em&gt;{it} + \epsilon&lt;/em&gt;{ijt}$
&lt;ul&gt;
&lt;li&gt;We split $\beta_{it}$ into its &lt;strong&gt;random&lt;/strong&gt; ($\tilde{\beta}_{it}$)
and &lt;strong&gt;non-random&lt;/strong&gt; ($\beta_0$) part&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;from-consumer-utility-to-demand&#34;&gt;From Consumer Utility to Demand&lt;/h3&gt;
&lt;p&gt;With a &lt;strong&gt;continuum of consumers in each market&lt;/strong&gt;: market shares = choice
probabilities&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P.S. continuum not needed, enough that sampling error on choice
probs negligible compared to that of moments based on variation
across products/markets&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
s_{jt} (\Delta_t, \boldsymbol X_t, \boldsymbol \sigma) = \Pr (y_{it} = j) = \int_{\mathcal A_j (\Delta_t)} \text d F_{\nu} \Big(\nu_{i0t}, \nu_{i1t}, &amp;hellip; , \nu_{iJt} \ \Big| \ \boldsymbol X_t, \boldsymbol \sigma \Big)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;where $$
\mathcal A_j(\Delta_t) = \Big\lbrace (\nu_{i0t}, \nu_{i1t}, &amp;hellip; , \nu_{iJt} ) \in \mathbb{R}^{J+1}: \delta_{jt} + \nu_{ijt} \geq \delta_{kt} + \nu_{ikt} \ , \ \forall k \Big\rbrace
$$ &lt;strong&gt;In words&lt;/strong&gt;: market share of firm $j$ is the frequency of
consumers buying good $j$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Demand&lt;/strong&gt; is just shares $s_{jt}$ per market size $M_t$ $$
q_{jt} = M_t \times s_j (\Delta_t, \boldsymbol X_t, \boldsymbol \sigma)
$$&lt;/p&gt;
&lt;h3 id=&#34;why-random-coefficients&#34;&gt;Why Random Coefficients?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Without&lt;/strong&gt; random coefficients $$
\begin{aligned}
u_{ijt} &amp;amp;= \underbrace{\boldsymbol x_{jt} \boldsymbol \beta_0 - \alpha p_{jt} + \xi_{jt}} + \epsilon_{ijt} \newline
&amp;amp;= \hspace{3.4em} \delta_{jt} \hspace{3.4em} + \epsilon_{ijt}
\end{aligned}
$$ If $\epsilon_{ijt}$ are iid and independent of
$(\boldsymbol X_t, P_t)$, e.g. as in the multinomial logit or probit
models,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;products differ only in mean utilities $\delta_{jt}$&lt;/li&gt;
&lt;li&gt;$\to$ market shares depend only on the mean utilities&lt;/li&gt;
&lt;li&gt;$\to$ price elasticities (own and cross) depend only on mean
utilities too&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Implication&lt;/strong&gt;: two products with the same market shares have the same
cross elasticities w.r.t. &lt;strong&gt;all&lt;/strong&gt; other products&lt;/p&gt;
&lt;h3 id=&#34;does-this-matter&#34;&gt;Does this matter?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Yes&lt;/strong&gt;!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Mercedes class-A&lt;/em&gt; and &lt;em&gt;Fiat Panda&lt;/em&gt; might both have low market
shares&lt;/li&gt;
&lt;li&gt;But realistically should have very different cross-price
elasticities w.r.t. &lt;em&gt;BMW series-2&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What is the issue?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Models (like MNL) that have only &lt;strong&gt;iid additive taste shocks&lt;/strong&gt;
impose very &lt;strong&gt;restrictive relationships&lt;/strong&gt; between the &lt;strong&gt;levels&lt;/strong&gt; of
market shares and the matrix of own and cross-price &lt;strong&gt;derivatives&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Impact on &lt;strong&gt;counterfactuals&lt;/strong&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Restrictions only coming from model assumptions (analytical
convenience)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Models always imporse restrictions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;necessary for estimation&lt;/li&gt;
&lt;li&gt;but must allow flexibility in the relevant dimensions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-do-random-coefficients-help&#34;&gt;How do random coefficients help?&lt;/h3&gt;
&lt;p&gt;In &lt;strong&gt;reality&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;goods differ in multiple dimensions&lt;/li&gt;
&lt;li&gt;consumers have (heterogeneous) preferences over these differences&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How do &lt;strong&gt;random coefficients&lt;/strong&gt; capture it?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;large $\beta_i^k$ $\leftrightarrow$ strong taste for characteristic
$k$
&lt;ul&gt;
&lt;li&gt;e.g., maximum speed for sport car&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Consumer $i$’s first choice likely to have high value of $x^k$&lt;/li&gt;
&lt;li&gt;$i$’s second choice too!
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mark&lt;/strong&gt;: cross elasticities are always about 1st vs. 2nd
choices&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Incorporating this allows more sensible substitution patterns&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;competition is mostly “local”&lt;/li&gt;
&lt;li&gt;i.e., between firms offering products appealing to the same
consumers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;which-random-coefficients&#34;&gt;Which random coefficients?&lt;/h3&gt;
&lt;p&gt;Which characteristics have random coefficients?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dummies for subsets of products?
&lt;ul&gt;
&lt;li&gt;S. T. Berry (&lt;a href=&#34;#ref-berry1994estimating&#34;&gt;1994&lt;/a&gt;): covers the
nested logit as a special case&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;certain horizontal or vertical characteristics?
&lt;ul&gt;
&lt;li&gt;parts of $(\boldsymbol X_t, P_t)$?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;In practice&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choice depends on the application and data set, including
instruments&lt;/li&gt;
&lt;li&gt;Too many RC’s (w.r.t quantity of data available) $\to$ imprecise
estimates of $\boldsymbol \sigma$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;blp-estimation&#34;&gt;BLP: Estimation&lt;/h2&gt;
&lt;h3 id=&#34;setting-1&#34;&gt;Setting&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Observables&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\boldsymbol X_t$: product characteristics&lt;/li&gt;
&lt;li&gt;$P_t$: prices&lt;/li&gt;
&lt;li&gt;$S_t$: observed market shares&lt;/li&gt;
&lt;li&gt;$\boldsymbol W_t$: observable cost shifters&lt;/li&gt;
&lt;li&gt;$\boldsymbol Z_t$: excluded instruments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Sketch of procedure&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;start with demand model alone&lt;/li&gt;
&lt;li&gt;suppose $ F_{&lt;code&gt;\nu&lt;/code&gt;{=tex}} (&lt;code&gt;\cdot  &lt;/code&gt;{=tex} |
 &lt;code&gt;\boldsymbol &lt;/code&gt;{=tex}X, &lt;code&gt;\boldsymbol &lt;/code&gt;{=tex}&lt;code&gt;\sigma &lt;/code&gt;{=tex})$ is
known (i.e., $\sigma$ known)&lt;/li&gt;
&lt;li&gt;for each market $t$, find mean utilities $\Delta_t \in \mathbb R$
such that
$s_{jt} (\Delta_t, \boldsymbol X_t, \boldsymbol \sigma) = s^{obs}_{jt} \ \forall j$
&lt;ul&gt;
&lt;li&gt;i.e.,“invert” model at observed market shares to find mean
utilities $\boldsymbol \delta$&lt;/li&gt;
&lt;li&gt;where $s^{obs}_{jt}$ are the observed market shares&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;using IV ,e.g. $\mathbb E [\boldsymbol z_{jt} | \xi_{jt} ] = 0$,
estimate the equation&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;issues-1&#34;&gt;Issues&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;What instruments?&lt;/li&gt;
&lt;li&gt;Will the “inversion” step actually work?&lt;/li&gt;
&lt;li&gt;What about $\boldsymbol \sigma$??&lt;/li&gt;
&lt;li&gt;Formal estimator?&lt;/li&gt;
&lt;li&gt;Computational algorithm(s)?&lt;/li&gt;
&lt;li&gt;Supply side
&lt;ul&gt;
&lt;li&gt;additional restrictions (moment conditions)
&lt;ul&gt;
&lt;li&gt;help estimation of demand&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;additional parameters: marginal cost function
&lt;ul&gt;
&lt;li&gt;why? may care directly&lt;/li&gt;
&lt;li&gt;and needed for counterfactuals that change equilibrium
quantities unless $mc$ is constant&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;instruments&#34;&gt;Instruments&lt;/h3&gt;
&lt;p&gt;We need intruments for all endogenous variables—&lt;strong&gt;prices and
quantities&lt;/strong&gt;—&lt;strong&gt;independently&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Excluded cost shifters $\boldsymbol W_t$ (classic)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Usually: wages, material costs, shipping cost to market $t$,
taxes/tariffs, demand shifters from other markets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or proxies for them&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Usually: price of same good in another mkt (“&lt;em&gt;Hausman
instruments&lt;/em&gt;”)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Markup shifters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Usually: characteristics of “nearby” markets (“&lt;em&gt;Waldfogel
instruments&lt;/em&gt;”)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Logic: income/age/education in San Francisco might affect prices
in Oakland but might be independent fo Oakland preferences&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Product characteristics of other firms in the same market
$\boldsymbol X_{-jt}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“&lt;em&gt;BLP instruments&lt;/em&gt;”&lt;/li&gt;
&lt;li&gt;affect quantities directly; affect prices (markups) via
equilibrium only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;inversion&#34;&gt;Inversion&lt;/h3&gt;
&lt;p&gt;How do we get from market shares to prices??&lt;/p&gt;
&lt;p&gt;Given x,σ and any positive shares sh, define the following &lt;strong&gt;mapping&lt;/strong&gt;
$\Phi : \mathbb R^j \to \mathbb R^j$ $$
\Phi (\Delta_t) = \Delta_t + \log\Big( \hat S^{obs}_t \Big) - \log \Big( S_t (\Delta_t, \boldsymbol X_t, \boldsymbol \sigma) \Big)
$$ S. T. Berry (&lt;a href=&#34;#ref-berry1994estimating&#34;&gt;1994&lt;/a&gt;): for any nonzero
shares sh, Φ is a &lt;strong&gt;contraction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;under mild conditions on the linear random coefficients random
utility model&lt;/li&gt;
&lt;li&gt;extreme value and normal random coeff not necessary&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What does it imply?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It has a unique fixed point: we can compute
$\delta_{jt} = \delta (S_t, \boldsymbol X_t, \boldsymbol \sigma)$&lt;/li&gt;
&lt;li&gt;We can compute the fixed point iterating the contraction from any
initial guess $\Delta_{0t}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-about-sigma&#34;&gt;What about $\sigma$?&lt;/h3&gt;
&lt;p&gt;What we we got?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;inversion result: for any market shares and any
$\boldsymbol \sigma$, we can find a vector of mean utilities
$\Delta_t$ that rationalizes the data with the BLP model&lt;/li&gt;
&lt;li&gt;a non-identification result? there is no information about
$\boldsymbol \sigma$ from market shares?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are we forgetting?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cross-market variation!&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;We can get the mean utilities
$\delta_{jt} = \boldsymbol x_{jt} \boldsymbol \beta_0 - \alpha p_{jt} + \xi_{jt}$&lt;/li&gt;
&lt;li&gt;As in OLS, use $\boldsymbol z_{jt} \perp \xi_{jt}$ to get
identification of
$(\alpha, \boldsymbol \beta_0, \boldsymbol \sigma)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;identification-of-sigma&#34;&gt;Identification of $\sigma$&lt;/h3&gt;
&lt;p&gt;We are trying to estimate
$(\alpha, \boldsymbol \beta_0, \boldsymbol \sigma)$ from $$
\mathbb E \Big[ \xi_{jt} (\alpha, \boldsymbol \beta_0, \boldsymbol \sigma) \cdot \boldsymbol z_{jt} \Big] = \mathbb E \Big[ \big( \delta_{jt}(\boldsymbol \sigma) - \boldsymbol x_{jt} \boldsymbol \beta_0 + \alpha p_{jt} \big) \cdot \boldsymbol z_{jt} \Big]
$$ What kind of &lt;strong&gt;intruments&lt;/strong&gt; $\boldsymbol z_{jt}$ do we need?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\boldsymbol x_{jt}$ (for $\boldsymbol \beta_0$)&lt;/li&gt;
&lt;li&gt;intruments for $p_{jt}$ (for $\alpha$)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;but also&lt;/strong&gt; something for $\boldsymbol \sigma$!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;blp-estimation-1&#34;&gt;BLP Estimation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Take guess of parameters
$(\alpha, \boldsymbol \beta_0, \boldsymbol \sigma)$&lt;/li&gt;
&lt;li&gt;From observed market shared $S^{obs}&lt;em&gt;{t}$ and $\boldsymbol \sigma$
get mean utilities $\delta&lt;/em&gt;{jt} (\boldsymbol \sigma)$&lt;/li&gt;
&lt;li&gt;Use also $(\alpha, \boldsymbol \beta_0)$ to get
$\xi_{jt} (\alpha, \boldsymbol \beta_0, \boldsymbol \sigma)$&lt;/li&gt;
&lt;li&gt;Compute empirical moments
$\frac{1}{JT} \xi_{jt} (\alpha, \boldsymbol \beta_0, \boldsymbol \sigma) \cdot \boldsymbol z_{jt}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The GMM estimator is
$(\hat \alpha, \boldsymbol{\hat{\beta}_0}, \boldsymbol{\hat{\sigma}})$
that get the empirical moments as close to $0$ as possible.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Computing $S_t (\Delta_t, \boldsymbol X_t, \boldsymbol \sigma)$
involves a &lt;strong&gt;high dimensional integral&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Use simulation to approximate distribution of random tastes
$\zeta_{it}^k$&lt;/li&gt;
&lt;li&gt;P.S. recall that we have decomposed random coefficients
$\beta_{it}^k$ as
$\beta_{it}^k = \beta_0^k + \sigma_k \zeta_{it}^k$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\xi_{jt} (\alpha, \boldsymbol \beta_0, \boldsymbol \sigma)$ has
&lt;strong&gt;no closed form solution&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Compute it via contraction&lt;/li&gt;
&lt;li&gt;MPEC?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;computation&#34;&gt;Computation&lt;/h2&gt;
&lt;h3 id=&#34;nested-fixed-point-algorithm&#34;&gt;Nested fixed point algorithm&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Sketch of the algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Draw a vector of consumer tastes&lt;/li&gt;
&lt;li&gt;Until you have found a minimum for
$\mathbb E \Big[ \xi_{jt} (\alpha, \boldsymbol \beta_0, \boldsymbol \sigma) \cdot \boldsymbol z_{jt} \Big]$
do
&lt;ul&gt;
&lt;li&gt;Pick a vector of parameter values
$(\alpha, \boldsymbol \beta_0, \boldsymbol \sigma)$&lt;/li&gt;
&lt;li&gt;Initialize mean utilities $\delta_{jt}^0$&lt;/li&gt;
&lt;li&gt;Until
$\big|\big| \Delta_{t}^{n+1} - \Delta_{t}^{n} \big|\big| &amp;lt; tolerance$
do
&lt;ul&gt;
&lt;li&gt;Compute implied shares:
$s_{jt} (\Delta_{t}^{n}, \boldsymbol X_t, \boldsymbol \sigma) = \int \frac{\exp \left[ \boldsymbol x_{j t} \boldsymbol{\tilde{\beta}}&lt;em&gt;{it}+\delta&lt;/em&gt;{j t}\right]}{1+\sum_{j^{\prime}} \exp \left[\boldsymbol x_{j^{\prime} t} \boldsymbol{\tilde{\beta}}&lt;em&gt;{it}+\delta&lt;/em&gt;{j&amp;rsquo; t}\right]} f\left( \boldsymbol{\tilde{\beta}}&lt;em&gt;{it} \mid \theta\right) d \tilde{\beta}&lt;/em&gt;{i t}$&lt;/li&gt;
&lt;li&gt;Update mean utilities:
$\Delta_{t}^{n+1} = \Delta_{t}^{n} + \log\Big( \hat S^{obs}&lt;em&gt;t \Big) - \log \Big( S_t (\Delta&lt;/em&gt;{t}^{n}, \boldsymbol X_t, \boldsymbol \sigma) \Big)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compute
$\xi_{jt} = \delta_{jt} - \boldsymbol x_{jt} \boldsymbol \beta_0 + \alpha p_{jt}$&lt;/li&gt;
&lt;li&gt;Compute
$\mathbb E \Big[ \xi_{jt} (\alpha, \boldsymbol \beta_0, \boldsymbol \sigma) \cdot \boldsymbol z_{jt} \Big]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Important to draw shocks outside the optimization routine!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;references-references&#34;&gt;References [references]&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;
markdown=&#34;1&#34;&gt;
&lt;div id=&#34;ref-berry1994estimating&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Berry, Steven T. 1994. “Estimating Discrete-Choice Models of Product
Differentiation.” &lt;em&gt;The RAND Journal of Economics&lt;/em&gt;, 242–62.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-berry1995automobile&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Berry, Steven, James Levinsohn, and Ariel Pakes. 1995. “Automobile
Prices in Market Equilibrium.” &lt;em&gt;Econometrica: Journal of the Econometric
Society&lt;/em&gt;, 841–90.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single Agent Dynamics</title>
      <link>https://matteocourthoud.github.io/course/empirical-io/07_dynamics_singleagent/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/course/empirical-io/07_dynamics_singleagent/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;IO&lt;/strong&gt;: role of &lt;em&gt;market structure&lt;/em&gt; on &lt;em&gt;equilibrium outcomes&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dynamics&lt;/strong&gt;: study the &lt;strong&gt;endogenous evolution&lt;/strong&gt; of &lt;em&gt;market structure&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Supply&lt;/strong&gt; side dynamics
&lt;ul&gt;
&lt;li&gt;Irreversible investment&lt;/li&gt;
&lt;li&gt;Entry sunk costs&lt;/li&gt;
&lt;li&gt;Product repositioning costs&lt;/li&gt;
&lt;li&gt;Price adjustment costs&lt;/li&gt;
&lt;li&gt;Learning by doing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Demand&lt;/strong&gt; side dynamics
&lt;ul&gt;
&lt;li&gt;Switching costs&lt;/li&gt;
&lt;li&gt;Durable or storable products&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Bonus motivation&lt;/strong&gt;: AI literature studies essentially the same set of
problems with similar tools (&lt;a href=&#34;#ref-igami2020artificial&#34;&gt;Igami 2020&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Irony: niche topic in IO (super niche in econ), but at the core of
the frontier in computer science
&lt;ul&gt;
&lt;li&gt;Why? Computation is hard, estimation harder, but extremely
powerful prediction tool&lt;/li&gt;
&lt;li&gt;The world is intrinsecally dynamic&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;examples-1&#34;&gt;Examples (1)&lt;/h3&gt;
&lt;p&gt;Some examples in empirical IO&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Investment&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Rust (&lt;a href=&#34;#ref-rust1987optimal&#34;&gt;1987&lt;/a&gt;): bus engine replacement
decision&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Durable goods&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Gowrisankaran and Rysman
(&lt;a href=&#34;#ref-gowrisankaran2012dynamics&#34;&gt;2012&lt;/a&gt;): consumer demand in the
digital camcorder industry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stockpiling&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Erdem, Imai, and Keane (&lt;a href=&#34;#ref-erdem2003brand&#34;&gt;2003&lt;/a&gt;): promotions
and stockpiling of ketchup&lt;/li&gt;
&lt;li&gt;Hendel and Nevo (&lt;a href=&#34;#ref-hendel2006measuring&#34;&gt;2006&lt;/a&gt;): stockpiling
of laundry detergents&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Erdem and Keane (&lt;a href=&#34;#ref-erdem1996decision&#34;&gt;1996&lt;/a&gt;): brand learning
in the laundry detergent industry&lt;/li&gt;
&lt;li&gt;Crawford and Shum (&lt;a href=&#34;#ref-crawford2005uncertainty&#34;&gt;2005&lt;/a&gt;): demand
learning of anti‐ulcer drug prescriptions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Switching costs&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Handel (&lt;a href=&#34;#ref-handel2013adverse&#34;&gt;2013&lt;/a&gt;): inertia in demand for
health insurance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;examples-2&#34;&gt;Examples (2)&lt;/h3&gt;
&lt;p&gt;But also in other applied micro fields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Labor economics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Should you go to college? (&lt;a href=&#34;#ref-keane1997career&#34;&gt;Keane and Wolpin
1997&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Health economics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Which health insurance to pick given there are switching costs?
(&lt;a href=&#34;#ref-handel2013adverse&#34;&gt;Handel 2013&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Addiction (&lt;a href=&#34;#ref-becker1988theory&#34;&gt;Becker and Murphy 1988&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Public finance&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;How should you set optimal taxes in a dynamic environment?
(&lt;a href=&#34;#ref-golosov2006new&#34;&gt;Golosov et al. 2006&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;do-we-really-need-dynamics&#34;&gt;Do we really need dynamics?&lt;/h3&gt;
&lt;p&gt;In some cases, we can &lt;strong&gt;reduce&lt;/strong&gt; a dynamic problem to a:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Static problem&lt;/li&gt;
&lt;li&gt;Reduced-form problem&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;E.g., Investment decision&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dynamic problem, as gains are realized after costs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;“Static” solution: invest if $\mathbb E (NPV ) &amp;gt; TC$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Action today ($a_t=0$ or $1$) does not affect the amount of future
payoffs (NPV)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But many cases where it’s hard to evaluate dynamic questions in a
static/reduced-form setting.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Typically, cases where decision today would affect payoffs tomorrow&lt;/li&gt;
&lt;li&gt;And you care about those payoffs ($\neq$ myopia)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;“&lt;em&gt;A dynamic model can do anything a static model can.&lt;/em&gt;”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;new-empirical-io&#34;&gt;New Empirical IO&lt;/h3&gt;
&lt;p&gt;So-called New Empirical IO (summary in Bresnahan
(&lt;a href=&#34;#ref-bresnahan1989empirical&#34;&gt;1989&lt;/a&gt;))&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some &lt;strong&gt;decisions today&lt;/strong&gt; might affect &lt;strong&gt;payoffs tomorrow&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;But the decision today depends on the &lt;strong&gt;state today&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;And the state today might have been the result of a &lt;strong&gt;decision
yesterday&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Etc…&lt;/li&gt;
&lt;li&gt;Need &lt;strong&gt;dynamics&lt;/strong&gt; to study these questions&lt;/li&gt;
&lt;li&gt;Where does it all start?
&lt;ul&gt;
&lt;li&gt;Pakes (&lt;a href=&#34;#ref-pakes1986patents&#34;&gt;1986&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Berry (&lt;a href=&#34;#ref-berry1992estimation&#34;&gt;1992&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pros-and-cons&#34;&gt;Pros and Cons&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can adress &lt;strong&gt;intertemporal trade-offs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flow vs stock stocks and benefits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can examine &lt;strong&gt;transitions&lt;/strong&gt; and not only steady states&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We are able to address &lt;strong&gt;policy questions&lt;/strong&gt; that cannot be addressed
with reduced-form methods&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standard advantage of structural estimation&lt;/li&gt;
&lt;li&gt;But in a context with relevant intertemporal trade-offs /
decisions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We typically need more &lt;strong&gt;assumptions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Robustness testing will therefore be important&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Identification&lt;/strong&gt; in dynamic models is less transparent&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thus time should be spent articulating what variation in the
data identifies our parameters of interest)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is often &lt;strong&gt;computationally intensive&lt;/strong&gt; (i.e., slow / unfeasible)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;from-statics-to-dynamics&#34;&gt;From Statics to Dynamics&lt;/h3&gt;
&lt;p&gt;Typical steps&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Specify the primitives of the model
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Static&lt;/strong&gt;: single period agents’ payoff functions (utility or
profit)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic&lt;/strong&gt;: static payoffs + &lt;em&gt;evolution of state variables&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Can be exogenous&lt;/li&gt;
&lt;li&gt;… or endogenous: decision today has an effect on the state
tomorrow&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solve for optimal behavior
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Static&lt;/strong&gt;: tipically agents maximize current utility or profit&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic&lt;/strong&gt;: agents maximize &lt;em&gt;present discounted value&lt;/em&gt; of
future utilities or profits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Search for parameter values that result in the “best match” between
our model predictions and observed behavior&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;1st-year-macro-recap&#34;&gt;1st year Macro Recap&lt;/h2&gt;
&lt;h3 id=&#34;markov-decision-processes&#34;&gt;Markov Decision Processes&lt;/h3&gt;
&lt;p&gt;Formally, a discrete-time MDP consists of the following &lt;strong&gt;objects&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A discrete &lt;strong&gt;time index&lt;/strong&gt; $t \in \lbrace 0,1,2,&amp;hellip;,T \rbrace$, for
$T \leq \infty$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;state space&lt;/strong&gt; $\mathcal S$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An &lt;strong&gt;action space&lt;/strong&gt; $\mathcal A$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;and a family of &lt;strong&gt;constraint sets&lt;/strong&gt;
$\lbrace \mathcal a_t(s_t) \subseteq \mathcal A \rbrace$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A family of &lt;strong&gt;transition probabilities&lt;/strong&gt;
$\lbrace \Pr_{t}(s_{t+1}|s_t,a_t) \rbrace$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;discount factor&lt;/strong&gt;, $\beta$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A family of single-period &lt;strong&gt;reward functions&lt;/strong&gt;
$\lbrace (u_t(s_t,a_t) \rbrace$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;so that the utility functional $U$ has an additively separable
decomposition $$
U(\boldsymbol s, \boldsymbol a) = \sum_{t=0}^{T} \beta^{t} u_{t}\left(s_t, a_{t}\right)
$$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mdp-2&#34;&gt;MDP (2)&lt;/h3&gt;
&lt;p&gt;In words&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;state space&lt;/strong&gt; $\mathcal S$ contains all the information needed
to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compute static utilities $u_t (s_t, a_t)$&lt;/li&gt;
&lt;li&gt;compute transition probabilities
$\lbrace \Pr_{t} (s_{t+1}|s_t,a_t) \rbrace$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The (conditional) &lt;strong&gt;action space&lt;/strong&gt; $\mathcal A (s_t)$ contains all
the actions available in state $s_t$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How can it be different by state? E.g. entry/exit decision if
you’re in/out of the market&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;transition probabilities&lt;/strong&gt;
$\lbrace \Pr_{t+1}(s_{t+1}|s_t,a_t) \rbrace$ define the
probabilities of future states $s_{t+1}$ conditional on&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Present state $s_t$&lt;/li&gt;
&lt;li&gt;Present decision $a_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;discount factor&lt;/strong&gt; $\beta$ together with the static &lt;strong&gt;reward
functions&lt;/strong&gt; $\lbrace (u_t(s_t,a_t) \rbrace$ determines the
&lt;strong&gt;objective function&lt;/strong&gt; $$
\mathbb E_{\boldsymbol s&amp;rsquo;} \Bigg[ \sum_{t=0}^{T} \beta^{t} u_{t}\left(s_t, a_{t}\right) \Bigg]
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;notation&#34;&gt;Notation&lt;/h3&gt;
&lt;p&gt;Brief parenthesis on notation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I have seen &lt;strong&gt;states&lt;/strong&gt; denoted as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s$ (for state)&lt;/li&gt;
&lt;li&gt;$x$&lt;/li&gt;
&lt;li&gt;$\omega$&lt;/li&gt;
&lt;li&gt;others, depending on the specific context, e.g. $e$ for
experience&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;I will try to stick to $s$ all the time&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I have seen &lt;strong&gt;decisions&lt;/strong&gt; denoted as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a$ (for action)&lt;/li&gt;
&lt;li&gt;$d$ (for decision)&lt;/li&gt;
&lt;li&gt;$x$&lt;/li&gt;
&lt;li&gt;others, depending on the specific context, e.g. $i$ for
investment&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;I will try to stick to $a$ all the time&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;maximization-problem&#34;&gt;Maximization Problem&lt;/h3&gt;
&lt;p&gt;The objective is to pick the decision rule (or &lt;strong&gt;policy function&lt;/strong&gt;)
$P = \boldsymbol a^* = \lbrace a_1^*, &amp;hellip;, a_t ^ * \rbrace$ that solves
$$
\max_{\boldsymbol a} \ \mathbb E_{\boldsymbol s&amp;rsquo;} \Bigg[ \sum_{t=0}^{T} \beta^{t} u_{t} \left(s_{t}, a_{t} \right) \Bigg]
$$ Where the expectation is taken over transition probabilities
generated by the decision rule $\boldsymbol a$.&lt;/p&gt;
&lt;h3 id=&#34;stationarity&#34;&gt;Stationarity&lt;/h3&gt;
&lt;p&gt;In many applications, we assume &lt;strong&gt;stationarity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;strong&gt;transition probabilities and utility functions do not directly
depend on&lt;/strong&gt; $t$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i.e., are the same for all $t$
&lt;ul&gt;
&lt;li&gt;$\Pr_{{\color{red}{t}}} (s_{t+1}|s_t,a_t) \  \to \ \Pr(s_{t+1}|s_t,a_t)$&lt;/li&gt;
&lt;li&gt;$u_{{\color{red}{t}}} (s_t,a_t) \ \to \ u(s_t,a_t)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Uncomfortable assumption?&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You think there is some reason (variable) why today’s probabilities
should be different from tomorrow’s?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;strong&gt;observable&lt;/strong&gt;, include that variable in the state space&lt;/li&gt;
&lt;li&gt;If &lt;strong&gt;unobservable&lt;/strong&gt;, integrate it out&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stationarity-2&#34;&gt;Stationarity (2)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;strong&gt;finite horizon&lt;/strong&gt; case ($T \leq \infty$), stationarity does
not help much&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\sum_{t=0}^{T} \beta^{t} u(s_t, a_{t})$ still depends on $t$,
conditional on $s_t$&lt;/li&gt;
&lt;li&gt;Why? Difference between $t$ and $T$ matters in the sum&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In &lt;strong&gt;infinite-horizon&lt;/strong&gt; problems, stationarity helps &lt;strong&gt;a lot&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Now the difference between $t$ and $T$ is always the same,
i.e. $\infty$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sum_{t=0}^{\infty} \beta^{t} u(s_t, a_{t})$ does &lt;strong&gt;not&lt;/strong&gt;
depend on $t$, conditional on $s_t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;The future looks the same whether the agent is in state $s_t$
at time $t$ or in state $s_{t+\tau} = s_t$ at time $t + \tau$&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;value-function&#34;&gt;Value Function&lt;/h3&gt;
&lt;p&gt;Consider a &lt;strong&gt;stationary infinite-horizon&lt;/strong&gt; problem&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The only variable which affects the agent’s view about the future is
the current value of the state, $s_t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can rewrite the &lt;strong&gt;agent’s problem&lt;/strong&gt; as $$
V_0(s_0) = \max_{\boldsymbol a} \ \mathbb E_{\boldsymbol s&amp;rsquo;} \Bigg[ \sum_{t=0}^{\infty} \beta^{t} u\left(s_t, a_{t}\right) \Bigg]
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a_t \in \mathcal A(s_t) \ \forall t$&lt;/li&gt;
&lt;li&gt;The expectation is taken over future states $\boldsymbol s&#39;$
&lt;ul&gt;
&lt;li&gt;that evolve according to
$\lbrace \Pr(s_{t+1}|s_t,a_t) \rbrace$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$V(\cdot)$ is called the &lt;strong&gt;value function&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-to-solve&#34;&gt;How to solve?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;One could try to solve it by &lt;strong&gt;brute force&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;i.e. try to solve for the structure of all of the optimal
decisions, $\boldsymbol a^*$&lt;/li&gt;
&lt;li&gt;Indeed, for finite-horizon problems, that might be necessary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;stationary infinite-horizon&lt;/strong&gt; problems, the value and policy
function should be &lt;strong&gt;time invariant&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;$V_{\color{red}{t}} (s_t) = V(s_t)$&lt;/li&gt;
&lt;li&gt;$P_{\color{red}{t}} (s_t) = P(s_t)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What do we gain?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bellman-equation&#34;&gt;Bellman Equation&lt;/h3&gt;
&lt;p&gt;$$
\begin{align}
V(s_0) &amp;amp;= \max_{\boldsymbol a} \ \mathbb E_{\boldsymbol s&amp;rsquo;} \Bigg[ \sum_{t=0}^{\infty} \beta^{t} u(s_t, a_{t}) \Bigg]
= \newline
&amp;amp;= \max_{\boldsymbol a} \ \mathbb E_{\boldsymbol s&amp;rsquo;} \Bigg[ {\color{red}{u(s_{0}, a_{0})}} + \sum_{{\color{red}{t=1}}}^{\infty} \beta^{t} u(s_t, a_{t}) \Bigg]
= \newline
&amp;amp;= \max_{\boldsymbol a} \ \Bigg\lbrace u(s_{0}, a_{0}) + {\color{red}{\mathbb E_{\boldsymbol s&amp;rsquo;}}} \Bigg[ \sum_{t=1}^{\infty} \beta^{t} u(s_t, a_{t}) \Bigg] \Bigg\rbrace
= \newline
&amp;amp;= \max_{\boldsymbol a} \ \Bigg\lbrace u(s_{0}, a_{0}) + {\color{red}{\beta}} \ \mathbb E_{\boldsymbol s&amp;rsquo;} \Bigg[ \sum_{t=1}^{\infty} \beta^{{\color{red}{t-1}}} u(s_t, a_{t}) \Bigg] \Bigg\rbrace
= \newline
&amp;amp;= \max_{{\color{red}{a_0}}} \ \Bigg\lbrace u(s_{0}, a_{0}) + \beta \ {\color{red}{\max_{\boldsymbol a}}}\ \mathbb E_{\boldsymbol s&amp;rsquo;} \Bigg[ \sum_{t=1}^{\infty} \beta^{t-1} u(s_t, a_{t}) \Bigg] \Bigg\rbrace
= \newline
&amp;amp;= \max_{a_0} \ \Bigg\lbrace u(s_{0}, a_{0}) + \beta \ {\color{red}{\int V(s_1) \Pr(s_1 | s_0, a_0)}} \Bigg\rbrace
\end{align}
$$&lt;/p&gt;
&lt;h3 id=&#34;bellman-equation-2&#34;&gt;Bellman Equation (2)&lt;/h3&gt;
&lt;p&gt;We have now a &lt;strong&gt;recursive formulation&lt;/strong&gt; of the value function: the
&lt;strong&gt;Bellman Equation&lt;/strong&gt; $$
{\color{red}{V(s_0)}} = \max_{a_0} \ \Bigg\lbrace u(s_{0}, a_{0}) + \beta \ \int {\color{red}{V(s_1)}} \Pr(s_1 | s_0, a_0) \Bigg\rbrace
$$ &lt;strong&gt;Intuition&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Bellman Equation is a &lt;strong&gt;functional equation&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Has to be satisfied in every state&lt;/li&gt;
&lt;li&gt;Can be written as ${\color{red}{V}} = T({\color{red}{V}})$&lt;/li&gt;
&lt;li&gt;We are actually looking for a &lt;strong&gt;fixed point&lt;/strong&gt; of $T$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The decision rule that satisfies the Bellman Equation is called the
&lt;strong&gt;policy function&lt;/strong&gt; $$
a(s_0) =  \arg \max_{a_0} \ \Bigg\lbrace u(s_{0}, a_{0}) + \beta \ \int V(s_1) \Pr(s_1 | s_0, a_0) \Bigg\rbrace
$$&lt;/p&gt;
&lt;h3 id=&#34;contractions&#34;&gt;Contractions&lt;/h3&gt;
&lt;p&gt;Under regularity conditions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$u(s, a)$ is jointly continuous and bounded in $(s, a)$&lt;/li&gt;
&lt;li&gt;$\mathcal A (s)$ is a continuous correspondence&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is possible to show that $$
T(W)(s) = \max_{a \in \mathcal A(s)} \ \Bigg\lbrace u(s, a) + \beta \ \int W(s&amp;rsquo;) \Pr(s&amp;rsquo; | s, a) \Bigg\rbrace
$$ is a &lt;strong&gt;contraction mapping&lt;/strong&gt; of modulus $\beta$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contraction Mapping Theorem&lt;/strong&gt;: then $T$ has a unique fixed point!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solving-for-the-value-function&#34;&gt;Solving for the Value Function&lt;/h3&gt;
&lt;p&gt;How do we actually do it in practice?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For &lt;strong&gt;finite horizon&lt;/strong&gt; MDPs: &lt;strong&gt;backward induction&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Start from the last period: static maximization problem&lt;/li&gt;
&lt;li&gt;Move backwards taking the future value as given&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;infinite horizon&lt;/strong&gt; MDPs: different options
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;value function iteration&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;most common&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;policy function iteration&lt;/li&gt;
&lt;li&gt;successive approximations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;difference-with-1st-year-macro&#34;&gt;Difference with 1st year Macro&lt;/h3&gt;
&lt;p&gt;So what’s going to be new here?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Estimation&lt;/strong&gt;: retrieve model primitives from observed behavior
&lt;ul&gt;
&lt;li&gt;And related: uncertainty&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strategic interaction&lt;/strong&gt;: multiple agents taking dynamic decisions
&lt;ul&gt;
&lt;li&gt;Next lecture&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;rust-1987&#34;&gt;Rust (1987)&lt;/h2&gt;
&lt;h3 id=&#34;setting&#34;&gt;Setting&lt;/h3&gt;
&lt;p&gt;Rust (&lt;a href=&#34;#ref-rust1987optimal&#34;&gt;1987&lt;/a&gt;): &lt;em&gt;An Empirical Model of Harold
Zurcher&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Harold Zurcher (HZ) is the city bus superintendant in Madison, WI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As bus engines get older, the probability of malfunctions increases&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HZ decides when to replace old bus engines with new ones&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimal stopping / investment problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tradeoff&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cost of a new engine (fixed, stock)&lt;/li&gt;
&lt;li&gt;Repair costs, because of engine failures (continuous, flow)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do we care about Harold Zurcher?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Obviously not (and neither did Rust), it’s a method paper&lt;/li&gt;
&lt;li&gt;But referee asked for an application&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data&#34;&gt;Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Units of observation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rust observes 162 buses over time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Observables&lt;/strong&gt;: for each bus, he sees&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;monthly mileage (RHS, state variable)&lt;/li&gt;
&lt;li&gt;and whether the engine was replaced (LHS, choice variable),&lt;/li&gt;
&lt;li&gt;in a given month&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Variation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;on average, bus engines were replaced every 5 years with over
200,000 elapsed miles&lt;/li&gt;
&lt;li&gt;considerable variation in the &lt;em&gt;time&lt;/em&gt; and &lt;em&gt;mileage&lt;/em&gt; at which
replacement occurs&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;idea&#34;&gt;Idea&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Construct a (parametric) &lt;strong&gt;model&lt;/strong&gt; which predicts the time and
mileage at which engine replacement occurs&lt;/li&gt;
&lt;li&gt;Use the model predictions (conditional on parameter values) to
&lt;strong&gt;estimate parameters&lt;/strong&gt; that “fit” the data
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;predicted&lt;/strong&gt; replacements, given mileage VS &lt;strong&gt;observed&lt;/strong&gt;
replacements, given mileage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ideally use the estimates to &lt;strong&gt;learn something&lt;/strong&gt; new
&lt;ul&gt;
&lt;li&gt;e.g. the correct &lt;em&gt;dynamic&lt;/em&gt; demand curve for bus engine
replacement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;static-alternative&#34;&gt;Static Alternative&lt;/h3&gt;
&lt;p&gt;What would you do otherwise?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You observe replacement decisions&lt;/li&gt;
&lt;li&gt;… and replacement costs&lt;/li&gt;
&lt;li&gt;$\to$ &lt;strong&gt;Regress&lt;/strong&gt; replacement decision on replacement costs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Replacement benefits are a flow (lower maintenance costs)&lt;/li&gt;
&lt;li&gt;… while the cost is a stock&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Outcome&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We expect the &lt;em&gt;overestimate&lt;/em&gt; demand elasticity. Why?&lt;/li&gt;
&lt;li&gt;Overpredict substitutions at low costs&lt;/li&gt;
&lt;li&gt;and underpredict substitution at high cost&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;Assumptions of the structural model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;State&lt;/strong&gt;: $s_t \in \lbrace 0, &amp;hellip; , s_{max} \rbrace$
&lt;ul&gt;
&lt;li&gt;engine accumulated mileage at time $t$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: “continuous” in the data but has to be discretized
into bins&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action&lt;/strong&gt;: $a_t \in \lbrace 0, 1 \rbrace$
&lt;ul&gt;
&lt;li&gt;replace engine at time $t$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State transitions&lt;/strong&gt;:
$\Pr ( s_{t+1} | s_{0}, &amp;hellip; , s_t ; \theta)= \Pr (s_{t+1} | s_t ; \theta )$
&lt;ul&gt;
&lt;li&gt;mileage $s_t$ evolves exogenously according to a 1st-order
Markov process&lt;/li&gt;
&lt;li&gt;The transition function is the same for every bus.&lt;/li&gt;
&lt;li&gt;If HZ replaces in period $t$ ($a_t = 1$), then $s_t = 0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-2&#34;&gt;Model (2)&lt;/h3&gt;
&lt;p&gt;HZ &lt;strong&gt;static utility function&lt;/strong&gt; (for a single bus) $$
u\left(s_t, a_{t} ; \theta\right)= \begin{cases}-c\left(s_t ; \theta\right) &amp;amp; \text { if } a_{t}=0 \text { (not replace) } \newline -R-c(0 ; \theta) &amp;amp; \text { if } a_{t}=1 \text { (replace) }\end{cases}
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$c(s_t ; \theta)$: expected &lt;strong&gt;costs of operating&lt;/strong&gt; a bus with
mileage $s_t$
&lt;ul&gt;
&lt;li&gt;​ including maintenance costs &amp;amp; social costs of breakdown&lt;/li&gt;
&lt;li&gt;We would expect $\frac{\partial c}{\partial s}&amp;gt;0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$R$ is the &lt;strong&gt;cost of replacement&lt;/strong&gt; (i.e., a new engine)
&lt;ul&gt;
&lt;li&gt;Note that replacement occurs immediately&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$u(s_t , a_t ; \theta)$: expected current utility from operating a
bus with mileage $s_t$ and making replacement decision $a_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-3&#34;&gt;Model (3)&lt;/h3&gt;
&lt;p&gt;HZ &lt;strong&gt;objective function&lt;/strong&gt; is to maximize the expected present discounted
sum of future utilities $$
V(s_t ; \theta) = \max_{\boldsymbol a} \mathbb E_{s_{t+1}} \left[\sum_{\tau=t}^{\infty} \beta^{\tau-t} u\left(s_{\tau}, a_{\tau} ; \theta\right) \ \Bigg| \ s_t, \boldsymbol a ; \theta\right]
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The expectation $\mathbb E$ is over future $x$, which evolve
according to Markov process&lt;/li&gt;
&lt;li&gt;$\max$ is over future choices $a_{t+1}, &amp;hellip; ,a_{\infty}$,
&lt;ul&gt;
&lt;li&gt;because HZ will observe future states $s_{\tau}$ before choosing
future actions $a_\tau$, this is a functional&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is for one bus (but multiple engines).&lt;/li&gt;
&lt;li&gt;HZ has an infinite horizon for his decision making&lt;/li&gt;
&lt;li&gt;$s_t$ summarizes state at time $t$, i.e., the expected value of
future utilities only depends on $s_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bellman-equation-1&#34;&gt;Bellman Equation&lt;/h3&gt;
&lt;p&gt;This (sequential) representation of HZ’s problem is very cumbersome to
work with.&lt;/p&gt;
&lt;p&gt;We can rewrite $V (s_t; \theta)$ with the following Bellman equation $$
V\left(s_t ; \theta\right) = \max_{a_{t}} \Bigg\lbrace u\left(s_t, a_{t} ; \theta\right)+\beta \mathbb E_{s_{t+1}} \Big[V\left(s_{t+1} ; \theta\right) \Big| s_t, a_{t} ; \theta\Big] \Bigg\rbrace
$$ Basically we are dividing the infinite sum (in the sequential form)
into a present component and a future component.&lt;/p&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Same $V$ on both sides of equation because of infinite horizon - the
future looks the same as the present for a given $s$ (i.e., it
doesn’t matter where you are in time).&lt;/li&gt;
&lt;li&gt;The expectation $\mathbb E$ is over the state-transition
probabilities, $\Pr (s_{t+1} | s_t, a_t ; \theta)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;order-of-markow-process&#34;&gt;Order of Markow Process&lt;/h3&gt;
&lt;p&gt;Suppose for a moment that $s_t$ follows a second-order markov process $$
s_{t+1}=f\left(s_t, {\color{red}{s_{t-1}}}, \varepsilon ; \theta\right)
$$ Now $s_t$ is not sufficient to describe current $V$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We need both $s_t$ and $s_{t-1}$ in the state space (i.e.,
$V (s_t , {\color{red}{s_{t-1}}}; \theta)$ contains $s_{t-1}$, too),&lt;/li&gt;
&lt;li&gt;and the expectation is over the transition probability
$\Pr (s_{t+1} | s_t, {\color{red}{s_{t-1}}}, a_t ; \theta)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;parenthesis-state-variables&#34;&gt;Parenthesis: State Variables&lt;/h3&gt;
&lt;p&gt;Which variables should be state variables? I.e. should be included in
the state space?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;General rule&lt;/strong&gt; for 1st order markow processes: variables need to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;define expected current payoff, &lt;strong&gt;and&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;define expectations over next period state (i.e., distribution of
$s_{t+1}$)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What do you do otherwise? Integrate them out! &lt;strong&gt;Examples&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Weather affects static utitilies but not transition probabilities
&lt;ul&gt;
&lt;li&gt;More annoying to replace the engine if it rains&lt;/li&gt;
&lt;li&gt;Integration means: &lt;em&gt;“compute expected utility of Harold Zurcher
before he opens the window”&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Month of the year affects transition probabilities but not utilities
&lt;ul&gt;
&lt;li&gt;Buses are used more in the winter&lt;/li&gt;
&lt;li&gt;Integration means: &lt;em&gt;“compute average transition probabilities
over months”&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: you can always get the non-expected value function if you
know the probability of raining or the transition probabilities by
month&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;policy-function&#34;&gt;Policy Function&lt;/h3&gt;
&lt;p&gt;Along with this value function comes a corresponding &lt;strong&gt;policy (or
choice) function&lt;/strong&gt; mapping the state $s_t$ into HZ’s optimal replacement
choice $a_t$ $$
P \left(s_t ; \theta\right) =  \max_{a_{t}} \Bigg\lbrace u\left(s_t, a_{t} ; \theta\right) + \beta \mathbb E_{s_{t+1}} \Big[ V \left(s_{t+1} ; \theta\right) \Big| s_t, a_{t} ; \theta\Big] \Bigg\rbrace
$$ Given $\frac{\partial c}{\partial s}&amp;gt;0$, the policy function has the
form $$
P \left(s_t ; \theta\right) =  \begin{cases}1 &amp;amp; \text { if } s_t \geq \gamma(\theta) \newline 0 &amp;amp; \text { if } s_t&amp;lt;\gamma(\theta)\end{cases}
$$ where $\gamma$ is the replacement mileage.&lt;/p&gt;
&lt;p&gt;How would this compare with the optimal replacement mileage if HZ was
myopic?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Answer: HZ would wait until $R \leq c(s)$ for the replacement action&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solving-the-model&#34;&gt;Solving the Model&lt;/h3&gt;
&lt;p&gt;Why do we want to solve for the value and policy functions?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We want to know the agent’s optimal behavior and the equilibrium
outcomes&lt;/li&gt;
&lt;li&gt;and be able to conduct comparative statics/dynamics (a.k.a.
counterfactual simulations)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We have the &lt;strong&gt;Bellman Equation&lt;/strong&gt; $$
V\left(s_t ; \theta\right) = \max_{a_{t}} \Bigg\lbrace u\left(s_t, a_{t} ; \theta\right)+\beta \mathbb E_{s_{t+1}} \Big[V\left(s_{t+1} ; \theta\right) \ \Big|
\ s_t, a_{t} ; \theta\Big] \Bigg\rbrace
$$ Which we can compactly write as $$
V\left(s_t ; \theta\right) = T \Big( V\left(s_{t+1} ; \theta\right) \Big)
$$ &lt;strong&gt;Blackwell’s Theorem&lt;/strong&gt;: under regularity conditions, $T$ is a
contraction mapping with modulus $\beta$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contraction Mapping Theorem&lt;/strong&gt;: $T$ has a fixed point and we can find
it by iterating $T$ from any starting value $V^{(0)}$.&lt;/p&gt;
&lt;h3 id=&#34;value-function-iteration&#34;&gt;Value Function Iteration&lt;/h3&gt;
&lt;p&gt;What does &lt;strong&gt;Blackwell’s Theorem&lt;/strong&gt; allow us to do?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Start with any arbitrary function $V^{(0)}(\cdot)$&lt;/li&gt;
&lt;li&gt;Apply the mapping $T$ to get $V^{(1)}(\cdot) = T (V^{(0)}(\cdot))$&lt;/li&gt;
&lt;li&gt;Apply again $V^{(2)}(\cdot) = T (V^{(1)}(\cdot))$&lt;/li&gt;
&lt;li&gt;Continue applying $T$ , and $V^{(k)}$ will converge to the unique
fixed point of $T$
&lt;ul&gt;
&lt;li&gt;i.e., the true value function $V(s_t; \theta)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Once we have $V(s_t; \theta)$, it’s fairly trivial to compute the
policy function $P(s_t; \theta)$
&lt;ul&gt;
&lt;li&gt;Static optimization problem (given $V$)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This process is called &lt;strong&gt;value function iteration&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;how-to-reconcile-model-and-data&#34;&gt;How to Reconcile Model and Data?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ideal Estimation Routine&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pick a parameter value $\theta$&lt;/li&gt;
&lt;li&gt;Solve value and policy function (&lt;em&gt;inner loop&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Match &lt;em&gt;predicted choices&lt;/em&gt; with &lt;em&gt;observed choices&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Find the parameter value $\hat \theta$ that best fits the data
(&lt;em&gt;outer loop&lt;/em&gt;)
&lt;ul&gt;
&lt;li&gt;Makes the observed choices “closest” to the predicted choices&lt;/li&gt;
&lt;li&gt;(or maximizes the likelihood of the observed choices)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: model easily &lt;strong&gt;rejected&lt;/strong&gt; by the data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The policy function takes the the form: replace iff
$s_t \geq \gamma(\theta)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Can’t explain the coexistence of e.g. “&lt;em&gt;a bus without replacement at
22K miles&lt;/em&gt;” and “&lt;em&gt;another bus being replaced at 17K mile&lt;/em&gt;s” in the
data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We need some &lt;strong&gt;unobservables&lt;/strong&gt; in the model to explain why observed
choices do not exactly match predicted choices&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rust-1987---estimation&#34;&gt;Rust (1987) - Estimation&lt;/h2&gt;
&lt;h3 id=&#34;uncertainty&#34;&gt;Uncertainty&lt;/h3&gt;
&lt;p&gt;How can we explain different replacement actions at different mileages
in the data?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add other observables&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Add some stochastic element&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But &lt;strong&gt;where&lt;/strong&gt;? Two options&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Randomness in decisions
&lt;ul&gt;
&lt;li&gt;I.e. &lt;em&gt;“Harold Zurcher sometimes would like to replace the bus
engine but he forgets”&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Probably still falsifiable&lt;/li&gt;
&lt;li&gt;Also need “&lt;em&gt;Harold Zurcher sometimes would like not to replace
but replacement happens”&lt;/em&gt; 🤔🤔🤔&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Randomness in the state
&lt;ul&gt;
&lt;li&gt;Harold Zurcher knows something that we don’t&lt;/li&gt;
&lt;li&gt;He &lt;strong&gt;always makes the optimal decision&lt;/strong&gt; but based on somethig
we don’t observe&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;unobservables&#34;&gt;Unobservables&lt;/h3&gt;
&lt;p&gt;Rust uses the following &lt;strong&gt;utility specification&lt;/strong&gt;: $$
u\left(s_t, a_{t}, {\color{red}{\epsilon_{t}}} ; \theta\right) = u\left(s_t, a_{t} ; \theta\right) + {\color{red}{\epsilon_{a_{t} t}}} = \begin{cases} - c\left(s_t ; \theta\right) + {\color{red}{\epsilon_{0 t}}} &amp;amp; \text { if } \ a_{t}=0 \newline \newline -R-c(0 ; \theta) + {\color{red}{\epsilon_{1 t}}} &amp;amp; \text { if } \ a_{t}=1 \end{cases}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The $\epsilon_{it}$ are components of utility of alternative $a$
that are observed by HZ but not by us, the econometrician.
&lt;ul&gt;
&lt;li&gt;E.g., the fact that an engine is running unusually smoothly
given its mileage,&lt;/li&gt;
&lt;li&gt;or the fact that HZ is sick and doesn’t feel like replacing the
engine this month&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: we have assumed addictive separability of $\epsilon$&lt;/li&gt;
&lt;li&gt;The $\epsilon_a$s also affect HZ’s replacement decision&lt;/li&gt;
&lt;li&gt;$\epsilon_{it}$ are &lt;strong&gt;both observed and relevant&lt;/strong&gt; $\to$ part of the
state space&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Can we still &lt;strong&gt;solve&lt;/strong&gt; the model? Can we &lt;strong&gt;estimate&lt;/strong&gt; it?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;unobservables-2&#34;&gt;Unobservables (2)&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Bellman Equation&lt;/strong&gt; becomes $$
V \Big( {\color{red}{ \lbrace s_\tau \rbrace_{\tau=1}^t , \lbrace \epsilon_\tau \rbrace_{\tau=1}^t }} ; \theta \Big) = \max_{a_{t}} \Bigg\lbrace u\left(s_t, a_{t} ; \theta\right) + {\color{red}{\epsilon_{it}}} + \beta \mathbb E_{s_{t+1}, {\color{red}{\epsilon_{t+1}}}} \Big[V\left(s_{t+1}, {\color{red}{\epsilon_{it+1}}} ; \theta\right) \ \Big|
\ {\color{red}{ \lbrace s_\tau \rbrace_{\tau=1}^t , \lbrace \epsilon_\tau \rbrace_{\tau=1}^t }}, a_{t} ; \theta\Big] \Bigg\rbrace
$$ &lt;strong&gt;Issues&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The problem is &lt;strong&gt;not Markow&lt;/strong&gt; anymore
&lt;ul&gt;
&lt;li&gt;Is $\epsilon_t$ correlated with $\epsilon_{t-\tau}$? How?&lt;/li&gt;
&lt;li&gt;Is $\epsilon_t$ correlated with $s_t$? And $s_{t-\tau}$? How?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dimension of the &lt;strong&gt;state space&lt;/strong&gt; has increased
&lt;ul&gt;
&lt;li&gt;From
$k = (k \text{ points})^{1 \text{ variable} \times 1 \text{ period}}$
points, to
$\infty = (k \text{ points})^{3 \text{ variables} \times \infty \text{ periods}}$
🤯🤯&lt;/li&gt;
&lt;li&gt;Assuming all variables assume $k$ values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Number of variables to integrate over to compute &lt;strong&gt;expectation&lt;/strong&gt;
$\mathbb E$ has increased
&lt;ul&gt;
&lt;li&gt;From one variable, $s$, to three,
$(s, \epsilon_{0}, \epsilon_{1})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assumptions&#34;&gt;Assumptions&lt;/h3&gt;
&lt;p&gt;Rust makes &lt;strong&gt;4 assumptions&lt;/strong&gt; to make the problem tractable:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First order Markow process of $\epsilon$&lt;/li&gt;
&lt;li&gt;Conditional independence of $\epsilon_t | s_t$ from $\epsilon_{t-1}$
and $s_{t-1}$&lt;/li&gt;
&lt;li&gt;Independence of $\epsilon_t$ from $s_t$&lt;/li&gt;
&lt;li&gt;Logit distribution of $\epsilon$&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;assumption-1&#34;&gt;Assumption 1&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A1&lt;/strong&gt;: first-order markov process of $\epsilon$ $$
\Pr \Big(s_{t+1}, \epsilon_{t+1} \Big| s_{1}, &amp;hellip;, s_t, \epsilon_{1}, &amp;hellip;, \epsilon_{t}, a_{t} ; \theta\Big) = \Pr \Big(s_{t+1}, \epsilon_{t+1} \Big| s_t, \epsilon_{t}, a_{t} ; \theta \Big)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What it buys&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s$ and $\epsilon$ prior to current period are irrelevant&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What it still allows&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;allows $s_t$ to be correlated with $\epsilon_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What are we assuming away&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Any sort of longer run dependence&lt;/li&gt;
&lt;li&gt;Does it matter? If yes, just re-consider what is one time period&lt;/li&gt;
&lt;li&gt;Or make the state space larger (as usual in Markow processes)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assumption-1---implications&#34;&gt;Assumption 1 - Implications&lt;/h3&gt;
&lt;p&gt;The Bellman Equation becomes $$
V\left(s_t, {\color{red}{\epsilon_{t}}} ; \theta\right) = \max_{a_{t}} \Bigg\lbrace u\left(s_t, a_{t} ; \theta\right) + {\color{red}{\epsilon_{a_{t} t}}} + \beta \mathbb E_{s_{t+1}, {\color{red}{\epsilon_{t+1}}}} \Big[V(s_{t+1}, {\color{red}{\epsilon_{t+1}}} ; \theta) \ \Big| \ s_t, a_{t}, {\color{red}{\epsilon_{t}}} ; \theta \Big] \Bigg\rbrace
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now the &lt;strong&gt;state&lt;/strong&gt; is $(s_t, \epsilon_t)$
&lt;ul&gt;
&lt;li&gt;sufficient, because defines both current utility and (the
expectation of) next-period state, under the first-order Markov
assumption&lt;/li&gt;
&lt;li&gt;$\epsilon_t$ is now analogous to $s_t$&lt;/li&gt;
&lt;li&gt;State space now is
$k^3 = (k \text{ points})^{3 \text{ variables} \times 1 \text{ period}}$
&lt;ul&gt;
&lt;li&gt;From
$\infty = (k \text{ points})^{3 \text{ variables} \times \infty \text{ periods}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Now we could use &lt;strong&gt;value function iteration&lt;/strong&gt; to solve the problem
&lt;ul&gt;
&lt;li&gt;If $\epsilon_t$ is continuous, it has to be discretised&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assumption-1---issues&#34;&gt;Assumption 1 - Issues&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Open issues&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Curse of dimensionality in the state space&lt;/strong&gt;:
($s_t, \epsilon_{0t}, \epsilon_{1t}$)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Before, there were $k$ points in state space (discrete values of
$x$)&lt;/li&gt;
&lt;li&gt;Now there are $k^3$ : $k$ each for $s$, $\epsilon_0$,
$\epsilon_1$
&lt;ul&gt;
&lt;li&gt;(Assuming we discretize all state variables into $k$ values)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generally, number of points in state space (and thus
computational time) increases exponentially in the number of
variables&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Curse of dimensionality in the expected value&lt;/strong&gt;:
$\mathbb E_{s_{t+1}, \epsilon_{0,t+1}, \epsilon_{1,t+1}}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each point in state space (at each iteration of the
contraction mapping), need to compute&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\mathbb E_{s_{t+1}, \epsilon_{t+1}} \Big[V (s_{t+1}, \epsilon_{t+1} ; \theta) \ \Big|  \ s_t, a_{t}, \epsilon_{t} ; \theta \Big]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Before, this was a 1-dimensional integral (or sum), now it’s
3-dimensional&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Initial conditions&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;assumption-2&#34;&gt;Assumption 2&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A2&lt;/strong&gt;: conditional independence of $\epsilon_t | s_t$ from
$\epsilon_{t-1}$ and $s_{t-1}$ $$
\Pr \Big(s_{t+1}, \epsilon_{t+1} \Big| s_t, \epsilon_{t}, a_{t} ; \theta \Big) = \Pr \Big( \epsilon_{t+1} \Big| s_{t+1} ; \theta \Big) \Pr \Big( s_{t+1} \Big| s_t, a_{t} ; \theta \Big)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What it buys&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s_{t+1}$ is independent of $\epsilon_t$&lt;/li&gt;
&lt;li&gt;$\epsilon_{t+1}$ is independent of $\epsilon_t$ and $s_t$,
conditional on $s_{t+1}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What it still allows&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\epsilon$ can be correlated across time, but only through the
$s$ process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What are we assuming away&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Any time of persistent heterogeneity&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Does it matter? Easily yes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are tons of applications where the unobservables are
either fixed or correlated over time&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If fixed, there are methods to handle unobserved
heterogeneity (i.e. bus “types”)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assumption-2---implications&#34;&gt;Assumption 2 - Implications&lt;/h3&gt;
&lt;p&gt;The Bellman Equation is $$
V\left(s_t, {\color{red}{\epsilon_{t}}} ; \theta\right) = \max_{a_{t}} \Bigg\lbrace u\left(s_t, a_{t} ; \theta\right) + {\color{red}{\epsilon_{a_{t} t}}} + \beta \mathbb E_{s_{t+1}, {\color{red}{\epsilon_{t+1}}}} \Big[V (s_{t+1}, {\color{red}{\epsilon_{t+1}}} ; \theta) \Big| s_t, a_{t} ; \theta \Big] \Bigg\rbrace
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now $\epsilon_{t}$ is noise that &lt;strong&gt;doesn’t affect the future&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;That is, conditional on $s_{t+1}$, $\epsilon_{t+1}$ is
uncorrelated with $\epsilon_{t}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Remeber&lt;/strong&gt;: if $\epsilon$ does not affect the future, it should’t be
in the state space!&lt;/p&gt;
&lt;p&gt;How? Integrate it out.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;rust-shortcut-asv&#34;&gt;Rust Shortcut: ASV&lt;/h3&gt;
&lt;p&gt;Rust: define the &lt;strong&gt;alternative-specific value function&lt;/strong&gt; $$
\begin{align}
&amp;amp;\bar V_0 \left(s_t ; \theta\right) = u\left(s_t, 0 ; \theta\right) + \beta \mathbb E_{s_{t+1}, {\color{red}{\epsilon_{t+1}}}} \Big[V\left(s_{t+1}, {\color{red}{\epsilon_{t+1}} }; \theta\right) | s_t, a_{t}=0 ; \theta\Big] \newline
&amp;amp;\bar V_1 \left(s_t ; \theta\right) = u\left(s_t, 1 ; \theta\right) + \beta \mathbb E_{s_{t+1}, {\color{red}{\epsilon_{t+1}}}} \Big[V\left(s_{t+1}, {\color{red}{\epsilon_{t+1}}} ; \theta\right) | s_t, a_{t}=1 ; \theta\Big]
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\bar V_0 (s_t)$ is the present discounted value of not replacing,
net of $\epsilon_{0t}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The state does not depend on&lt;/strong&gt; $\epsilon_{t}$!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What is the relationship with the value function? $$
V\left(s_t, \epsilon_{t} ; \theta\right) = \max_{a_{t}} \Bigg\lbrace \begin{array}{l}
\bar V_0 \left(s_t ; \theta\right)+\epsilon_{0 t}
\ ; \newline
\bar V_1 \left(s_t ; \theta\right)+\epsilon_{1 t}
\end{array} \Bigg\rbrace
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We have a 1-to-1 mapping between
$V\left(s_t, \epsilon_{t} ; \theta\right)$ and
$\bar V_a \left(s_t ; \theta\right)$ !&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If we have one, we can get the other&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rust-shortcut&#34;&gt;Rust Shortcut&lt;/h3&gt;
&lt;p&gt;Can we solve for $\bar V$?&lt;/p&gt;
&lt;p&gt;Yes! They have a &lt;strong&gt;recursive formulation&lt;/strong&gt; $$
\begin{aligned}
&amp;amp;
\bar V_0 \left(s_t ; \theta\right) = u\left(s_t, 0 ; \theta\right) + \beta \mathbb E_{s_{t+1}, {\color{red}{\epsilon_{t+1}}}} \Bigg[ \max_{a_{t+1}} \Bigg\lbrace \begin{array}{l}
\bar V_0 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{0 t+1}}}
\ ; \newline
\bar V_1 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{1 t+1}}}
\end{array} \Bigg\rbrace \ \Bigg| \ s_t, a_{t}=0 ; \theta \Bigg] \newline
&amp;amp;
\bar V_1 \left(s_t ; \theta\right) = u\left(s_t, 1 ; \theta\right) + \beta \mathbb E_{s_{t+1}, {\color{red}{\epsilon_{t+1}}}} \Bigg[ \max_{a_{t+1}} \Bigg\lbrace \begin{array}{l}
\bar V_0 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{0 t+1}}}
\ ; \newline
\bar V_1 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{1 t+1}}}
\end{array} \Bigg\rbrace \ \Bigg| \ s_t, a_{t}=1 ; \theta \Bigg] \newline
\end{aligned}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rust (&lt;a href=&#34;#ref-rust1988maximum&#34;&gt;1988&lt;/a&gt;) shows that it’s a joint
contraction mapping&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memo&lt;/strong&gt;: the state space now is
$2k = (2 \text{ actions}) \times (k \text{ points})^{1 \text{ variables} \times 1 \text{ period}}$
&lt;ul&gt;
&lt;li&gt;instead of
$3^k = (k \text{ points})^{3 \text{ variables} \times 1 \text{ period}}$&lt;/li&gt;
&lt;li&gt;Much smaller!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lesson&lt;/strong&gt;: any state variable that does not affect continuation
values (the future) does not have to be in the “actual” state space&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assumption-2---implications-1&#34;&gt;Assumption 2 - Implications&lt;/h3&gt;
&lt;p&gt;We can also &lt;strong&gt;split the expectation&lt;/strong&gt; in the alternative-specific value
function $$
\begin{aligned}
&amp;amp;
\bar V_0 \left(s_t ; \theta\right) = u\left(s_t, 0 ; \theta\right) + \beta \mathbb E_{s_{t+1}} \Bigg[ \mathbb E_{{\color{red}{\epsilon_{t+1}}}} \Bigg[ \max_{a_{t+1}} \Bigg\lbrace \begin{array}{l}
\bar V_0 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{0 t+1}}}
\ ; \newline
\bar V_1 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{1 t+1}}}
\end{array} \Bigg\rbrace \ \Bigg| \ s_t \Bigg] \ \Bigg| \ s_t, a_{t}=0 ; \theta \Bigg] \newline
&amp;amp;
\bar V_1 \left(s_t ; \theta\right) = u\left(s_t, 1 ; \theta\right) + \beta \mathbb E_{s_{t+1}} \Bigg[ \mathbb E_{{\color{red}{\epsilon_{t+1}}}} \Bigg[ \max_{a_{t+1}} \Bigg\lbrace \begin{array}{l}
\bar V_0 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{0 t+1}}}
\ ; \newline
\bar V_1 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{1 t+1}}}
\end{array} \Bigg\rbrace \ \Bigg| \ s_t \Bigg] \ \Bigg| \ s_t, a_{t}=1 ; \theta \Bigg] \newline
\end{aligned}
$$ This allows us to concentrate on one single term $$
\mathbb E_{{\color{red}{\epsilon_{t+1}}}} \Bigg[ \max_{a_{t+1}} \Bigg\lbrace \begin{array}{l}
\bar V_0 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{0 t+1}}}
\ ; \newline
\bar V_1 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{1 t+1}}}
\end{array} \Bigg\rbrace \ \Bigg| \ s_t \Bigg]
$$ &lt;strong&gt;Open issues&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distribution of $\epsilon_{t+1}$ has to be simulated&lt;/li&gt;
&lt;li&gt;Distribution of $\epsilon_{t+1}$ depends on $s_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assumption-3&#34;&gt;Assumption 3&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A3&lt;/strong&gt;: independence of $\epsilon_t$ from $s_t$ $$
\Pr \Big( \epsilon_{t+1} \Big| s_{t+1} ; \theta \Big) \Pr \Big( s_{t+1} \Big| s_t, a_{t} ; \theta \Big) = \Pr \big( \epsilon_{t+1} \big| \theta \big) \Pr \Big( s_{t+1} \Big| s_t, a_{t} ; \theta \Big)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What it buys&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\epsilon$ not correlated with anything $$
\mathbb E_{{\color{red}{\epsilon_{t+1}}}} \Bigg[ \max_{a_{t+1} \in \lbrace 0, 1 \rbrace } \Bigg\lbrace \begin{array}{l}
\bar V_0 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{0 t+1}}}
\ ; \newline
\bar V_1 \left(s_{t+1} ; \theta\right) + {\color{red}{\epsilon_{1 t+1}}}
\end{array} \Bigg\rbrace \ \Bigg]
$$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What are we assuming away&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some state-specific noise… probably irrelevant&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Open Issues&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distribution of $\epsilon_{t+1}$ has to be simulated&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assumption-4&#34;&gt;Assumption 4&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A4&lt;/strong&gt;: $\epsilon$ is type 1 extreme value distributed (logit)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What it buys&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Closed form solution for $\mathbb E_{\epsilon_{t+1}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;What are we assuming away&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Different substitution patterns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Relevant? Maybe, if there are at least three options (here
binary choice)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As logit assumption in demand estimation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Logit magic&lt;/strong&gt; 🧙🪄 $$
\mathbb E_{\epsilon} \Bigg[ \max_n \bigg( \Big\lbrace \delta_n + \epsilon_n \Big\rbrace_{n=1}^N \bigg) \Bigg] = 0.5772 + \ln \bigg( \sum_{n=1}^N e^{\delta_n} \bigg)
$$&lt;/p&gt;
&lt;p&gt;where $0.5772$ is Euler’s constant&lt;/p&gt;
&lt;h3 id=&#34;assumption-4---implications&#34;&gt;Assumption 4 - Implications&lt;/h3&gt;
&lt;p&gt;The Bellman equation becomes $$
\begin{aligned}
&amp;amp;
\bar V_0 \left(s_t ; \theta\right) = u\left(s_t, 0 ; \theta\right) + \beta \mathbb E_{s_{t+1}} \Bigg[ 0.5772 + \ln \Bigg( \sum_{a&amp;rsquo; \in \lbrace 0, 1 \rbrace} e^{\bar V_{a&amp;rsquo;} (s_{t+1} ; \theta)} \Bigg) \ \Bigg| \ s_t, a_{t}=0 ; \theta \Bigg] \newline
&amp;amp;
\bar V_1 \left(s_t ; \theta\right) = u\left(s_t, 1 ; \theta\right) + \beta \mathbb E_{s_{t+1}} \Bigg[ 0.5772 + \ln \Bigg( \sum_{a&amp;rsquo; \in \lbrace 0, 1 \rbrace} e^{\bar V_{a&amp;rsquo;} (s_{t+1} ; \theta)} \Bigg) \ \Bigg| \ s_t, a_{t}=1 ; \theta \Bigg] \newline
\end{aligned}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We got &lt;strong&gt;fully rid of $\epsilon$&lt;/strong&gt;!
&lt;ul&gt;
&lt;li&gt;How? With a lot of assumptions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;estimation&#34;&gt;Estimation&lt;/h3&gt;
&lt;p&gt;So far we have analysized how the &lt;strong&gt;4 assumptions&lt;/strong&gt; help &lt;strong&gt;solving the
model&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What about &lt;strong&gt;estimation&lt;/strong&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Maximum Likelihood&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For a single bus, the &lt;strong&gt;likelihood function&lt;/strong&gt; is&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\mathcal L = \Pr \Big(s_{1}, &amp;hellip; , s_T, a_{0}, &amp;hellip; , a_{T} \ \Big| \ s_{0} ; \theta\Big)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i.e. probability of observed decisions
$\lbrace a_{0}, &amp;hellip; , a_{T} \rbrace$&lt;/li&gt;
&lt;li&gt;and sequence of states $\lbrace s_{1}, &amp;hellip; , s_T \rbrace$&lt;/li&gt;
&lt;li&gt;conditional on the initial state $s_0$&lt;/li&gt;
&lt;li&gt;and the parameter values $\theta$&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;What is the impact of the 4 assumptions on the likelihood function?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;likelihood-function-a1&#34;&gt;Likelihood Function (A1)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A1&lt;/strong&gt;: First order Markow process of $\epsilon$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We gain independence across time&lt;/li&gt;
&lt;li&gt;We can decompose the joint distribution in marginals across time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\begin{align}
\mathcal L(\theta) &amp;amp;=  \Pr \Big(s_{1}, &amp;hellip; , s_T, a_{0}, &amp;hellip; , a_{T} \Big| s_{0} ; \theta\Big)\newline
&amp;amp;=  \prod_{t=1}^T \Pr \Big(a_{t+1} , s_{t+1} \Big| s_t, a_t ; \theta\Big)
\end{align}
$$&lt;/p&gt;
&lt;h3 id=&#34;likelihood-function-a2&#34;&gt;Likelihood Function (A2)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A2&lt;/strong&gt;: independence of $\epsilon_t$ from $\epsilon_{t-1}$ and $s_{t-1}$
on $s_t$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can decompose the joint distribution of $a_t$ and $s_{t+1}$ into
marginals $$
\begin{align}
\mathcal L(\theta) &amp;amp;= \prod_{t=1}^T \Pr \Big(a_{t+1} , s_{t+1} \Big| s_t, a_t ; \theta\Big)
= \newline
&amp;amp;= \prod_{t=1}^T \Pr \big(a_t \big| s_t ; \theta\big) \Pr \Big(s_{t+1} \Big| s_t, a_t ; \theta\Big)
\end{align}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\Pr \big(s_{t+1} \big| s_t, a_t ; \theta\big)$ can be estimated
from the data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we’ll come back to it&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for $\Pr \big(a_t \big| s_t ; \theta\big)$ we need the two remaining
assumptions&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;likelihood-function-a3&#34;&gt;Likelihood Function (A3)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A3&lt;/strong&gt;: Independence of $\epsilon_t$ from $s_t$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No need to condition on $s_t$&lt;/li&gt;
&lt;li&gt;E.g. probability of replacement&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\begin{align}
\Pr \big(a_t=1 \big| s_t ; \theta \big) &amp;amp;= \Pr \Big( \bar V_1 (s_{t+1} ; \theta) + \epsilon_{1 t+1} \geq \bar V_0 (s_{t+1} ; \theta) + \epsilon_{0 t+1} \ \Big| \ s_t ; \theta \Big)
= \newline
&amp;amp;= \Pr \Big( \bar V_1 (s_{t+1} ; \theta) + \epsilon_{1 t+1} \geq \bar V_0 (s_{t+1} ; \theta) + \epsilon_{0 t+1} \ \Big| \ \theta \Big)
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In words: same distribution of shocks in every state&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;likelihood-function-a4&#34;&gt;Likelihood Function (A4)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A4&lt;/strong&gt;: Logit distribution of $\epsilon$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;E.g. probability of replacement becomes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\begin{align}
\Pr \big(a_t=1 \big| s_t ; \theta \big) &amp;amp;= \Pr \Big( \bar V_1 (s_{t+1} ; \theta) + \epsilon_{1 t+1} \geq \bar V_0 (s_{t+1} ; \theta) + \epsilon_{0 t+1} \ \Big| \ \theta \Big)
= \newline
&amp;amp;= \frac{e^{\bar V_1 (s_{t+1} ; \theta)}}{e^{\bar V_0 (s_{t+1} ; \theta)} + e^{\bar V_1 (s_{t+1} ; \theta)}}
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have a closed form expression!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;likelihood-function&#34;&gt;Likelihood Function&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;final form&lt;/strong&gt; of the likelihood function for one bus is $$
\mathcal L(\theta) = \prod_{t=1}^T \Pr\big(a_t \big| s_t ; \theta \big) \Pr \Big(s_{t+1} \ \Big| \ s_t, a_t ; \theta\Big)
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Pr \Big(s_{t+1} \ \Big| \ s_t, a_t ; \theta\Big)$ can be estimated
from the data
&lt;ul&gt;
&lt;li&gt;given mileage $x$ and investment decision $a$, what are the
observed frequencies of future states $x&amp;rsquo;$?&lt;/li&gt;
&lt;li&gt;does not have to depend on $\theta$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\Pr\big(a_t \big| s_t ; \theta \big)$ depends on
$\bar V_a (s ; \theta)$
&lt;ul&gt;
&lt;li&gt;$\bar V_a (s ; \theta)$ we know how to compute&lt;/li&gt;
&lt;li&gt;given a value of $\theta$&lt;/li&gt;
&lt;li&gt;solve by value function iteration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;likelihood-function-2&#34;&gt;Likelihood Function (2)&lt;/h3&gt;
&lt;p&gt;Since we have may buses, $j$, the likelihood of the data is $$
\mathcal L(\theta) = \prod_{j} \mathcal L_j (\theta) = \prod_{j} \prod_{t=1}^T \Pr\big(a_{jt} \big| s_{jt} ; \theta \big) \Pr \Big(s_{j,t+1} \ \Big| \ s_{jt}, a_{jt} ; \theta\Big)
$$ And, as usual, we prefer to work with log-likelihoods $$
\log \mathcal L(\theta) = \sum_{j} \sum_{t=1}^T \Bigg( \log \Pr\big(a_{jt} \big| s_{jt} ; \theta \big) + \log\Pr \Big(s_{j,t+1} \ \Big| \ s_{jt}, a_{jt} ; \theta\Big) \Bigg)
$$&lt;/p&gt;
&lt;h3 id=&#34;estimation-1&#34;&gt;Estimation&lt;/h3&gt;
&lt;p&gt;Now we have all the pieces to estimate $\theta$!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Procedure&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Estimate the state transition probabilities
$\Pr \big(s_{t+1} \big| s_t, a_t ; \theta\big)$&lt;/li&gt;
&lt;li&gt;Select a value of $\theta$&lt;/li&gt;
&lt;li&gt;Init a choice-specific value function
$\bar V_a^{(0)} (s_{t+1} ; \theta)$
&lt;ol&gt;
&lt;li&gt;Apply the Bellman operator to compute
$\bar V_a^{(1)} (s_{t+1} ; \theta)$&lt;/li&gt;
&lt;li&gt;Iterate until convergence to
$\bar V_d^{(k \to \infty)} (s_{t+1} ; \theta)$ (&lt;em&gt;inner loop&lt;/em&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Compute the choice probabilities
$\Pr \big(a_t\big| s_t ; \theta \big)$&lt;/li&gt;
&lt;li&gt;Compute the likelihood
$\mathcal L = \prod_j \prod_{t=1}^T \Pr \big(a_t \big| s_t ; \theta\big) \Pr \Big(s_{t+1} \Big| s_t, a_t ; \theta\Big)$&lt;/li&gt;
&lt;li&gt;Iterate (2-5) until you are have found a (possibly global) minimum
(&lt;em&gt;outer loop&lt;/em&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;What do &lt;strong&gt;dynamics&lt;/strong&gt; add?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Static&lt;/strong&gt; demand curve ($\beta =0$) is much more sensitive to the
price of engine replacement. Why?
&lt;ul&gt;
&lt;li&gt;Compares present price with present savings&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If you compare present price with flow of future benefits, you are
less price sensitive
&lt;ul&gt;
&lt;li&gt;More realistic&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;../img/7_01.png&#34; style=&#34;width:50.0%&#34; /&gt;
&lt;h3 id=&#34;extensions&#34;&gt;Extensions&lt;/h3&gt;
&lt;p&gt;Main &lt;strong&gt;limitation&lt;/strong&gt; of Rust (&lt;a href=&#34;#ref-rust1987optimal&#34;&gt;1987&lt;/a&gt;): &lt;strong&gt;value
function iteration&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Costly: has to be done for each parameter explored during
optimization&lt;/li&gt;
&lt;li&gt;Particularly costly if the state space is large&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Solutions&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Solve the model without solving a fixed point problem
&lt;ul&gt;
&lt;li&gt;Hotz and Miller (&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solve the model and estimate the parameters at the same time
&lt;ul&gt;
&lt;li&gt;Inner and outer loop in parallel&lt;/li&gt;
&lt;li&gt;Imai, Jain, and Ching (&lt;a href=&#34;#ref-imai2009bayesian&#34;&gt;2009&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Treat the estimation as a constrained optimization problem
&lt;ul&gt;
&lt;li&gt;MPEC, as for demand&lt;/li&gt;
&lt;li&gt;Use off-the-shelf optimization algorithms&lt;/li&gt;
&lt;li&gt;Su and Judd (&lt;a href=&#34;#ref-su2012constrained&#34;&gt;2012&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We’ll cover Hotz and Miller (&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;) since at
the core of the estimation of dynamic games.&lt;/p&gt;
&lt;h2 id=&#34;hotz--miller-1993&#34;&gt;Hotz &amp;amp; Miller (1993)&lt;/h2&gt;
&lt;h3 id=&#34;motivation-1&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Setting&lt;/strong&gt;: Harold Zurcher problem&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;same model&lt;/li&gt;
&lt;li&gt;same assumptions&lt;/li&gt;
&lt;li&gt;same notation&lt;/li&gt;
&lt;li&gt;same objective&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: computationally intense to do value function iteration&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Can we solve the model without solving a fixed point problem?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;estimation-in-rust&#34;&gt;Estimation in Rust&lt;/h3&gt;
&lt;p&gt;How did we estimate the model in Rust? &lt;strong&gt;Two main equations&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Solve the &lt;strong&gt;Bellman equation&lt;/strong&gt; of the alternative-specific value
function $$
{\color{green}{\bar V(s; \theta)}} = \tilde f( {\color{green}{\bar V(s; \theta)}})
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the &lt;strong&gt;expected policy function&lt;/strong&gt; $$
{\color{blue}{P( \cdot | s; \theta)}} = \tilde g( {\color{green}{\bar V(s; \theta)}} ; \theta)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Maximize the likelihood function&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\mathcal L(\theta) = \prod_{j} \prod_{t=1}^T {\color{blue}{ \Pr\big(a_{jt} \big| s_{jt} ; \theta \big)}} \Pr \Big(s_{j,t+1} \ \Big| \ s_{jt}, a_{jt} ; \theta\Big)
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Can we remove step 1?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;hotz--miller-ideas&#34;&gt;Hotz &amp;amp; Miller Idea(s)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Idea 1&lt;/strong&gt;: it would be great if we could start from something like $$
{\color{blue}{P(\cdot|s; \theta)}} = T( {\color{blue}{P(\cdot|s; \theta)}} ; \theta)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No need to solve for the value function&lt;/li&gt;
&lt;li&gt;But we would still need a to solve a &lt;strong&gt;fixed point&lt;/strong&gt; problem&lt;/li&gt;
&lt;li&gt;Back from the start? No&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Idea 2&lt;/strong&gt;: could replace the RHS element with a &lt;strong&gt;consistent estimate&lt;/strong&gt;
$$
{\color{blue}{P(\cdot|s; \theta)}} = T( {\color{red}{\hat P(\cdot|s; \theta)}} ; \theta)
$$ And this could give us an estimating equation!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Unclear? No problem, let’s go slowly step by step&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;two-main-equations&#34;&gt;Two Main Equations&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bellman equation&lt;/strong&gt; $$
{\color{green}{\bar V_a \left(s_t ; \theta\right)}} = u\left(s_t, a ; \theta\right) + \beta \mathbb E_{s_{t+1}, \epsilon_{t+1}} \Bigg[ \max_{a&amp;rsquo;} \Big\lbrace {\color{green}{\bar V_{a&amp;rsquo;}}} \left(s_{t+1}; \theta\right) + \epsilon_{a&amp;rsquo;,t+1} \Big\rbrace \ \Big| \ s_t, a_t=a ; \theta \Bigg]
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Expected policy function&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
{\color{blue}{\Pr \big(a_t=a \big| s_t ; \theta \big)}} = \Pr \Big( {\color{green}{\bar V_a (s_{t+1} ; \theta)}} + \epsilon_{a, t+1} \geq {\color{green}{\bar V_{a&amp;rsquo;} (s_{t+1} ; \theta)}} + \epsilon_{a&amp;rsquo;, t+1} , \ \forall a&amp;rsquo; \ \Big| \ \theta \Big)
$$&lt;/p&gt;
&lt;p&gt;Expected decision &lt;strong&gt;before&lt;/strong&gt; the shocks $\epsilon_t$ are realized&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Not&lt;/strong&gt; the policy function
&lt;ul&gt;
&lt;li&gt;The policy function maps
$s_t \times \epsilon \to \lbrace 0 , 1 \rbrace$&lt;/li&gt;
&lt;li&gt;The expected policy function maps $s_t \to [ 0 , 1 ]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Easier to work with: does not depend on the shocks
&lt;ul&gt;
&lt;li&gt;Not a deterministic policy, but a stochastic one&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hotz--miller---idea-1&#34;&gt;Hotz &amp;amp; Miller - Idea 1&lt;/h3&gt;
&lt;p&gt;How do we get from the two equations $$
\begin{aligned}
{\color{green}{\bar V(s; \theta)}} &amp;amp;= \tilde f( {\color{green}{\bar V(s; \theta)}}) \newline
{\color{blue}{P(\cdot|s; \theta)}} &amp;amp;= \tilde g( {\color{green}{\bar V(s; \theta)}} ; \theta)
\end{aligned}
$$ To one? $$
{\color{blue}{P(\cdot|s; \theta)}} = T ({\color{blue}{P(\cdot|s; \theta)}}; \theta)
$$ If we could express $\bar V$ in terms of $P$, … $$
\begin{aligned}
{\color{green}{\bar V(s; \theta)}} &amp;amp; = \tilde h( {\color{blue}{P(\cdot|s; \theta)}})  \newline
{\color{blue}{P(\cdot|s; \theta)}} &amp;amp;= \tilde g( {\color{green}{\bar V(s; \theta)}} ; \theta)
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;…. we could then substitute the first equation into the second …&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;But&lt;/strong&gt;, easier to work with a different representation of the value
function.&lt;/p&gt;
&lt;h3 id=&#34;expected-value-function&#34;&gt;Expected Value Function&lt;/h3&gt;
&lt;p&gt;Recall Rust &lt;strong&gt;value function&lt;/strong&gt; (not the alternative-specific $\bar V$)
$$
V\left(s_t, \epsilon_t ; \theta\right) = \max_{a_{t}} \Bigg\lbrace u \left( s_t, a_{t} ; \theta \right)  + \epsilon_{a_{t} t} + \beta \mathbb E_{s_{t+1}, \epsilon_{t+1}} \Big[V\left(s_{t+1}, \epsilon_{t+1} ; \theta\right) \Big| s_t, a_{t} ; \theta\Big] \Bigg\rbrace
$$ We can express it in terms of &lt;strong&gt;expected value function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$
V\left(s_t ; \theta\right) = \mathbb E_{\epsilon_t} \Bigg[ \max_{a_{t}} \Bigg\lbrace u\left(s_t, a_t ; \theta\right) + \epsilon_{a_{t} t}+ \beta \mathbb E_{s_{t+1}} \Big[V\left(s_{t+1}; \theta\right) \Big| s_t, a_{t} ; \theta\Big] \Bigg\rbrace \Bigg]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Value of being in state $s_t$ without knowing the realization of the
shock $\epsilon_t$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“Value of Harold Zurcher before opening the window and seeing
if it’s raining or not”&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analogous to the relationship between policy funciton and expected
policy function&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;expectation of future value now is only over $s_{t+1}$&lt;/li&gt;
&lt;li&gt;$V\left(s_t ; \theta\right)$ can be solved via value function
iteration as the operator on the RHS is a contraction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;representation-equivalence&#34;&gt;Representation Equivalence&lt;/h3&gt;
&lt;p&gt;Recall the &lt;strong&gt;alternative-specific value function&lt;/strong&gt; of Rust&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
{\color{green}{\bar V_a \left( s_t ; \theta\right)}} &amp;amp;= u\left(s_t, d ; \theta\right) + \beta \mathbb E_{s_{t+1}, \epsilon_{t+1}} \Bigg[ \max_{a&amp;rsquo;} \Big\lbrace {\color{green}{\bar V_{a&amp;rsquo;} \left(s_{t+1}; \theta\right)}} + \epsilon_{a&amp;rsquo;,t+1} \Big\rbrace \ \Big| \ s_t, a_t=a ; \theta \Bigg] \newline
&amp;amp;=u\left(s_t, a ; \theta\right)+\beta \mathbb E_{s_{t+1}, \epsilon_{t+1}} \Big[ {\color{orange}{V \left( s_{t+1}, \epsilon_{t+1} ; \theta \right)}} \Big| s_t, a_t=a ; \theta \Big]
\newline
&amp;amp;= u \left( s_t, a ; \theta \right) + \beta \mathbb E_{s_{t+1}} \Big[ {\color{red}{V \left( s_{t+1} ; \theta \right)}} \Big| s_t, a_t=a; \theta \Big]
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Relationship with the &lt;strong&gt;value function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$
{\color{orange}{V \left(s_t, \epsilon_{t} ; \theta \right)}} = \max_{a_{t}} \Big\lbrace {\color{green}{ \bar  V_0 \left( s_t ; \theta \right)}} + \epsilon_{0t}, {\color{green}{\bar V_1 \left( s_t ; \theta \right)}} + \epsilon_{1t} \Big\rbrace
$$&lt;/p&gt;
&lt;p&gt;Relationship with the &lt;strong&gt;expected value function&lt;/strong&gt; $$
{\color{red}{V\left(s_t ; \theta\right)}} = \mathbb E_{\epsilon_t} \Big[ {\color{orange}{V\left(s_t, \epsilon_{t} ; \theta\right)}} \ \Big| \ s_t \Big]
$$&lt;/p&gt;
&lt;h3 id=&#34;goal&#34;&gt;Goal&lt;/h3&gt;
&lt;p&gt;We switched from &lt;strong&gt;alternative-specific value function&lt;/strong&gt;
${\color{green}{\bar V (s_t ; \theta)}}$ to &lt;strong&gt;expected value function&lt;/strong&gt;
${\color{red}{V(s_t ; \theta)}}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;But the goal is the same&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Go from this representation $$
\begin{align}
{\color{red}{V(s ; \theta)}} &amp;amp; = f( {\color{red}{V(s ; \theta)}}) \newline
{\color{blue}{P(\cdot | s ; \theta)}} &amp;amp; = g( {\color{red}{V(s ; \theta)}}; \theta)
\end{align}
$$ To this $$
\begin{align}
{\color{red}{V(s ; \theta)}} &amp;amp; = h( {\color{blue}{P(\cdot|s ; \theta)}} ; \theta) \newline
{\color{blue}{P(\cdot|s ; \theta)}} &amp;amp; = g({\color{red}{V(s ; \theta)}}; \theta)
\end{align}
$$ I.e. we want to express the &lt;strong&gt;expected value function (EV)&lt;/strong&gt; in terms
of the &lt;strong&gt;expected policy function (EP)&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;**Note **: the $f$, $g$ and $h$ functions are different functions now.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;express-ev-in-terms-of-ep-1&#34;&gt;Express EV in terms of EP (1)&lt;/h3&gt;
&lt;p&gt;First, let’s ged rid of one operator: the &lt;strong&gt;max&lt;/strong&gt; operator $$
V\left(s_t ; \theta\right)
= \sum_a \Pr \Big(a_t=a | s_t ; \theta \Big) * \left[\begin{array}{c}
u\left(s_t, a ; \theta\right) + \mathbb E_{\epsilon_t} \Big[\epsilon_{at}\Big| a_t=a, s_t\Big] \newline \qquad + \beta \mathbb E_{s_{t+1}} \Big[V\left(s_{t+1} ; \theta\right) \Big| s_t, a_t=a ; \theta\Big]
\end{array}\right]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We are just substituting the $\max$ with the policy
$\Pr\left(a_t=a| s_t ; \theta\right)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Important: we got rid of the $\max$ operator&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;But we are still taking the expectation over&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Future states $s_{t+1}$&lt;/li&gt;
&lt;li&gt;Shocks $\epsilon_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;express-ev-in-terms-of-ep-2&#34;&gt;Express EV in terms of EP (2)&lt;/h3&gt;
&lt;p&gt;Now we get rid of another operator: the expectation over $s_{t+1}$ $$
\mathbb E_{s_{t+1}} \Big[V\left(s_{t+1} ; \theta\right) \Big| s_t, a_t=a ; \theta\Big] \qquad \to \qquad \sum_{s_{t+1}} V\left(s_{t+1} ; \theta\right) \Pr \Big(s_{t+1} \Big| s_t, a_t=a ; \theta \Big)
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\sum_{s_{t+1}}$ is the summation over the next states&lt;/li&gt;
&lt;li&gt;$\Pr (s_{t+1} | s_t, a_t=a ; \theta )$ is the transition probability
(conditional on a particular choice)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;so that the expected value function becomes $$
V\left(s_t ; \theta\right)
= \sum_a \Pr \Big(a_t=a | s_t ; \theta \Big) * \left[\begin{array}{c}
u\left(s_t, a ; \theta\right) + \mathbb E_{\epsilon_t} \Big[\epsilon_{at}\Big| a_t=a, s_t\Big] \newline + \beta \sum_{s_{t+1}} V\left(s_{t+1} ; \theta\right) \Pr \Big(s_{t+1} \Big| s_t, a_t=a ; \theta \Big)
\end{array}\right]
$$&lt;/p&gt;
&lt;h3 id=&#34;express-ev-in-terms-of-ep-3&#34;&gt;Express EV in terms of EP (3)&lt;/h3&gt;
&lt;p&gt;The previous equation, was defined at the state level $s_t$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;system of $k$ equations, 1 for each state (value of $x$)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we &lt;strong&gt;stack&lt;/strong&gt; them, we can write them as $$
V\left(s ; \theta\right)
= \sum_a \Pr \Big(a \ \Big| \ s ; \theta \Big) .* \Bigg[
u\left(s, a ; \theta\right) + \mathbb E_{\epsilon} \Big[\epsilon_{a} \ \Big| \ a, s \Big] + \beta \ T(a ; \theta) \ V(s ; \theta) \Bigg]
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$T(a)$: $k \times k$ matrix of transition probabilities from state
$s_t$ to $s_{t+1}$, given decision $a$&lt;/li&gt;
&lt;li&gt;$.*$ is the dot product operator (or element-wise matrix
multiplication)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;express-ev-in-terms-of-ep-4&#34;&gt;Express EV in terms of EP (4)&lt;/h3&gt;
&lt;p&gt;Now we have a system of $k$ equations in $k$ unknowns that we can solve.&lt;/p&gt;
&lt;p&gt;Tearing down notation to the bare minimum, we have $$
V = \sum_a P_a .* \bigg[ u_a + \mathbb E [\epsilon_a ] + \beta \ T_a \ V \bigg]
$$ which we can rewrite as $$
V - \beta \  \left( \sum_a P_a .* T_a \right) V = \sum_a P_a .* \bigg[ u_a + \mathbb E [\epsilon_a ] \bigg]
$$&lt;/p&gt;
&lt;p&gt;and finally we can solve for $V$ through the famous &lt;strong&gt;Hotz and Miller
inversion&lt;/strong&gt; $$
V = \left[I - \beta \ \sum_a P_a .* T_a \right]^{-1} \ * \ \left( \sum_a P_a \ .* \ \bigg[ u_a + \mathbb E [\epsilon_a] \bigg] \right)
$$ Solved? No. We still need to do something about
$\mathbb E [\epsilon_a]$.&lt;/p&gt;
&lt;h3 id=&#34;express-ev-in-terms-of-ep-5&#34;&gt;Express EV in terms of EP (5)&lt;/h3&gt;
&lt;p&gt;What is $\mathbb E [\epsilon_a]$?&lt;/p&gt;
&lt;p&gt;Let’s consider for example the expected value of the shock, conditional
on investment $$
\begin{aligned}
\mathbb E \Big[ \epsilon_{1 t} \ \Big| \ a_t = 1, \cdot \Big] &amp;amp;= \mathbb E \Big[ \epsilon_{t} \ \Big| \ \bar V_1 \left( s_t ; \theta \right) + \epsilon_{1 t} &amp;gt; \bar V_0 \left( s_t ; \theta \right) + \epsilon_{0 t} \Big] \newline
&amp;amp; = \mathbb E \Big[ \epsilon_{1 t} \ \Big| \ \bar V_1 \left( s_t ; \theta \right)  - \bar V_0 \left( s_t ; \theta \right) &amp;gt; \epsilon_{0 t} - \epsilon_{1 t} \Big]
\end{aligned}
$$ with &lt;strong&gt;logit magic&lt;/strong&gt; 🧙🪄 is $$
\mathbb E\left[\epsilon_{1 t} | a_{t}=1, s_t\right] = 0.5772 - \ln \left(P\left(s_t ; \theta\right)\right)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;where $0.5772$ is Euler’s constant.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We again got rid of another $\max$ operator!&lt;/p&gt;
&lt;h3 id=&#34;express-ev-in-terms-of-ep-6&#34;&gt;Express EV in terms of EP (6)&lt;/h3&gt;
&lt;p&gt;Now we can substitute it back and we have an equation which is &lt;em&gt;just&lt;/em&gt; a
function of primitives $$
\begin{aligned}
V(\cdot ; \theta) =&amp;amp; \Big[I-(1-P(\cdot ; \theta)) \beta T(0 ; \theta)-P(\cdot ; \theta) \beta T(1 ; \theta)\Big]^{-1}
\newline * &amp;amp; \left[
\begin{array}{c}
(1-P(\cdot ; \theta))\Big[u(\cdot, 0 ; \theta)+0.5772-\ln (1-P(\cdot ; \theta))\Big] \newline + P(\cdot ; \theta)\Big[u(\cdot, 1 ; \theta) + 0.5772 - \ln (P(\cdot ; \theta))\Big]
\end{array}
\right]
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Or more compactly $$
V = \left[I - \beta \ \sum_a P_a .* T_a \right]^{-1} \ * \ \left( \sum_a P_a \ .* \ \bigg[ u_a + 0.5772 - \ln(P_d) \bigg] \right)
$$&lt;/p&gt;
&lt;h3 id=&#34;first-equation&#34;&gt;First Equation&lt;/h3&gt;
&lt;p&gt;What is the first equation? $$
V = \left[I - \beta \ \sum_a P_a .* T_a \right]^{-1} \ * \ \left( \sum_a P_a \ .* \ \bigg[ u_a + 0.5772 - \ln(P_a) \bigg] \right)
$$ &lt;strong&gt;Expected static payoff&lt;/strong&gt;:
$\sum_a P_a \ .* \ \bigg[ u_a + 0.5772 + \ln(P_a) \bigg]$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is the expected static payoff of choice $a$ in each state,
$u_a + 0.5772 + \ln(P_a)$&lt;/li&gt;
&lt;li&gt;… integrated over the choice probabilities, $P_a$&lt;/li&gt;
&lt;li&gt;It’s a $k \times 1$ vector&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Unconditional transition probabilities&lt;/strong&gt;: $\sum_a P_a .* T_a$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are the transition probabilities conditional on a choice $a$ for
every present and future state, $T_a$&lt;/li&gt;
&lt;li&gt;… integrated over the choice probabilities, $P_a$&lt;/li&gt;
&lt;li&gt;It’s a $k \times k$ matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;recap&#34;&gt;Recap&lt;/h3&gt;
&lt;p&gt;We got our first equation $$
{\color{red}{V}} = \left[I - \beta \ \sum_a {\color{blue}{P_a}} .* T_a \right]^{-1} \ * \ \left( \sum_a {\color{blue}{P_a}} \ .* \ \bigg[ u_a + 0.5772 - \ln({\color{blue}{P_a}}) \bigg] \right)
$$&lt;/p&gt;
&lt;p&gt;I.e. $$
\begin{align}
{\color{red}{V(s ; \theta)}} &amp;amp; = h( {\color{blue}{P(s ; \theta)}} ; \theta) \newline
\end{align}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What about the second equation
${\color{blue}{P(\cdot|s ; \theta)}} = g({\color{red}{V(s ; \theta)}}; \theta)$?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;from-v-to-p&#34;&gt;From V to P&lt;/h3&gt;
&lt;p&gt;In general, the expected probability of investment is $$
P(a=1; \theta)= \Pr \left[\begin{array}{c}
u(\cdot, 1 ; \theta)+\epsilon_{1 t}+\beta \mathbb E \Big[V(\cdot ; \theta) \Big| \cdot, a_{t}=1 ; \theta \Big]&amp;gt; \newline \qquad
u(\cdot, 0 ; \theta) + \epsilon_{0 t}+\beta \mathbb E \Big[V(\cdot ; \theta) \Big| \cdot, a_{t}=0 ; \theta \Big]
\end{array}\right]
$$&lt;/p&gt;
&lt;p&gt;With the &lt;strong&gt;logit assumption&lt;/strong&gt;, simplifies to $$
{\color{blue}{P(a=1 ; \theta)}} = \frac{\exp \Big(u(\cdot, 1 ; \theta)+\beta T(1 ; \theta) V(\cdot ; \theta) \Big)}{\sum_{a&amp;rsquo;} \exp \Big(u(\cdot, a&amp;rsquo; ; \theta)+\beta T(a&amp;rsquo; ; \theta) V(\cdot ; \theta) \Big)} = \frac{\exp (u_1 +\beta T_1 {\color{red}{V}} )}{\sum_{a&amp;rsquo;} \exp (u_{a&amp;rsquo;} +\beta T_{a&amp;rsquo;} {\color{red}{V}} )}
$$&lt;/p&gt;
&lt;p&gt;Now we have also the second equation! $$
\begin{align}
{\color{blue}{P(s ; \theta)}} &amp;amp; = g({\color{red}{V(s ; \theta)}}; \theta)
\end{align}
$$&lt;/p&gt;
&lt;h3 id=&#34;hotz--miller---idea-2&#34;&gt;Hotz &amp;amp; Miller - Idea 2&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Idea 2&lt;/strong&gt;: Replace ${\color{blue}{P} (\cdot)}$ on the RHS with a
&lt;em&gt;consistent&lt;/em&gt; estimator ${\color{Turquoise}{\hat P (\cdot)}}$ $$
{\color{cyan}{\bar P(\cdot ; \theta)}} = g(h({\color{Turquoise}{\hat P(\cdot)}} ; \theta); \theta)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;${\color{cyan}{\bar P(\cdot ; \theta_0)}}$ will converge to the true
${\color{blue}{P(\cdot ; \theta_0)}}$, because
${\color{Turquoise}{\hat P (\cdot)}}$ is converging to
${\color{blue}{P(\cdot ; \theta_0)}}$ asymptotically.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: pay attention to $\theta_0$ vs $\theta$ here:
${\color{cyan}{\bar P(\cdot ; \theta)}}$ does &lt;strong&gt;not&lt;/strong&gt; generally
converge to ${\color{blue}{P(\cdot ; \theta)}}$for arbitrary
$\theta$, because ${\color{Turquoise}{\hat P(\cdot)}}$ is
converging to ${\color{blue}{P(\cdot ; \theta_0)}}$ but &lt;strong&gt;not&lt;/strong&gt;
${\color{blue}{P(\cdot ; \theta)}}$ with any $\theta$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How to compute ${\color{Turquoise}{\hat P(\cdot)}}$?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the data, you observe states and decisions&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can compute frequency of decisions given states&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In Rust: frequency of engine replacement, given a mileage
(discretized)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Assumption&lt;/strong&gt;: you have enough data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What if a state is not realised?&lt;/li&gt;
&lt;li&gt;Use frequencies in &lt;em&gt;observed&lt;/em&gt; states to extrapolate frequencies
in &lt;em&gt;unobserved&lt;/em&gt; states&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;recap-1&#34;&gt;Recap&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt; so far&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Estimate the &lt;strong&gt;conditional choice probabilities&lt;/strong&gt;
${\color{Turquoise}{\hat P}}$ from the data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nonparametrically: frequency of each decision in each state&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solve for the expected value function with the inverstion step $$
{\color{orange}{\hat V}} = \left[I - \beta \ \sum_a  {\color{Turquoise}{\hat P_a}} .* T_a \right]^{-1} \ * \ \left( \sum_a {\color{Turquoise}{\hat P_a}} \ .* \ \bigg[ u_a + 0.5772 - \ln({\color{Turquoise}{\hat P_a}}) \bigg] \right)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the &lt;strong&gt;predicted CCP&lt;/strong&gt;, given $V$ $$
{\color{cyan}{\bar P(a=1 ; \theta)}} = \frac{\exp (u_1 +\beta T_1 {\color{orange}{\hat V}} )}{\sum_{a&amp;rsquo;} \exp (u_{a&amp;rsquo;} +\beta T_{a&amp;rsquo;} {\color{orange}{\hat V}} )}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;What now? Use the estimated CCP to build an objective function.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;objective-function&#34;&gt;Objective Function&lt;/h3&gt;
&lt;p&gt;We have (at least) 2 options&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hotz and Miller (&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;) use GMM&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\mathbb E \Big[a_t - \bar P(s_t, \theta) \ \Big| \ s_t \Big] = 0 \quad \text{ at } \quad \theta = \theta_0
$$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Aguirregabiria and Mira (&lt;a href=&#34;#ref-aguirregabiria2002swapping&#34;&gt;2002&lt;/a&gt;)
use MLE
&lt;ul&gt;
&lt;li&gt;by putting $\bar P(s_t, \theta)$ in the likelihood function
instead of $P(s_t, \theta)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will follow the second approach&lt;/p&gt;
&lt;h3 id=&#34;pseudo-likelihood&#34;&gt;Pseudo-Likelihood&lt;/h3&gt;
&lt;p&gt;The likelihood function for one bus is $$
\mathcal{L}(\theta) = \prod_{t=1}^{T}\left(\hat{\operatorname{Pr}}\left(a=1 \mid s_{t}; \theta\right) \mathbb{1}\left(a_{t}=1\right)+\left(1-\hat{\operatorname{Pr}}\left(a=0 \mid s_{t}; \theta\right)\right) \mathbb{1}\left(a_{t}=0\right)\right)
$$ where $\hat \Pr\big(a_{t} \big| s_{t} ; \theta \big)$ is a function
of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CCPs $\hat P$: estimated from data&lt;/li&gt;
&lt;li&gt;transition matrix $T$: estimated from the data, given $\theta$&lt;/li&gt;
&lt;li&gt;static payoffs $u$: known, given $\theta$&lt;/li&gt;
&lt;li&gt;discount factor $\beta$ : assumed&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Why &lt;strong&gt;pseudo-likelihood&lt;/strong&gt;? We have inputed something that is not a
primitive but a consistent estimate of an equilibrium object, $\hat P$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Now a few comments on Hotz and Miller (&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computational bottleneck&lt;/li&gt;
&lt;li&gt;Aguirregabiria and Mira (&lt;a href=&#34;#ref-aguirregabiria2002swapping&#34;&gt;2002&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Importance of the T1EV assumption&lt;/li&gt;
&lt;li&gt;Data requirements&lt;/li&gt;
&lt;li&gt;Unobserved heterogeneity&lt;/li&gt;
&lt;li&gt;Identification&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;computational-bottleneck&#34;&gt;Computational Bottleneck&lt;/h3&gt;
&lt;p&gt;There is still 1 computational &lt;strong&gt;bottleneck&lt;/strong&gt; in HM: the inversion step
$$
V = \left[I - \beta \ \sum_a P_a .* T_a \right]^{-1} \ * \ \left( \sum_a P_a \ .* \ \bigg[ u_a + 0.5772 - \ln(P_a) \bigg] \right)
$$ The $\left[I - \beta \ \sum_a P_a .* T_a \right]$ matrix has
dimension $k \times k$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;With large state space, hard to invert&lt;/li&gt;
&lt;li&gt;Even with modern computational power&lt;/li&gt;
&lt;li&gt;Hotz et al. (&lt;a href=&#34;#ref-hotz1994simulation&#34;&gt;1994&lt;/a&gt;): forward simulation of
the value function
&lt;ul&gt;
&lt;li&gt;You have the policy, the transitions and the utilities&lt;/li&gt;
&lt;li&gt;Just compute discounted flow of payoffs&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Core&lt;/strong&gt; idea behind the estimation of dynamic games&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aguirregabiria-mira-2002&#34;&gt;Aguirregabiria, Mira (2002)&lt;/h3&gt;
&lt;p&gt;Hotz and Miller (&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;) inversion gets us a
recursive equation in &lt;strong&gt;probability space&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;instead of the Bellman Equation in the &lt;strong&gt;value space&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\bar P(\cdot ; \theta) = g(h(\hat P(\cdot) ; \theta); \theta)
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Idea&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do you gain something by iterating $K$ imes?
&lt;ul&gt;
&lt;li&gt;$K=1$: Hotz and Miller (&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;$K \to \infty$: Rust (&lt;a href=&#34;#ref-rust1987optimal&#34;&gt;1987&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Monte Carlo simulations&lt;/strong&gt;: finite sample properties of K−stage
estimators improve monotonically with K
&lt;ul&gt;
&lt;li&gt;But especially for $K=2$!&lt;/li&gt;
&lt;li&gt;Really &lt;strong&gt;worth iterating once&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;type-1-ev-errors&#34;&gt;Type 1 EV errors&lt;/h3&gt;
&lt;p&gt;Crucial assumption&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Without logit errors, we need to simulate their distribution&lt;/li&gt;
&lt;li&gt;True also for Rust&lt;/li&gt;
&lt;li&gt;But it’s generally accepted
&lt;ul&gt;
&lt;li&gt;doesn’t imply it’s innocuous&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-requirements&#34;&gt;Data Requirements&lt;/h3&gt;
&lt;p&gt;For both Hotz et al. (&lt;a href=&#34;#ref-hotz1994simulation&#34;&gt;1994&lt;/a&gt;) and Rust
(&lt;a href=&#34;#ref-rust1987optimal&#34;&gt;1987&lt;/a&gt;), we need to &lt;strong&gt;discretize the state
space&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can be complicated with continuous variables&lt;/li&gt;
&lt;li&gt;Problem also in Rust&lt;/li&gt;
&lt;li&gt;But particularly problematic in Hotz et al.
(&lt;a href=&#34;#ref-hotz1994simulation&#34;&gt;1994&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Relies crucially on consistency of CCP estimates&lt;/li&gt;
&lt;li&gt;Need sufficient &lt;strong&gt;variation in actions for each state&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;unobserved-heterogeneity&#34;&gt;Unobserved Heterogeneity&lt;/h3&gt;
&lt;p&gt;Hotz et al. (&lt;a href=&#34;#ref-hotz1994simulation&#34;&gt;1994&lt;/a&gt;) cannot handle unobserved
heterogeneity or “unobserved state variables” that are persistent over
time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Suppose there are 2 bus types $\tau$: high and low quality&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We &lt;strong&gt;don’t know the share&lt;/strong&gt; of types in the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With Rust&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Parametrize the effect of the difference in qualities&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;E.g. high quality engines break less often&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parametrize the proportion of high quality buses&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solve the value function by type $V(s_t, \tau ; \theta)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Integrate over types when computing choice probabilities $$
P(a|s) = \int P(a|s,\tau) P(\tau) =  \Pr(a|s, \tau=0) * \Pr(\tau=0) + \Pr(a|s, \tau=1) * \Pr(\tau=1)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;unobserved-heterogeneity-2&#34;&gt;Unobserved Heterogeneity (2)&lt;/h3&gt;
&lt;p&gt;What is the problem with Hotz et al. (&lt;a href=&#34;#ref-hotz1994simulation&#34;&gt;1994&lt;/a&gt;)?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The unobserved heterogeneity generates &lt;strong&gt;persistency in choices&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I don’t replace today because it’s high quality, but I also
probably don’t replace tomorrow either&lt;/li&gt;
&lt;li&gt;Decisions independent across time &lt;strong&gt;only conditional on type&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Likelihood of decisions must be integrated over types $$
\mathcal L (\theta) = \sum_{\tau_a} \prod_{t=1}^{T} \Pr (a_{jt}| s_{jt}, \tau_a) \Pr(\tau_a)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hotz &amp;amp; Miller needs &lt;strong&gt;consistent estimates&lt;/strong&gt; of $P(a, s, \tau)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Difficult when $\tau$ is not observed!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;identification&#34;&gt;Identification&lt;/h3&gt;
&lt;p&gt;Work on identification&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rust (&lt;a href=&#34;#ref-rust1994structural&#34;&gt;1994&lt;/a&gt;) and Magnac and Thesmar
(&lt;a href=&#34;#ref-magnac2002identifying&#34;&gt;2002&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Rust (&lt;a href=&#34;#ref-rust1987optimal&#34;&gt;1987&lt;/a&gt;) is non-paramentrically
underidentified $\to$ parametric assumptions are essential&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aguirregabiria and Suzuki
(&lt;a href=&#34;#ref-aguirregabiria2014identification&#34;&gt;2014&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Kalouptsidi, Scott, and Souza-Rodrigues
(&lt;a href=&#34;#ref-kalouptsidi2017non&#34;&gt;2017&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Abbring and Daljord (&lt;a href=&#34;#ref-abbring2020identifying&#34;&gt;2020&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Can identify discount factor with some “instrument” that shifts
future utilities but not current payoff&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kalouptsidi et al. (&lt;a href=&#34;#ref-kalouptsidi2020partial&#34;&gt;2020&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;references-references&#34;&gt;References [references]&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;
markdown=&#34;1&#34;&gt;
&lt;div id=&#34;ref-abbring2020identifying&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Abbring, Jaap H, and Øystein Daljord. 2020. “Identifying the Discount
Factor in Dynamic Discrete Choice Models.” &lt;em&gt;Quantitative Economics&lt;/em&gt; 11
(2): 471–501.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-aguirregabiria2002swapping&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Aguirregabiria, Victor, and Pedro Mira. 2002. “Swapping the Nested Fixed
Point Algorithm: A Class of Estimators for Discrete Markov Decision
Models.” &lt;em&gt;Econometrica&lt;/em&gt; 70 (4): 1519–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-aguirregabiria2014identification&#34; class=&#34;csl-entry&#34;
markdown=&#34;1&#34;&gt;
&lt;p&gt;Aguirregabiria, Victor, and Junichi Suzuki. 2014. “Identification and
Counterfactuals in Dynamic Models of Market Entry and Exit.”
&lt;em&gt;Quantitative Marketing and Economics&lt;/em&gt; 12 (3): 267–304.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-becker1988theory&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Becker, Gary S, and Kevin M Murphy. 1988. “A Theory of Rational
Addiction.” &lt;em&gt;Journal of Political Economy&lt;/em&gt; 96 (4): 675–700.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-berry1992estimation&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Berry, Steven T. 1992. “Estimation of a Model of Entry in the Airline
Industry.” &lt;em&gt;Econometrica: Journal of the Econometric Society&lt;/em&gt;, 889–917.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-bresnahan1989empirical&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Bresnahan, Timothy F. 1989. “Empirical Studies of Industries with Market
Power.” &lt;em&gt;Handbook of Industrial Organization&lt;/em&gt; 2: 1011–57.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-crawford2005uncertainty&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Crawford, Gregory S, and Matthew Shum. 2005. “Uncertainty and Learning
in Pharmaceutical Demand.” &lt;em&gt;Econometrica&lt;/em&gt; 73 (4): 1137–73.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-erdem2003brand&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Erdem, Tülin, Susumu Imai, and Michael P Keane. 2003. “Brand and
Quantity Choice Dynamics Under Price Uncertainty.” &lt;em&gt;Quantitative
Marketing and Economics&lt;/em&gt; 1 (1): 5–64.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-erdem1996decision&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Erdem, Tülin, and Michael P Keane. 1996. “Decision-Making Under
Uncertainty: Capturing Dynamic Brand Choice Processes in Turbulent
Consumer Goods Markets.” &lt;em&gt;Marketing Science&lt;/em&gt; 15 (1): 1–20.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-golosov2006new&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Golosov, Mikhail, Aleh Tsyvinski, Ivan Werning, Peter Diamond, and
Kenneth L Judd. 2006. “New Dynamic Public Finance: A User’s Guide [with
Comments and Discussion].” &lt;em&gt;NBER Macroeconomics Annual&lt;/em&gt; 21: 317–87.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gowrisankaran2012dynamics&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Gowrisankaran, Gautam, and Marc Rysman. 2012. “Dynamics of Consumer
Demand for New Durable Goods.” &lt;em&gt;Journal of Political Economy&lt;/em&gt; 120 (6):
1173–1219.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-handel2013adverse&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Handel, Benjamin R. 2013. “Adverse Selection and Inertia in Health
Insurance Markets: When Nudging Hurts.” &lt;em&gt;American Economic Review&lt;/em&gt; 103
(7): 2643–82.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hendel2006measuring&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Hendel, Igal, and Aviv Nevo. 2006. “Measuring the Implications of Sales
and Consumer Inventory Behavior.” &lt;em&gt;Econometrica&lt;/em&gt; 74 (6): 1637–73.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hotz1993conditional&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Hotz, V Joseph, and Robert A Miller. 1993. “Conditional Choice
Probabilities and the Estimation of Dynamic Models.” &lt;em&gt;The Review of
Economic Studies&lt;/em&gt; 60 (3): 497–529.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hotz1994simulation&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Hotz, V Joseph, Robert A Miller, Seth Sanders, and Jeffrey Smith. 1994.
“A Simulation Estimator for Dynamic Models of Discrete Choice.” &lt;em&gt;The
Review of Economic Studies&lt;/em&gt; 61 (2): 265–89.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-igami2020artificial&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Igami, Mitsuru. 2020. “Artificial Intelligence as Structural Estimation:
Deep Blue, Bonanza, and AlphaGo.” &lt;em&gt;The Econometrics Journal&lt;/em&gt; 23 (3):
S1–24.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-imai2009bayesian&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Imai, Susumu, Neelam Jain, and Andrew Ching. 2009. “Bayesian Estimation
of Dynamic Discrete Choice Models.” &lt;em&gt;Econometrica&lt;/em&gt; 77 (6): 1865–99.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kalouptsidi2020partial&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Kalouptsidi, Myrto, Yuichi Kitamura, Lucas Lima, and Eduardo A
Souza-Rodrigues. 2020. “Partial Identification and Inference for Dynamic
Models and Counterfactuals.” National Bureau of Economic Research.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kalouptsidi2017non&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Kalouptsidi, Myrto, Paul T Scott, and Eduardo Souza-Rodrigues. 2017. “On
the Non-Identification of Counterfactuals in Dynamic Discrete Games.”
&lt;em&gt;International Journal of Industrial Organization&lt;/em&gt; 50: 362–71.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-keane1997career&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Keane, Michael P, and Kenneth I Wolpin. 1997. “The Career Decisions of
Young Men.” &lt;em&gt;Journal of Political Economy&lt;/em&gt; 105 (3): 473–522.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-magnac2002identifying&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Magnac, Thierry, and David Thesmar. 2002. “Identifying Dynamic Discrete
Decision Processes.” &lt;em&gt;Econometrica&lt;/em&gt; 70 (2): 801–16.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pakes1986patents&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Pakes, Ariel. 1986. “Patents as Options: Some Estimates of the Value of
Holding European Patent Stocks.” &lt;em&gt;Econometrica&lt;/em&gt; 54 (4): 755–84.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rust1987optimal&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Rust, John. 1987. “Optimal Replacement of GMC Bus Engines: An Empirical
Model of Harold Zurcher.” &lt;em&gt;Econometrica: Journal of the Econometric
Society&lt;/em&gt;, 999–1033.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rust1988maximum&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;———. 1988. “Maximum Likelihood Estimation of Discrete Control
Processes.” &lt;em&gt;SIAM Journal on Control and Optimization&lt;/em&gt; 26 (5): 1006–24.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rust1994structural&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;———. 1994. “Structural Estimation of Markov Decision Processes.”
&lt;em&gt;Handbook of Econometrics&lt;/em&gt; 4: 3081–3143.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2012constrained&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Su, Che-Lin, and Kenneth L Judd. 2012. “Constrained Optimization
Approaches to Estimation of Structural Models.” &lt;em&gt;Econometrica&lt;/em&gt; 80 (5):
2213–30.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic Games</title>
      <link>https://matteocourthoud.github.io/course/empirical-io/08_dynamics_games/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/course/empirical-io/08_dynamics_games/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;intro&#34;&gt;Intro&lt;/h3&gt;
&lt;p&gt;Setting: agents making &lt;strong&gt;strategic decisions&lt;/strong&gt; (new) in &lt;strong&gt;dynamic
environments&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Entry and exit: Collard-Wexler (&lt;a href=&#34;#ref-collard2013demand&#34;&gt;2013&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Sunk costs: Ryan (&lt;a href=&#34;#ref-ryan2012costs&#34;&gt;2012&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Innovation: Goettler and Gordon (&lt;a href=&#34;#ref-goettler2011does&#34;&gt;2011&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;(or whatever changes in response to investment)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Exploitation of natural resources: Huang and Smith
(&lt;a href=&#34;#ref-huang2014dynamic&#34;&gt;2014&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Durable goods: Esteban and Shum (&lt;a href=&#34;#ref-esteban2007durable&#34;&gt;2007&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Lit review&lt;/strong&gt;: forthcoming IO Handbook chapter Aguirregabiria,
Collard-Wexler, and Ryan (&lt;a href=&#34;#ref-aguirregabiria2021dynamic&#34;&gt;2021&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;single--vs-multi-agent&#34;&gt;Single- vs Multi-Agent&lt;/h3&gt;
&lt;p&gt;Typically in IO we study agents in &lt;strong&gt;strategic&lt;/strong&gt; environments.
Complicated in dynamic environments.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Curse of dimensionality&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Single agent: need to track what the agent sees ($k$ states)&lt;/li&gt;
&lt;li&gt;Multi-agent: need to keep track what every agent sees
($k^J$states)&lt;/li&gt;
&lt;li&gt;Difference exponential in the number of agents&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Expectations&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Need not only to keep track of how the environment evolves&lt;/li&gt;
&lt;li&gt;… but also of how other players act&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Equilibrium&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Because of the strategic interaction, the Bellman equation is
&lt;em&gt;not a contraction&lt;/em&gt; anymore
&lt;ul&gt;
&lt;li&gt;Equilibrium existence?&lt;/li&gt;
&lt;li&gt;Equilibrium uniqueness?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;plan&#34;&gt;Plan&lt;/h3&gt;
&lt;p&gt;We will cover &lt;strong&gt;first the estimation&lt;/strong&gt; and then the computation of
dynamic games&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Weird…&lt;/li&gt;
&lt;li&gt;Standard estimation method: Bajari, Benkard, and Levin
(&lt;a href=&#34;#ref-bajari2007estimating&#34;&gt;2007&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Does &lt;strong&gt;not&lt;/strong&gt; require to solve the model&lt;/li&gt;
&lt;li&gt;Indeed, that’s the &lt;strong&gt;advantage&lt;/strong&gt; of the method&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;: still need to solve the model for counterfactuals&lt;/li&gt;
&lt;li&gt;So we’ll cover computation afterwards&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Last&lt;/strong&gt;: bridge between Structural IO and Artificial Intelligence&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Different &lt;em&gt;objectives&lt;/em&gt; but similar &lt;em&gt;methods&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Dynamic tools niche in IO but at the core of AI&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bajari-benkard-levin-2008&#34;&gt;Bajari, Benkard, Levin (2008)&lt;/h2&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;Stylized version of Ericson and Pakes (&lt;a href=&#34;#ref-ericson1995markov&#34;&gt;1995&lt;/a&gt;)
(no entry/exit)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$J$ firms (products) indexed by $j \in \lbrace 1, &amp;hellip;, J \rbrace$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Time $t$ is dicrete, horizon is infinite&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;States&lt;/strong&gt; $s_{jt} \in \lbrace 1, &amp;hellip; \bar s \rbrace$: quality of
product $j$ in period $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt; $a_{jt} \in \mathbb R^+$: investment decision of firm
$j$ in period $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Static payoffs&lt;/strong&gt; $$
\pi_j (s_{jt}, \boldsymbol s_{-jt}, a_{jt}; \theta^\pi)
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\boldsymbol s_{-it}$: state vector of all other firms in period
$t$&lt;/li&gt;
&lt;li&gt;$\theta^\pi$: parameters that govern static profits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: if we micro-fund $\pi(\cdot)$ , e.g. with some demand and
supply model, we have 2 strategic decisions: prices (static) and
investment (dynamic).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;model-2&#34;&gt;Model (2)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;State transitions&lt;/strong&gt; $$
\boldsymbol s_{t+1} = f(\boldsymbol s_t, \boldsymbol a_t, \boldsymbol \epsilon_t; \theta^f)
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\boldsymbol a_t$: vector of actions of all firm&lt;/li&gt;
&lt;li&gt;$\boldsymbol \epsilon_t$: vector of idiosyncratic shocks&lt;/li&gt;
&lt;li&gt;$\theta^f$: parameters that govern state transitions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Objective function&lt;/strong&gt;: firms maximize expected discounted future
profits $$
\max_{\boldsymbol a} \ \mathbb E_t \left[ \sum_{\tau=0}^\infty \beta^{\tau} \pi_{j, t+\tau} (\theta^\pi) \right]
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;value-function&#34;&gt;Value Function&lt;/h3&gt;
&lt;p&gt;The value function of firm $j$ at time $t$ in state $\boldsymbol s_{t}$,
under a set of strategy functions $\boldsymbol P$ (one for each firm) is
$$
V^{\boldsymbol P_{-j}}&lt;em&gt;{j} (\mathbf{s}&lt;/em&gt;{t}) = \max_{a_{jt} \in \mathcal{A}&lt;em&gt;j \left(\mathbf{s}&lt;/em&gt;{t}\right)} \Bigg\lbrace \pi_{j}^{\boldsymbol P_{-j}} (a_{jt}, \mathbf{s}&lt;em&gt;{t} ; \theta^\pi ) + \beta \mathbb E&lt;/em&gt;{\boldsymbol s_{t+1}} \Big[  V_{j}^{\boldsymbol P_{-j}} \left(\mathbf{s}&lt;em&gt;{t+1}\right) \ \Big| \ a&lt;/em&gt;{jt}, \boldsymbol s_{t} ; \theta^f \Big] \Bigg\rbrace
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\pi_{j}^{\boldsymbol P_{-j}} (a_{jt}, \mathbf{s}&lt;em&gt;{t} ; \theta^\pi )$
are the static profits of firm $j$ given action $a&lt;/em&gt;{jt}$ and policy
functions $\boldsymbol P_{-j}$ for all firms a part from $j$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The expecation $\mathbb E$ is taken with respect to the conditional
transition probabilities
$f^{\boldsymbol P_{-j}} (\mathbf{s}&lt;em&gt;{t+1} | \mathbf{s}&lt;/em&gt;{t}, a_{jt} ; \theta^f)$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;equilibrium&#34;&gt;Equilibrium&lt;/h3&gt;
&lt;p&gt;Equillibrium notion: &lt;strong&gt;Markow Perfect Equilibrium&lt;/strong&gt; (&lt;a href=&#34;#ref-maskin1988theory&#34;&gt;Maskin and Tirole
1988&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Assumption&lt;/strong&gt;: players’ strategies at period $t$ are functions only
of payoff-relevant state variables at the same period&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: a set of $J$ value and policy functions,
$\boldsymbol V$ and $\boldsymbol P$ such that each firm
&lt;ol&gt;
&lt;li&gt;maximizes its value function $V_j$&lt;/li&gt;
&lt;li&gt;given the policy function of every other firm
$\boldsymbol P_{-j}$&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What is it basically?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nash Equilibrium in the policy functions&lt;/li&gt;
&lt;li&gt;What are we ruling out?
&lt;ul&gt;
&lt;li&gt;Strategies that depend on longer histories&lt;/li&gt;
&lt;li&gt;E.g. “has anyone ever cheated in a cartel?”&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;estimation&#34;&gt;Estimation&lt;/h3&gt;
&lt;p&gt;We want to estimate 2 sets of &lt;strong&gt;parameters&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\theta^\pi$: parameterizes period profit function $\pi(\cdot)$&lt;/li&gt;
&lt;li&gt;$\theta^f$: parameterizes state transition function $f(\cdot)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generally 2 &lt;strong&gt;approaches&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Full solution
&lt;ul&gt;
&lt;li&gt;Impractical (we’ll see more details later)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rely on some sort of Hotz and Miller
(&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;) CCP inversion
&lt;ul&gt;
&lt;li&gt;Aguirregabiria and Mira
(&lt;a href=&#34;#ref-aguirregabiria2007sequential&#34;&gt;2007&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Bajari, Benkard, and Levin (&lt;a href=&#34;#ref-bajari2007estimating&#34;&gt;2007&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Pakes, Ostrovsky, and Berry (&lt;a href=&#34;#ref-pakes2007simple&#34;&gt;2007&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Pesendorfer and Schmidt-Dengler
(&lt;a href=&#34;#ref-pesendorfer2008asymptotic&#34;&gt;2008&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;bbl-overview&#34;&gt;BBL Overview&lt;/h3&gt;
&lt;p&gt;Bajari, Benkard, and Levin (&lt;a href=&#34;#ref-bajari2007estimating&#34;&gt;2007&lt;/a&gt;) plan&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Estimate &lt;strong&gt;transition probabilities&lt;/strong&gt; and &lt;strong&gt;conditional choice
probabilities&lt;/strong&gt; from the data&lt;/li&gt;
&lt;li&gt;Use them to simulate the &lt;strong&gt;expected value function&lt;/strong&gt;, given a set of
parameters&lt;/li&gt;
&lt;li&gt;Use optimality of estimated choices to pin down static profit
parameters
&lt;ul&gt;
&lt;li&gt;I.e. repeat (2) for alternative strategies
&lt;ul&gt;
&lt;li&gt;By definition suboptimal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Estimating equation&lt;/strong&gt;: values implied by observed strategies
should be higher than values implied by alternative strategies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;bbl-first-stage&#34;&gt;BBL: First Stage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Estimate the &lt;strong&gt;transition probabilities&lt;/strong&gt;
$f ( \cdot | a_{jt}, \boldsymbol s_t; \hat \theta^f )$
&lt;ul&gt;
&lt;li&gt;I.e. what is the observed frequency of any state-to-state
transition?&lt;/li&gt;
&lt;li&gt;For any given action of firm $j$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;… and &lt;strong&gt;conditional choice probabilities&lt;/strong&gt;
$\hat P_j(\cdot | \boldsymbol s_t)$
&lt;ul&gt;
&lt;li&gt;I.e. what is the probability of each action, for each firm $j$
in each state $\boldsymbol s$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can be done &lt;strong&gt;non-parametrically&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;i.e. just observe frequencies&lt;/li&gt;
&lt;li&gt;Conditional on having enough data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: need to estimate transitions, conditional on each
state and action&lt;/li&gt;
&lt;li&gt;Problem with many states and actions, but especially with &lt;strong&gt;many
players&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Curse of dimensionality&lt;/li&gt;
&lt;li&gt;Number of states increases exponentially in number of
players&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: parametric assumptions would contradict the model for
the estimation of value/policy functions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;bbl-second-stage&#34;&gt;BBL: Second Stage&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;First step&lt;/strong&gt;: from transitions $f(\hat \theta^f)$ and CCPs
$\boldsymbol{\hat P}$ to values&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can use transitions and CCPs to simulate &lt;strong&gt;histories&lt;/strong&gt; (of length
$\tilde T$)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;of states
$\lbrace \boldsymbol{\tilde{s}&lt;em&gt;{\tau}} \rbrace&lt;/em&gt;{\tau = 1}^{\tilde T}$&lt;/li&gt;
&lt;li&gt;and actions
$\lbrace \boldsymbol{\tilde{a}&lt;em&gt;{\tau}} \rbrace&lt;/em&gt;{\tau = 1}^{\tilde T}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Given a parameter value $\tilde \theta^\pi$, we can compute &lt;strong&gt;static
payoffs&lt;/strong&gt;:
$\pi_{j}^{\boldsymbol {\hat{P}&lt;em&gt;{-j}}} \left( \tilde a&lt;/em&gt;{j\tau}, \boldsymbol{\tilde s}_{\tau} ; \tilde \theta^\pi \right)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simulated history + static payoffs = &lt;strong&gt;simulated value function&lt;/strong&gt; $$
{V}&lt;em&gt;{j}^{\boldsymbol {\hat{P}}} \left(\boldsymbol{s}&lt;/em&gt;{t} ; \tilde \theta^\pi \right) =  \sum_{\tau=0}^{\tilde T} \beta^{\tau} \pi_{j}^{\boldsymbol {\hat{P}&lt;em&gt;{-j}}} \left( \tilde a&lt;/em&gt;{j\tau}, \boldsymbol{\tilde s}_{\tau} ; \tilde \theta^\pi \right)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can average over many, e.g. $R$, simulated value functions to get
an &lt;strong&gt;expected value function&lt;/strong&gt; $$
{V}&lt;em&gt;{j}^{\boldsymbol {\hat{P}}, R} \left( \boldsymbol{s}&lt;/em&gt;{t} ; \tilde \theta^\pi \right) = \frac{1}{R}  \sum_{r=0}^{R}\Bigg( \sum_{\tau=0}^{\tilde T} \beta^{\tau} \pi_{j}^{\boldsymbol {\hat{P}&lt;em&gt;{-j}}} \left(\tilde a^{(r)}&lt;/em&gt;{j\tau}, \boldsymbol{\tilde s}^{(r)}_{\tau} ; \tilde \theta^\pi \right) \Bigg)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;in-practice-for-a-parameter-value-tilde-thetapi&#34;&gt;In practice, for a parameter value $\tilde \theta^\pi$&lt;/h3&gt;
&lt;p&gt;For $r = 1, &amp;hellip;, R$ simulations do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize firms value to zero&lt;/li&gt;
&lt;li&gt;Fot $\tau=0, &amp;hellip;, \tilde T$ do
&lt;ul&gt;
&lt;li&gt;For each state in $\boldsymbol{\tilde s}^{(r)}_{\tau}$ do:
&lt;ul&gt;
&lt;li&gt;Use $\boldsymbol{\hat P}$ to &lt;em&gt;draw&lt;/em&gt; a vector of firm actions
$\boldsymbol{\tilde a}^{(r)}_{\tau}$&lt;/li&gt;
&lt;li&gt;For each firm $j = 1, &amp;hellip;, J$ do:
&lt;ul&gt;
&lt;li&gt;Compute static profits
$\pi_{j}^{\boldsymbol {\hat{P}&lt;em&gt;{-j}}} \left(\tilde a^{(r)}&lt;/em&gt;{j\tau}, \boldsymbol{\tilde s}^{(r)}_{\tau} ; \tilde \theta^\pi \right)$&lt;/li&gt;
&lt;li&gt;Add discounted profits
$\beta^{\tau} \pi_{j}^{\boldsymbol {\hat{P}&lt;em&gt;{-j}}} \left(\tilde a^{(r)}&lt;/em&gt;{j\tau}, \boldsymbol{\tilde s}^{(r)}_{\tau} ; \tilde \theta^\pi \right)$
to the value function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use
$f ( \cdot | \boldsymbol {a_{t}}, \boldsymbol s_t; \hat \theta^f )$
to &lt;em&gt;draw&lt;/em&gt; the next state
$\boldsymbol{\tilde s}^{(r)}_{\tau + 1}$&lt;/li&gt;
&lt;li&gt;Use the next state, $\boldsymbol{\tilde s}^{(r)}_{\tau + 1}$
as current state for the next iteration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then average all the value functions together to obtain an &lt;strong&gt;expected
value function&lt;/strong&gt;
$V_{j}^{\boldsymbol {\hat{P}}, R} \left(\boldsymbol{s}_{t} ; \tilde \theta^\pi \right)$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: advantage of simulations: can be parallelized&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;objective-function&#34;&gt;Objective Function&lt;/h3&gt;
&lt;p&gt;What have we done so far?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given some parameters $\theta^\pi$, we computed the &lt;strong&gt;expected value
function&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How do we pick the $\theta^\pi$ that best rationalizes the data?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I.e. what is the &lt;strong&gt;objective function&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;Potentially many options&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;BBL idea&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the expected value function has to be optimal, given the CCPs&lt;/li&gt;
&lt;li&gt;I.e. any other policy function should give a lower expected value&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“Best”&lt;/strong&gt; $\theta^\pi$: those for which the implied expected value
function under the estimated CCPs is greater than the one implied by
&lt;em&gt;any other&lt;/em&gt; CCP&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: it’s an inequality statement&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;objective-function-2&#34;&gt;Objective Function (2)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Idea&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If the observed policy ${\color{green}{\boldsymbol{\hat P}}}$ is
optimal,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;All other policies ${\color{red}{\boldsymbol{\tilde P}}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;… at the true parameters $\theta^f$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;… should give a lower expected value $$
V_{j}^{{\color{red}{\boldsymbol{\tilde P}}}, R} \left( \boldsymbol{s}&lt;em&gt;{t} ; \tilde \theta^\pi \right) \leq V&lt;/em&gt;{j}^{{\color{green}{\boldsymbol{\hat P}}}, R} \left( \boldsymbol{s}_{t} ; \tilde \theta^\pi \right)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;So which are the true parameters?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Those for which any deviation from the observed policy
${\color{green}{\boldsymbol{\hat P}}}$ yields a lower value&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Objective function&lt;/strong&gt; to minimize: &lt;strong&gt;violations&lt;/strong&gt; under
alternative policies ${\color{red}{\boldsymbol{\tilde P}}}$ $$
\min_{\tilde \theta^\pi} \sum_{\boldsymbol s_{t}} \sum_{{\color{red}{\boldsymbol{\tilde P}}}} \Bigg[\min \bigg\lbrace V_{j}^{{\color{green}{\boldsymbol{\hat P}}}, R} \left( \boldsymbol{s}&lt;em&gt;{t} ; \tilde \theta^\pi \right) - V&lt;/em&gt;{j}^{{\color{red}{\boldsymbol{\tilde P}}}, R} \left( \boldsymbol{s}_{t} ; \tilde \theta^\pi \right) \ , \ 0 \bigg\rbrace \Bigg]^{2}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;estimator&#34;&gt;Estimator&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Estimator&lt;/strong&gt;: $\theta^\pi$ that minimizes the average (squared)
magnitude of violations for any alternative policy
${\color{red}{\boldsymbol{\tilde P}}}$ $$
\hat{\theta}^\pi= \arg \min_{\tilde \theta^\pi} \sum_{\boldsymbol s_{t}} \sum_{{\color{red}{\boldsymbol{\tilde P}}}} \Bigg[\min \bigg\lbrace V_{j}^{{\color{green}{\boldsymbol{\hat P}}}, R} \left( \boldsymbol{s}&lt;em&gt;{t} ; \tilde \theta^\pi \right) - V&lt;/em&gt;{j}^{{\color{red}{\boldsymbol{\tilde P}}}, R} \left( \boldsymbol{s}_{t} ; \tilde \theta^\pi \right) \ , \ 0 \bigg\rbrace \Bigg]^{2}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\min \Big\lbrace V_{j}^{{\color{green}{\boldsymbol{\hat P}}}, R} - V_j^{{\color{red}{\boldsymbol{\tilde P}}}, R} \ , \ 0 \Big\rbrace$
to pick only the violations
&lt;ul&gt;
&lt;li&gt;If ${\color{green}{\boldsymbol{\hat P}}}$ implies higher value,
we can ignore&lt;/li&gt;
&lt;li&gt;Doesn’t matter by how much you respect the inequality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Which alternative policies&lt;/strong&gt;
${\color{red}{\boldsymbol{\tilde P}}}$ should we use?
&lt;ul&gt;
&lt;li&gt;In principle, any perturbation is ok&lt;/li&gt;
&lt;li&gt;But &lt;strong&gt;in practice&lt;/strong&gt;, if we perturbe it too much, we can go too
far off&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tip 1&lt;/strong&gt;: start with very &lt;em&gt;small&lt;/em&gt; perturbations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tip 2&lt;/strong&gt;: use perturbation that &lt;em&gt;sensibly&lt;/em&gt; affect the dynamics
&lt;ul&gt;
&lt;li&gt;E.g. exiting in a state in which a firm is not a competitive
threat&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tip 3&lt;/strong&gt;: use perturbations on dimensions that are &lt;em&gt;relevant&lt;/em&gt;
for the research question
&lt;ul&gt;
&lt;li&gt;E.g. they affect dimensions where you want to make
counterfactual predictions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;advantages&#34;&gt;Advantages&lt;/h3&gt;
&lt;p&gt;We have seen that there are &lt;strong&gt;competing methods&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What are the &lt;strong&gt;advantages&lt;/strong&gt; of Bajari, Benkard, and Levin
(&lt;a href=&#34;#ref-bajari2007estimating&#34;&gt;2007&lt;/a&gt;) over those?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Continuous actions&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;BBL does not require actions to be discretised&lt;/li&gt;
&lt;li&gt;You can just sample actions from the data!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Choice of alternative CCPs&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The researcher is free to choose the alternative CCPs
${\color{red}{\boldsymbol{\tilde P}}}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: can make source of variation more transparent
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;allows the researcher to focus on those predictions of the
model that are key for the specific research questions&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: it’s a &lt;em&gt;very&lt;/em&gt; high dimensional space
&lt;ul&gt;
&lt;li&gt;There are &lt;em&gt;very very&lt;/em&gt; many alternative policy functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;problems&#34;&gt;Problems&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Computational &lt;strong&gt;curse of dimensionality&lt;/strong&gt; is gone (in the state
space)
&lt;ul&gt;
&lt;li&gt;But we have a curse of dimensionality in data&lt;/li&gt;
&lt;li&gt;Need a lot of markets because &lt;strong&gt;now 1 market is 1 observation&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multiple equilibria&lt;/strong&gt;??
&lt;ul&gt;
&lt;li&gt;We are basically assuming it away&lt;/li&gt;
&lt;li&gt;Estimating the CCPs in the first stage we assume that is the
equilibrium that is played in all markets at all times&lt;/li&gt;
&lt;li&gt;To run counterfactuals, we &lt;strong&gt;still need to solve the model&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unobserved heterogeneity
&lt;ul&gt;
&lt;li&gt;Kasahara and Shimotsu (&lt;a href=&#34;#ref-kasahara2009nonparametric&#34;&gt;2009&lt;/a&gt;):
how to identify the (minimum) number of unobserved types&lt;/li&gt;
&lt;li&gt;Arcidiacono and Miller
(&lt;a href=&#34;#ref-arcidiacono2011conditional&#34;&gt;2011&lt;/a&gt;): how to use an EM
algorithm for the 1st stage estimation with unobserved types,
conditional on the number of types&lt;/li&gt;
&lt;li&gt;Berry and Compiani (&lt;a href=&#34;#ref-berry2021empirical&#34;&gt;2021&lt;/a&gt;):
instrumental variables approach, relying on observed states in
the distant past&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-stationarity&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If we have a long time period, something fundamentally might
have changed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ericson-pakes-1995&#34;&gt;Ericson Pakes (1995)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Ericson and Pakes (&lt;a href=&#34;#ref-ericson1995markov&#34;&gt;1995&lt;/a&gt;) and companion paper
Pakes and McGuire (&lt;a href=&#34;#ref-pakes1994computing&#34;&gt;1994&lt;/a&gt;) for the computation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$J$ firms indexed by $j \in \lbrace 1, &amp;hellip;, J \rbrace$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Time $t$ is dicrete $t$, horizon is infinite&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;State $s_{jt}$: quality of firm $j$ in period $t$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Per period profits $$
\pi (s_{jt}, \boldsymbol s_{-jt}, ; \theta^\pi)
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\boldsymbol s_{-it}$: state vector of all other firms in period
$t$&lt;/li&gt;
&lt;li&gt;$\theta^\pi$: parameters that govern static profits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can micro-fund profits with some demand and supply functions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There can be some underlying static strategic interaction&lt;/li&gt;
&lt;li&gt;E.g. logit demand and bertrand competition in prices $p_{it}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;state-transitions&#34;&gt;State Transitions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Investment&lt;/strong&gt;: firms can invest an dollar amount $x$ to increase their
future quality&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Continuous decision variable ($\neq$ Rust)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Probability that investment is successful $$
\Pr \big(i_{jt} \ \big| \ a_{it} = x \big) = \frac{\alpha x}{1 + \alpha x}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Higher investment, higher success probability&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\alpha$ parametrizes the returns on investment&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Quality depreciation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;With probability $\delta$, quality decreases by one level&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Law of motion&lt;/strong&gt; $$
s_{j,t+1} = s_{jt} + i_{jt} - \delta
$$&lt;/p&gt;
&lt;h3 id=&#34;decision-variables&#34;&gt;Decision Variables&lt;/h3&gt;
&lt;p&gt;Note that in Ericson and Pakes (&lt;a href=&#34;#ref-ericson1995markov&#34;&gt;1995&lt;/a&gt;) we have
two separate decision variables&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Static&lt;/strong&gt; decision variable: price $p_{jt}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic&lt;/strong&gt; decision variable: investment $i_{jt}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Does not have to be the case!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Besanko et al. (&lt;a href=&#34;#ref-besanko2010learning&#34;&gt;2010&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model of &lt;strong&gt;learning-by-doing&lt;/strong&gt;: firms decrease their marginal cost
through sales&lt;/li&gt;
&lt;li&gt;State variable: firm stock of know how $e$
&lt;ul&gt;
&lt;li&gt;The higher the stock of know-how, the lower the marginal cost&lt;/li&gt;
&lt;li&gt;Increases when a firm manages to make a sale
&lt;ul&gt;
&lt;li&gt;$q \in [0,1]$ now is both static quantity and transition
probability&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Single&lt;/strong&gt; decision variable: price $p$
&lt;ul&gt;
&lt;li&gt;Usual static effects on profits
$\pi_{jt} = (p_{jt} - c(e_{jt})) \cdot q_j(\boldsymbol p_t)$&lt;/li&gt;
&lt;li&gt;But also dynamic effect through transition probabilities
&lt;ul&gt;
&lt;li&gt;Probability of increasing $e_t$: $q_j(\boldsymbol p_t)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;equilibrium-1&#34;&gt;Equilibrium&lt;/h3&gt;
&lt;p&gt;Firms maximize the expected flow of discounted profits $$
\max_{\boldsymbol a} \ \mathbb E_t \left[ \sum_{\tau=0}^\infty \beta^{\tau} \pi_{j, t+\tau} (\theta^\pi) \right]
$$ &lt;strong&gt;Markow Perfect Equilibrium&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Equillibrium notion: &lt;strong&gt;Markow Perfect Equilibrium&lt;/strong&gt; (&lt;a href=&#34;#ref-maskin1988theory&#34;&gt;Maskin and Tirole
1988&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A set of $J$ value and policy functions, $\boldsymbol V$ and
$\boldsymbol P$ such that each firm
&lt;ol&gt;
&lt;li&gt;maximizes its value function $V_j$&lt;/li&gt;
&lt;li&gt;given the policy function of every other firm
$\boldsymbol P_{-j}$&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;exit&#34;&gt;Exit&lt;/h3&gt;
&lt;p&gt;One important extension is &lt;strong&gt;exit&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In each time period, incuments decide whether to stay&lt;/li&gt;
&lt;li&gt;… or exit and get a scrap value $\phi^{exit}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Belman Equation of incumbent $j$ at time $t$ is $$
V^{\boldsymbol P_{-j}}&lt;em&gt;{j} (\mathbf{s}&lt;/em&gt;{t}) = \max_{d^{exit}&lt;em&gt;{jt} \in \lbrace 0, 1 \rbrace} \Bigg\lbrace
\begin{array}{c}
\beta \phi^{exit} \ , \newline
\max&lt;/em&gt;{a_{jt} \in \mathcal{A}&lt;em&gt;j \left(\mathbf{s}&lt;/em&gt;{t}\right)} \Big\lbrace  \pi_{j}^{\boldsymbol P_{-j}} (a_{jt}, \mathbf{s}&lt;em&gt;{t} ; \theta^\pi ) + \beta \mathbb E&lt;/em&gt;{\boldsymbol s_{t+1}} \Big[  V_{j}^{\boldsymbol P_{-j}} \left(\mathbf{s}&lt;em&gt;{t+1}\right) \ \Big| \ a&lt;/em&gt;{jt}, \boldsymbol s_{t} ; \theta^f \Big] \Big\rbrace
\end{array}
\Bigg\rbrace
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\phi^{exit}$: exit scrap value&lt;/li&gt;
&lt;li&gt;$d^{exit}_{jt} \in \lbrace 0,1 \rbrace$: exit decision&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;entry&#34;&gt;Entry&lt;/h3&gt;
&lt;p&gt;We can also incorporate endogenous &lt;strong&gt;entry&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One or more &lt;strong&gt;potential entrants&lt;/strong&gt; exist outside the market&lt;/li&gt;
&lt;li&gt;They can pay an entry cost $\phi^{entry}$ and enter the market at a
quality state $\bar s$&lt;/li&gt;
&lt;li&gt;… or remain outside at no cost&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Value function $$
V_{j}^{\boldsymbol P_{-j}} (e, \boldsymbol x_{-jt} ; \theta) = \max_{d^{entry} \in \lbrace 0,1 \rbrace }
\Bigg\lbrace
\begin{array}{c}
0 \ ; \newline&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;\phi^{entry} + \beta \mathbb E_{\boldsymbol s_{t+1}} \Big[ V_{j}^{\boldsymbol P_{-j}} (\bar s, \boldsymbol s_{-j, t+1} ; \theta) \ \Big| \ \boldsymbol s_{t} ; \theta^f \Big]
\end{array}
\Bigg\rbrace
$$ where&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$d^{entry} \in \lbrace 0,1 \rbrace$: entry decision&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\phi^{entry}$: entry cost&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\bar s$: state in which entrants enters (could be random)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Do we observe potential entrants?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Igami (&lt;a href=&#34;#ref-igami2017estimating&#34;&gt;2017&lt;/a&gt;): tech industry announce
their entry&lt;/li&gt;
&lt;li&gt;Critique: not really potential entrants, they are half-way inside&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;equilibrium-existence&#34;&gt;Equilibrium Existence&lt;/h3&gt;
&lt;p&gt;Doraszelski and Satterthwaite (&lt;a href=&#34;#ref-doraszelski2010computable&#34;&gt;2010&lt;/a&gt;):
a MPE might not exist in Ericson and Pakes
(&lt;a href=&#34;#ref-ericson1995markov&#34;&gt;1995&lt;/a&gt;) model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Replace fixed entry costs $\phi^{entry}$ and exit scrap values
$\phi^{exit}$ with random ones&lt;/li&gt;
&lt;li&gt;It becomes a game of incomplete information
&lt;ul&gt;
&lt;li&gt;First explored in Rust (&lt;a href=&#34;#ref-rust1994structural&#34;&gt;1994&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;New equilibrium concept&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Markov Perfect Bayesian Nash Equilibrium (MPBNE)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basically the same, with rational beliefs on random variables&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solving-the-model&#34;&gt;Solving the Model&lt;/h3&gt;
&lt;p&gt;Solving the model is very similar to Rust&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given parameter values $\theta$&lt;/li&gt;
&lt;li&gt;Start with a guess for the value and policy functions&lt;/li&gt;
&lt;li&gt;Until convergence, do:
&lt;ul&gt;
&lt;li&gt;For each firm $j = 1, &amp;hellip;, J$, do:
&lt;ul&gt;
&lt;li&gt;Take the policy functions of all other firms&lt;/li&gt;
&lt;li&gt;Compute the implied transition probabilities&lt;/li&gt;
&lt;li&gt;Use them to compute the new policy function for firm $j$&lt;/li&gt;
&lt;li&gt;Compute the implied value function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Where do things get complicated / tricky? Policy function update&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;policy-update-example-exit-game&#34;&gt;Policy Update Example: exit game&lt;/h3&gt;
&lt;p&gt;Imagine a stylized exit game with 2 firms&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easy to get an update rule of the form: &lt;em&gt;“exit if opponent stays,
stay if opponent exits”&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Computationally&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize policy functions to $(exit, exit)$&lt;/li&gt;
&lt;li&gt;Iteration 1:
&lt;ul&gt;
&lt;li&gt;Each firm takes opponent policy as given: $exit$&lt;/li&gt;
&lt;li&gt;Update own optimal policy: $stay$&lt;/li&gt;
&lt;li&gt;New policy: $(stay, stay)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Iteration 2: $(stay, stay) \to (exit, exit)$&lt;/li&gt;
&lt;li&gt;Iteration 2: $(exit, exit) \to (stay, stay)$&lt;/li&gt;
&lt;li&gt;Etc…&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Issues&lt;/strong&gt;: value function iteration might not converge and
equilibrium multeplicity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;convergence-tips&#34;&gt;Convergence Tips&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Try different &lt;strong&gt;starting values&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Often it’s what makes the biggest difference&lt;/li&gt;
&lt;li&gt;Ideally, start as close as possible to true values&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Approximation methods&lt;/strong&gt; can help (we’ll see more later)
&lt;ul&gt;
&lt;li&gt;I.e. get a fast approximation to use as starting vlaue for
solution algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Partial/stochastic &lt;strong&gt;value function update rule&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Instead of $V&amp;rsquo; = T(V)$, use $V&amp;rsquo; = \alpha T(V) + (1-\alpha)V$&lt;/li&gt;
&lt;li&gt;Very good to break loops, especially if $\alpha$ is stochastic,
e.g. $\alpha \sim U(0,1)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How large is the &lt;strong&gt;support of the entry/exit costs&lt;/strong&gt;?
&lt;ul&gt;
&lt;li&gt;If support is too small, you end up back in the entry/exit loop&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Try alternative &lt;strong&gt;non-parallel updating schemes&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;E.g. update value one state at the time (in random order?)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Last but not least: &lt;strong&gt;change the model&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;In particular, from simultaneous to alternating moves&lt;/li&gt;
&lt;li&gt;or continuous time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multiple-equilibria&#34;&gt;Multiple Equilibria&lt;/h3&gt;
&lt;p&gt;How to find them?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Besanko et al. (&lt;a href=&#34;#ref-besanko2010learning&#34;&gt;2010&lt;/a&gt;) and Borkovsky,
Doraszelski, and Kryukov (&lt;a href=&#34;#ref-borkovsky2010user&#34;&gt;2010&lt;/a&gt;):
&lt;strong&gt;homotopy method&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;can find some equilibria, but not all&lt;/li&gt;
&lt;li&gt;complicated to implement: need to compute first order conditions
$H(\boldsymbol V, \theta) = 0$ and their Jacobian
$\Delta H(\boldsymbol V, \theta)$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Idea&lt;/strong&gt;: trace the equilibrium correspondence
$H^{-1} = \lbrace (\boldsymbol V, \theta) : H(\boldsymbol V, \theta) = 0 \rbrace$
in the value-parameter space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Eibelshäuser and Poensgen (&lt;a href=&#34;#ref-eibelshauser2019markov&#34;&gt;2019&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Markov Quantal Response Equilibrium&lt;/li&gt;
&lt;li&gt;approact dynamic games from a evolutionary game theory
perspective
&lt;ul&gt;
&lt;li&gt;actions played at random and those bringing highest payoffs
survive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\to$ homothopy method guaranteed to find one equilibrium&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pesendorfer and Schmidt-Dengler
(&lt;a href=&#34;#ref-pesendorfer2010sequential&#34;&gt;2010&lt;/a&gt;): some equilibria are not
Lyapunov-stable
&lt;ul&gt;
&lt;li&gt;BR iteration cannot find them unless you start exactly at the
solution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Su and Judd (&lt;a href=&#34;#ref-su2012constrained&#34;&gt;2012&lt;/a&gt;) and Egesdal, Lai, and
Su (&lt;a href=&#34;#ref-egesdal2015estimating&#34;&gt;2015&lt;/a&gt;): same point, but numerically
&lt;ul&gt;
&lt;li&gt;using MPEC approach&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multiple-equilibria-2&#34;&gt;Multiple Equilibria (2)&lt;/h3&gt;
&lt;p&gt;Can we assume them away?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Igami (&lt;a href=&#34;#ref-igami2017estimating&#34;&gt;2017&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Finite horizon&lt;/li&gt;
&lt;li&gt;Homogenous firms (in profit functions and state transitions)&lt;/li&gt;
&lt;li&gt;One dynamic move per period (overall, not per-firm)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Abbring and Campbell (&lt;a href=&#34;#ref-abbring2010last&#34;&gt;2010&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Entry/exit game&lt;/li&gt;
&lt;li&gt;Homogeneous firms&lt;/li&gt;
&lt;li&gt;Entry and exit decisions are follow a last-in first-out (LIFO)
structure
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;“An entrant expects to produce no longer than any
incumbent”&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Iskhakov, Rust, and Schjerning (&lt;a href=&#34;#ref-iskhakov2016recursive&#34;&gt;2016&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;can find all equilibria, but for very specific class of dynamic
games&lt;/li&gt;
&lt;li&gt;must always proceed “forward”
&lt;ul&gt;
&lt;li&gt;e.g. either entry or exit but not both&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Idea: can solve by backward induction even if horizon is
infinite&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;curse-of-dimensionality&#34;&gt;Curse of Dimensionality&lt;/h3&gt;
&lt;p&gt;What are the computational bottlenecks? $$
V^{\boldsymbol P_{-j}}&lt;em&gt;{j} ({\color{red}{\mathbf{s}&lt;/em&gt;{t}}}) = \max_{a_{jt} \in \mathcal{A}&lt;em&gt;j \left(\mathbf{s}&lt;/em&gt;{t}\right)} \Bigg\lbrace \pi_{j}^{\boldsymbol P_{-j}} (a_{jt}, \mathbf{s}&lt;em&gt;{t} ; \theta^\pi ) + \beta \mathbb E&lt;/em&gt;{{\color{red}{\mathbf{s}&lt;em&gt;{t+1}}}} \Big[  V&lt;/em&gt;{j}^{\boldsymbol P_{-j}} \left(\mathbf{s}&lt;em&gt;{t+1}\right) \ \Big| \ a&lt;/em&gt;{jt}, \boldsymbol s_{t} ; \theta^f \Big] \Bigg\rbrace
$$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Dimension of the state space&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;In single agent problems, we have as many states as many values
of $s_{jt}$ ($k$)&lt;/li&gt;
&lt;li&gt;In dynamics games, the state space goes from $k$ to $k^J$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;symmetry helps&lt;/strong&gt;: state $[1,2,3]$ and $[1,3,2]$ become the
same for firm 1&lt;/li&gt;
&lt;li&gt;How much do we gain? From $k^J$ to
$k \cdot {k + J - 2 \choose k - 1}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dimension of the integrand&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If in single agent problems, we have to integrate over $\kappa$
outcomes,
&lt;ul&gt;
&lt;li&gt;4 in Rust: engine replaced (yes|no) $\times$ mileage
increases (yes|no)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;… in dynamic games, we have to consider $\kappa^J$ outcomes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: bottlenecks are not addittive but multiplicative: have to
solve the expectation for each point in the state space. Improving on
any of the two helps a lot.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;curse-of-dimensionality-2&#34;&gt;Curse of Dimensionality (2)&lt;/h3&gt;
&lt;p&gt;Two and a half classes of solutions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Computational&lt;/strong&gt;: approximate the equilibrium
&lt;ul&gt;
&lt;li&gt;Doraszelski (&lt;a href=&#34;#ref-doraszelski2003r&#34;&gt;2003&lt;/a&gt;): use Chebyshev
polynomials for a basis function&lt;/li&gt;
&lt;li&gt;Farias, Saure, and Weintraub
(&lt;a href=&#34;#ref-farias2012approximate&#34;&gt;2012&lt;/a&gt;): combine approximations
with a MPEC-like approach&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conceptual&lt;/strong&gt;: define another game
&lt;ul&gt;
&lt;li&gt;Weintraub, Benkard, and Van Roy
(&lt;a href=&#34;#ref-weintraub2008markov&#34;&gt;2008&lt;/a&gt;): oblivious equilibrium&lt;/li&gt;
&lt;li&gt;Ifrach and Weintraub (&lt;a href=&#34;#ref-ifrach2017framework&#34;&gt;2017&lt;/a&gt;): moment
based equilibrium&lt;/li&gt;
&lt;li&gt;Doraszelski and Judd (&lt;a href=&#34;#ref-doraszelski2012avoiding&#34;&gt;2012&lt;/a&gt;):
games in continuous time&lt;/li&gt;
&lt;li&gt;Doraszelski and Judd (&lt;a href=&#34;#ref-doraszelski2019dynamic&#34;&gt;2019&lt;/a&gt;):
games with random moves&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kind of both: Pakes and McGuire (&lt;a href=&#34;#ref-pakes2001stochastic&#34;&gt;2001&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;experience-based equilibrium (&lt;a href=&#34;#ref-fershtman2012dynamic&#34;&gt;Fershtman and Pakes
2012&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: useful also to get good starting values for a full solution
method!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;oblivious-equilibrium&#34;&gt;Oblivious Equilibrium&lt;/h3&gt;
&lt;p&gt;Weintraub, Benkard, and Van Roy (&lt;a href=&#34;#ref-weintraub2008markov&#34;&gt;2008&lt;/a&gt;): what
if &lt;strong&gt;firms had no idea about the state of other firms&lt;/strong&gt;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;or atomistic firms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The value function becomes $$
V_{j} ({\color{red}{s_{t}}}) = \max_{a_{jt} \in \mathcal{A}&lt;em&gt;j \left({\color{red}{s&lt;/em&gt;{t}}}\right)} \Bigg\lbrace {\color{red}{\mathbb E_{\boldsymbol s_t}}} \Big[ \pi_{j} (a_{jt}, \mathbf{s}&lt;em&gt;{t} ; \theta^\pi ) \Big|  P  \Big] + \beta \mathbb E&lt;/em&gt;{{\color{red}{s_{t+1}}}} \Big[  V_{j} \left({\color{red}{s_{t+1}}}\right) \ \Big| \ a_{jt}, {\color{red}{s_{t}}} ; \theta^f \Big] \Bigg\rbrace
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now the state is just $s_t$ instead of $\boldsymbol s_t$
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Huge&lt;/strong&gt; computational gain: from $k^J$ points to $k$&lt;/li&gt;
&lt;li&gt;Also the expectation of future states is taken over $3$ instead
of $3^J$ points
&lt;ul&gt;
&lt;li&gt;(3 because quality can go up, down or stay the same)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;But need to compute static profits as the expected value given the
current policy function
&lt;ul&gt;
&lt;li&gt;Need to keep track of the asymptotic state distribution as you
iterate the value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;games-with-random-moves&#34;&gt;Games with Random Moves&lt;/h3&gt;
&lt;p&gt;Doraszelski and Judd (&lt;a href=&#34;#ref-doraszelski2019dynamic&#34;&gt;2019&lt;/a&gt;): what if
instead of simultaneously, firms would &lt;strong&gt;move one at the time at
random&lt;/strong&gt;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Important&lt;/strong&gt;: to have the same frequency of play, &lt;strong&gt;a period now is
$J$ times shorter&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The value function becomes $$
V^{\boldsymbol P_{-j}}&lt;em&gt;{j} (\mathbf{s}&lt;/em&gt;{t}, {\color{red}{n=j}}) = \max_{a_{jt} \in \mathcal{A}&lt;em&gt;j \left(\mathbf{s}&lt;/em&gt;{t}\right)} \Bigg\lbrace {\color{red}{\frac{1}{J}}}\pi_{j}^{\boldsymbol P_{-j}} (a_{jt}, \mathbf{s}&lt;em&gt;{t} ; \theta^\pi ) + {\color{red}{\sqrt[J]{\beta}}} \mathbb E&lt;/em&gt;{{\color{red}{n,  s_{j, t+1}}}} \Big[  V_{j}^{\boldsymbol P_{-j}} \left(\mathbf{s}&lt;em&gt;{t+1}, {\color{red}{n}} \right) \ \Big| \ a&lt;/em&gt;{jt}, \boldsymbol s_{t} ; \theta^f \Big] \Bigg\rbrace
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$n$: indicates whose turn is to play&lt;/li&gt;
&lt;li&gt;since a turn is $J$ times shorter, profits are $\frac{1}{J} \pi$ and
discount factor is $\sqrt[J]{\beta}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Computational gain&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Expectation now taken over $n, s_{j, t+1}$ instead of
$\boldsymbol s_{t+1}$&lt;/li&gt;
&lt;li&gt;I.e. $Jk$ points instead of $3^k$ (3 because quality can go up, down
or stay the same)&lt;/li&gt;
&lt;li&gt;Huge computational difference!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;games-in-continuous-time&#34;&gt;Games in Continuous Time&lt;/h3&gt;
&lt;p&gt;Doraszelski and Judd (&lt;a href=&#34;#ref-doraszelski2012avoiding&#34;&gt;2012&lt;/a&gt;): what’s the
advantage of continuous time?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Probability that two firms take a decision simultaneously is zero&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With continuous time, the value function becomes $$
V^{\boldsymbol P_{-j}}&lt;em&gt;{j} (\mathbf{s}&lt;/em&gt;{t}) = \max_{a_{jt} \in \mathcal{A}&lt;em&gt;j \left(\mathbf{s}&lt;/em&gt;{t}\right)} \Bigg\lbrace \frac{1}{\lambda(a_{jt}) - \log(\beta)} \Bigg( \pi_{j}^{\boldsymbol P_{-j}} (a_{jt}, \mathbf{s}&lt;em&gt;{t} ; \theta^\pi ) + \lambda(a&lt;/em&gt;{jt}) \mathbb E_{\boldsymbol s_{t+1}} \Big[  V_{j}^{\boldsymbol P_{-j}} \left(\mathbf{s}&lt;em&gt;{t+1}\right) \ \Big| \ a&lt;/em&gt;{jt}, \boldsymbol s_{t} ; \theta^f \Big] \Bigg) \Bigg\rbrace
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\lambda(a_{jt}) = \delta + \frac{\alpha a_{jt}}{1 + \alpha a_{jt}}$
is the hazard rate for firm $j$ that &lt;strong&gt;something happens&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;i.e. either an increase in quality, with probability
$\frac{\alpha a_{jt}}{1 + \alpha a_{jt}}$&lt;/li&gt;
&lt;li&gt;… or a decrease in quality with probability $\delta$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Computational gain&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now the expectation over future states
$\mathbb E_{\boldsymbol s_{t+1}}$ is over $2J$ points instead of
$3^J$
&lt;ul&gt;
&lt;li&gt;3 because quality can go up, down or stay the same&lt;/li&gt;
&lt;li&gt;2 because in continuous time we don’t care if the state does not
change (investment fails)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comparison&#34;&gt;Comparison&lt;/h3&gt;
&lt;p&gt;Which method is &lt;strong&gt;best&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;I compare them in Courthoud (&lt;a href=&#34;#ref-courthoud2020approximation&#34;&gt;2020&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fastest: Weintraub, Benkard, and Van Roy
(&lt;a href=&#34;#ref-weintraub2008markov&#34;&gt;2008&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Effectively transforms the game into single-agent dynamics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Best trade-off: Doraszelski and Judd
(&lt;a href=&#34;#ref-doraszelski2019dynamic&#34;&gt;2019&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Simple, practical and also helps in terms of equilibrium
multeplicity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Also in Courthoud (&lt;a href=&#34;#ref-courthoud2020approximation&#34;&gt;2020&lt;/a&gt;): games
with random order
&lt;ul&gt;
&lt;li&gt;Better approximation than Doraszelski and Judd
(&lt;a href=&#34;#ref-doraszelski2019dynamic&#34;&gt;2019&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;And similar similar time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;applications&#34;&gt;Applications&lt;/h3&gt;
&lt;p&gt;Some applications of these methods include&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Approximation methods
&lt;ul&gt;
&lt;li&gt;Sweeting (&lt;a href=&#34;#ref-sweeting2013dynamic&#34;&gt;2013&lt;/a&gt;): product
repositioning among radio stations&lt;/li&gt;
&lt;li&gt;Barwick and Pathak (&lt;a href=&#34;#ref-barwick2015costs&#34;&gt;2015&lt;/a&gt;): entry and
exit in the real estate brokerage industry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Oblivious equilibrium
&lt;ul&gt;
&lt;li&gt;Xu and Chen (&lt;a href=&#34;#ref-xu2020structural&#34;&gt;2020&lt;/a&gt;): R&amp;amp;D investment in
the Korean electric motor industry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Moment based equilibrium
&lt;ul&gt;
&lt;li&gt;Jeon (&lt;a href=&#34;#ref-jeon2020learning&#34;&gt;2020&lt;/a&gt;): demand learning in the
container shipping industry&lt;/li&gt;
&lt;li&gt;Caoui (&lt;a href=&#34;#ref-caoui2019estimating&#34;&gt;2019&lt;/a&gt;): technology adoption
with network effects in the movie industry&lt;/li&gt;
&lt;li&gt;Vreugdenhil (&lt;a href=&#34;#ref-vreugdenhil2020booms&#34;&gt;2020&lt;/a&gt;): search and
matching in the oil drilling industry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Games in continuous time
&lt;ul&gt;
&lt;li&gt;Arcidiacono et al. (&lt;a href=&#34;#ref-arcidiacono2016estimation&#34;&gt;2016&lt;/a&gt;):
entry, exit and scale decisions in retail competition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Games with random moves
&lt;ul&gt;
&lt;li&gt;Igami (&lt;a href=&#34;#ref-igami2017estimating&#34;&gt;2017&lt;/a&gt;): innovation, entry,
exit in the hard drive industry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;from-io-to-ai&#34;&gt;From IO to AI&lt;/h2&gt;
&lt;h3 id=&#34;bridging-two-literatures&#34;&gt;Bridging two Literatures&lt;/h3&gt;
&lt;p&gt;There is one method to approximate the equilibrium in dynamic games that
is a bit different from the others: Pakes and McGuire
(&lt;a href=&#34;#ref-pakes2001stochastic&#34;&gt;2001&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Idea&lt;/strong&gt;: approximate the value function by Monte-Carlo simulation&lt;/li&gt;
&lt;li&gt;Firms start with a guess for the alternative-specific value function&lt;/li&gt;
&lt;li&gt;Act according to it&lt;/li&gt;
&lt;li&gt;Observe realized payoffs and state transitions&lt;/li&gt;
&lt;li&gt;And update the alternative-specific value function according to the
realized outcomes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Experience-Based Equilibrium&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Defined in Fershtman and Pakes (&lt;a href=&#34;#ref-fershtman2012dynamic&#34;&gt;2012&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Def&lt;/strong&gt;: &lt;em&gt;policy is optimal given beliefs of state transitions and
observed transitions are consistent with the beliefs&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: definition silent on off-equilibrium path beliefs&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pakes-and-mcguire-2001&#34;&gt;Pakes and McGuire (2001)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Players start with &lt;strong&gt;alternative-specific value function&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;yes, the ASV from Rust (&lt;a href=&#34;#ref-rust1994structural&#34;&gt;1994&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;$\bar V_{j,a}^{(0)} (\boldsymbol s ; \theta)$: initial value of
player $j$ for action $a$ in state $\boldsymbol s$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Until convergence, do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Compute optimal action, given
$\bar V_{j, a}^{(t)} (\boldsymbol s ; \theta)$ $$
a^* = \arg \max_a \bar V_{j, a}^{(t)} (\boldsymbol s ; \theta)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Observe the realized payoff
$\pi_{j, a^&lt;em&gt;}(\boldsymbol s ; \theta)$ and the realized next
state $\boldsymbol {s&amp;rsquo;}(\boldsymbol s, a^&lt;/em&gt;; \theta)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the alternative-specific value function of the chosen
action $k^&lt;em&gt;$ $$
\bar V_{j, a^&lt;/em&gt;}^{(t+1)} (\boldsymbol s ; \theta) = (1-\alpha_{\boldsymbol s, t}) \bar V_{j, a^&lt;em&gt;}^{(t)} (\boldsymbol s ; \theta) + \alpha_{\boldsymbol s, t} \Big[\pi_{j, a^&lt;/em&gt;}(\boldsymbol s ; \theta) + \arg \max_a \bar V_{j, a}^{(t)} (\boldsymbol s&amp;rsquo; ; \theta) \Big]
$$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\alpha_{\boldsymbol s, t} = \frac{1}{\text{number of times state } \boldsymbol s \text{ has been visited}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Where is the &lt;strong&gt;strategic interaction&lt;/strong&gt;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Firm always take &lt;em&gt;“best action so far”&lt;/em&gt; in each state
&lt;ul&gt;
&lt;li&gt;Start to take a new action only when the previous best has
performed badly for many periods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Remindful of literature of evolutionary game theory&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Importance of &lt;strong&gt;starting values&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Imagine, all payoffs are positive but value initialized to zero&lt;/li&gt;
&lt;li&gt;First action in each state $\to$ only action ever taken in that
state&lt;/li&gt;
&lt;li&gt;Loophole.
&lt;ul&gt;
&lt;li&gt;Why? Firms always take $\arg \max_a \bar V_a$ and never
&lt;em&gt;explore&lt;/em&gt; the alternatives&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Convergence&lt;/strong&gt; by desing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As $\lim_{t \to \infty} \alpha_{\boldsymbol s, t} = 1$&lt;/li&gt;
&lt;li&gt;Firms stop updating the value by design&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;q-learning&#34;&gt;Q-Learning&lt;/h3&gt;
&lt;p&gt;Computer Science reinforcement learning literature (AI): &lt;strong&gt;Q-learning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Differences&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar V_a( \boldsymbol s)$ called $Q_a(\boldsymbol s)$, hence the
name&lt;/li&gt;
&lt;li&gt;Firms don’t always take the optimal action
&lt;ul&gt;
&lt;li&gt;At the beginning of the algorithm: &lt;strong&gt;exploration&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Firms take actions at random&lt;/li&gt;
&lt;li&gt;Just to explore what happens taking different actions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gradually shift towards &lt;strong&gt;exploitation&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;I.e. take the optimal action, given
$\bar V^{(t)}( \boldsymbol s)$ at iteration $t$&lt;/li&gt;
&lt;li&gt;I.e. shift towards Pakes and McGuire
(&lt;a href=&#34;#ref-pakes2001stochastic&#34;&gt;2001&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;applications-1&#34;&gt;Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Doraszelski, Lewis, and Pakes (&lt;a href=&#34;#ref-doraszelski2018just&#34;&gt;2018&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Firm do actually learn by trial and error&lt;/li&gt;
&lt;li&gt;Setting: demand learning in the UK frequency response market
(electricity)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Asker et al. (&lt;a href=&#34;#ref-asker2020computational&#34;&gt;2020&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Uses Pakes and McGuire (&lt;a href=&#34;#ref-pakes2001stochastic&#34;&gt;2001&lt;/a&gt;) for
estimation&lt;/li&gt;
&lt;li&gt;Setting: dynamic timber auctions with information sharing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Calvano et al. (&lt;a href=&#34;#ref-calvano2020artificial&#34;&gt;2020&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Study Q-learning pricing algorithms&lt;/li&gt;
&lt;li&gt;In repeated price competition with differentiated products&lt;/li&gt;
&lt;li&gt;(Computational) lab experiment: what do these algorithms
converge to?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Finding&lt;/strong&gt;: algorithms learn reward-punishment collusive
strategies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;references-references&#34;&gt;References [references]&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;
markdown=&#34;1&#34;&gt;
&lt;div id=&#34;ref-abbring2010last&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Abbring, Jaap H, and Jeffrey R Campbell. 2010. “Last-in First-Out
Oligopoly Dynamics.” &lt;em&gt;Econometrica&lt;/em&gt; 78 (5): 1491–1527.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-aguirregabiria2021dynamic&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Aguirregabiria, Victor, Allan Collard-Wexler, and Stephen P Ryan. 2021.
“Dynamic Games in Empirical Industrial Organization.” National Bureau of
Economic Research.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-aguirregabiria2007sequential&#34; class=&#34;csl-entry&#34;
markdown=&#34;1&#34;&gt;
&lt;p&gt;Aguirregabiria, Victor, and Pedro Mira. 2007. “Sequential Estimation of
Dynamic Discrete Games.” &lt;em&gt;Econometrica&lt;/em&gt; 75 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-arcidiacono2016estimation&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Arcidiacono, Peter, Patrick Bayer, Jason R Blevins, and Paul B
Ellickson. 2016. “Estimation of Dynamic Discrete Choice Models in
Continuous Time with an Application to Retail Competition.” &lt;em&gt;The Review
of Economic Studies&lt;/em&gt; 83 (3): 889–931.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-arcidiacono2011conditional&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Arcidiacono, Peter, and Robert A Miller. 2011. “Conditional Choice
Probability Estimation of Dynamic Discrete Choice Models with Unobserved
Heterogeneity.” &lt;em&gt;Econometrica&lt;/em&gt; 79 (6): 1823–67.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-asker2020computational&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Asker, John, Chaim Fershtman, Jihye Jeon, and Ariel Pakes. 2020. “A
Computational Framework for Analyzing Dynamic Auctions: The Market
Impact of Information Sharing.” &lt;em&gt;The RAND Journal of Economics&lt;/em&gt; 51 (3):
805–39.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-bajari2007estimating&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Bajari, Patrick, C Lanier Benkard, and Jonathan Levin. 2007. “Estimating
Dynamic Models of Imperfect Competition.” &lt;em&gt;Econometrica&lt;/em&gt; 75 (5):
1331–70.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-barwick2015costs&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Barwick, Panle Jia, and Parag A Pathak. 2015. “The Costs of Free Entry:
An Empirical Study of Real Estate Agents in Greater Boston.” &lt;em&gt;The RAND
Journal of Economics&lt;/em&gt; 46 (1): 103–45.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-berry2021empirical&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Berry, Steven T, and Giovanni Compiani. 2021. “Empirical Models of
Industry Dynamics with Endogenous Market Structure.” &lt;em&gt;Annual Review of
Economics&lt;/em&gt; 13.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-besanko2010learning&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Besanko, David, Ulrich Doraszelski, Yaroslav Kryukov, and Mark
Satterthwaite. 2010. “Learning-by-Doing, Organizational Forgetting, and
Industry Dynamics.” &lt;em&gt;Econometrica&lt;/em&gt; 78 (2): 453–508.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-borkovsky2010user&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Borkovsky, Ron N, Ulrich Doraszelski, and Yaroslav Kryukov. 2010. “A
User’s Guide to Solving Dynamic Stochastic Games Using the Homotopy
Method.” &lt;em&gt;Operations Research&lt;/em&gt; 58 (4-part-2): 1116–32.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-calvano2020artificial&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Calvano, Emilio, Giacomo Calzolari, Vincenzo Denicolo, and Sergio
Pastorello. 2020. “Artificial Intelligence, Algorithmic Pricing, and
Collusion.” &lt;em&gt;American Economic Review&lt;/em&gt; 110 (10): 3267–97.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-caoui2019estimating&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Caoui, El Hadi. 2019. “Estimating the Costs of Standardization: Evidence
from the Movie Industry.” &lt;em&gt;R&amp;amp;R, Review of Economic Studies&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-collard2013demand&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Collard-Wexler, Allan. 2013. “Demand Fluctuations in the Ready-Mix
Concrete Industry.” &lt;em&gt;Econometrica&lt;/em&gt; 81 (3): 1003–37.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-courthoud2020approximation&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Courthoud, Matteo. 2020. “Approximation Methods for Large Dynamic
Stochastic Games.” &lt;em&gt;Working Paper&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-doraszelski2003r&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Doraszelski, Ulrich. 2003. “An r&amp;amp;d Race with Knowledge Accumulation.”
&lt;em&gt;Rand Journal of Economics&lt;/em&gt;, 20–42.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-doraszelski2012avoiding&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Doraszelski, Ulrich, and Kenneth L Judd. 2012. “Avoiding the Curse of
Dimensionality in Dynamic Stochastic Games.” &lt;em&gt;Quantitative Economics&lt;/em&gt; 3
(1): 53–93.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-doraszelski2019dynamic&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;———. 2019. “Dynamic Stochastic Games with Random Moves.” &lt;em&gt;Quantitative
Marketing and Economics&lt;/em&gt; 17 (1): 59–79.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-doraszelski2018just&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Doraszelski, Ulrich, Gregory Lewis, and Ariel Pakes. 2018. “Just
Starting Out: Learning and Equilibrium in a New Market.” &lt;em&gt;American
Economic Review&lt;/em&gt; 108 (3): 565–615.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-doraszelski2010computable&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Doraszelski, Ulrich, and Mark Satterthwaite. 2010. “Computable
Markov-Perfect Industry Dynamics.” &lt;em&gt;The RAND Journal of Economics&lt;/em&gt; 41
(2): 215–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-egesdal2015estimating&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Egesdal, Michael, Zhenyu Lai, and Che-Lin Su. 2015. “Estimating Dynamic
Discrete-Choice Games of Incomplete Information.” &lt;em&gt;Quantitative
Economics&lt;/em&gt; 6 (3): 567–97.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-eibelshauser2019markov&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Eibelshäuser, Steffen, and David Poensgen. 2019. “Markov Quantal
Response Equilibrium and a Homotopy Method for Computing and Selecting
Markov Perfect Equilibria of Dynamic Stochastic Games.” &lt;em&gt;Working Paper&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ericson1995markov&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Ericson, Richard, and Ariel Pakes. 1995. “Markov-Perfect Industry
Dynamics: A Framework for Empirical Work.” &lt;em&gt;The Review of Economic
Studies&lt;/em&gt; 62 (1): 53–82.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-esteban2007durable&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Esteban, Susanna, and Matthew Shum. 2007. “Durable-Goods Oligopoly with
Secondary Markets: The Case of Automobiles.” &lt;em&gt;The RAND Journal of
Economics&lt;/em&gt; 38 (2): 332–54.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-farias2012approximate&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Farias, Vivek, Denis Saure, and Gabriel Y Weintraub. 2012. “An
Approximate Dynamic Programming Approach to Solving Dynamic Oligopoly
Models.” &lt;em&gt;The RAND Journal of Economics&lt;/em&gt; 43 (2): 253–82.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-fershtman2012dynamic&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Fershtman, Chaim, and Ariel Pakes. 2012. “Dynamic Games with Asymmetric
Information: A Framework for Empirical Work.” &lt;em&gt;The Quarterly Journal of
Economics&lt;/em&gt; 127 (4): 1611–61.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-goettler2011does&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Goettler, Ronald L, and Brett R Gordon. 2011. “Does AMD Spur Intel to
Innovate More?” &lt;em&gt;Journal of Political Economy&lt;/em&gt; 119 (6): 1141–1200.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hotz1993conditional&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Hotz, V Joseph, and Robert A Miller. 1993. “Conditional Choice
Probabilities and the Estimation of Dynamic Models.” &lt;em&gt;The Review of
Economic Studies&lt;/em&gt; 60 (3): 497–529.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-huang2014dynamic&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Huang, Ling, and Martin D Smith. 2014. “The Dynamic Efficiency Costs of
Common-Pool Resource Exploitation.” &lt;em&gt;American Economic Review&lt;/em&gt; 104 (12):
4071–4103.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ifrach2017framework&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Ifrach, Bar, and Gabriel Y Weintraub. 2017. “A Framework for Dynamic
Oligopoly in Concentrated Industries.” &lt;em&gt;The Review of Economic Studies&lt;/em&gt;
84 (3): 1106–50.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-igami2017estimating&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Igami, Mitsuru. 2017. “Estimating the Innovator’s Dilemma: Structural
Analysis of Creative Destruction in the Hard Disk Drive Industry,
1981–1998.” &lt;em&gt;Journal of Political Economy&lt;/em&gt; 125 (3): 798–847.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-iskhakov2016recursive&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Iskhakov, Fedor, John Rust, and Bertel Schjerning. 2016. “Recursive
Lexicographical Search: Finding All Markov Perfect Equilibria of Finite
State Directional Dynamic Games.” &lt;em&gt;The Review of Economic Studies&lt;/em&gt; 83
(2): 658–703.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-jeon2020learning&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Jeon, Jihye. 2020. “Learning and Investment Under Demand Uncertainty in
Container Shipping.” &lt;em&gt;The RAND Journal of Economics&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kasahara2009nonparametric&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Kasahara, Hiroyuki, and Katsumi Shimotsu. 2009. “Nonparametric
Identification of Finite Mixture Models of Dynamic Discrete Choices.”
&lt;em&gt;Econometrica&lt;/em&gt; 77 (1): 135–75.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-maskin1988theory&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Maskin, Eric, and Jean Tirole. 1988. “A Theory of Dynamic Oligopoly, II:
Price Competition, Kinked Demand Curves, and Edgeworth Cycles.”
&lt;em&gt;Econometrica: Journal of the Econometric Society&lt;/em&gt;, 571–99.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pakes1994computing&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Pakes, Ariel, and Paul McGuire. 1994. “Computing Markov-Perfect Nash
Equilibria: Numerical Implications of a Dynamic Differentiated Product
Model.” &lt;em&gt;RAND Journal of Economics&lt;/em&gt; 25 (4): 555–89.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pakes2001stochastic&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;———. 2001. “Stochastic Algorithms, Symmetric Markov Perfect Equilibrium,
and the ‘Curse’of Dimensionality.” &lt;em&gt;Econometrica&lt;/em&gt; 69 (5): 1261–81.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pakes2007simple&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Pakes, Ariel, Michael Ostrovsky, and Steven Berry. 2007. “Simple
Estimators for the Parameters of Discrete Dynamic Games (with Entry/Exit
Examples).” &lt;em&gt;The RAND Journal of Economics&lt;/em&gt; 38 (2): 373–99.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pesendorfer2008asymptotic&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Pesendorfer, Martin, and Philipp Schmidt-Dengler. 2008. “Asymptotic
Least Squares Estimators for Dynamic Games.” &lt;em&gt;The Review of Economic
Studies&lt;/em&gt; 75 (3): 901–28.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pesendorfer2010sequential&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;———. 2010. “Sequential Estimation of Dynamic Discrete Games: A Comment.”
&lt;em&gt;Econometrica&lt;/em&gt; 78 (2): 833–42.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rust1994structural&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Rust, John. 1994. “Structural Estimation of Markov Decision Processes.”
&lt;em&gt;Handbook of Econometrics&lt;/em&gt; 4: 3081–3143.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ryan2012costs&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Ryan, Stephen P. 2012. “The Costs of Environmental Regulation in a
Concentrated Industry.” &lt;em&gt;Econometrica&lt;/em&gt; 80 (3): 1019–61.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2012constrained&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Su, Che-Lin, and Kenneth L Judd. 2012. “Constrained Optimization
Approaches to Estimation of Structural Models.” &lt;em&gt;Econometrica&lt;/em&gt; 80 (5):
2213–30.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-sweeting2013dynamic&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Sweeting, Andrew. 2013. “Dynamic Product Positioning in Differentiated
Product Markets: The Effect of Fees for Musical Performance Rights on
the Commercial Radio Industry.” &lt;em&gt;Econometrica&lt;/em&gt; 81 (5): 1763–803.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vreugdenhil2020booms&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Vreugdenhil, Nicholas. 2020. “Booms, Busts, and Mismatch in Capital
Markets: Evidence from the Offshore Oil and Gas Industry.” &lt;em&gt;R&amp;amp;R at
Journal of Political Economy&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-weintraub2008markov&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Weintraub, Gabriel Y, C Lanier Benkard, and Benjamin Van Roy. 2008.
“Markov Perfect Industry Dynamics with Many Firms.” &lt;em&gt;Econometrica&lt;/em&gt; 76
(6): 1375–1411.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-xu2020structural&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Xu, Daniel Yi, and Yanyou Chen. 2020. “A Structural Empirical Model of
r&amp;amp;d, Firm Heterogeneity, and Industry Evolution.” &lt;em&gt;Journal of Industrial
Economics.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Coding: Logit Demand</title>
      <link>https://matteocourthoud.github.io/course/empirical-io/11_logit_demand/</link>
      <pubDate>Wed, 10 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/course/empirical-io/11_logit_demand/</guid>
      <description>&lt;h3 id=&#34;intro&#34;&gt;Intro&lt;/h3&gt;
&lt;p&gt;In this session, I am going to cover demand estimation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compute equilibrium outcomes with Logit demand&lt;/li&gt;
&lt;li&gt;Simulate a dataset&lt;/li&gt;
&lt;li&gt;Estimate Logit demand&lt;/li&gt;
&lt;li&gt;Compare different instruments&lt;/li&gt;
&lt;li&gt;Include supply&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;In this first part, we are going to assume that consumer
$i \in \lbrace1,&amp;hellip;,I\rbrace$ utility from good
$j \in \lbrace1,&amp;hellip;,J\rbrace$ in market $t \in \lbrace1,&amp;hellip;,T\rbrace$
takes the form&lt;/p&gt;
&lt;p&gt;$$
u_{ijt} = \boldsymbol x_{jt} \boldsymbol \beta_{it} - \alpha p_{jt} + \xi_{jt} + \epsilon_{ijt}
$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\xi_{jt}$ is type-1 extreme value distributed&lt;/li&gt;
&lt;li&gt;$\boldsymbol \beta$ has dimension $K$
&lt;ul&gt;
&lt;li&gt;i.e. goods have $K$ characteristics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;
&lt;p&gt;We have $J$ firms and each product has $K$ characteristics&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;J = 3;                            # 3 firms == products
K = 2;                            # 2 product characteristics
c = rand(Uniform(0, 1), J);       # Random uniform marginal costs
ξ = rand(Normal(0, 1), J+1);      # Random normal individual shocks
X = rand(Exponential(1), J, K);   # Random exponential product characteristics
β = [.5, 2, -1];                  # Preferences (last one is for prices, i.e. alpha)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-demand&#34;&gt;Code Demand&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function demand(p::Vector, X::Matrix, β::Vector, ξ::Vector)::Tuple{Vector, Number}
    &amp;quot;&amp;quot;&amp;quot;Compute demand&amp;quot;&amp;quot;&amp;quot;
    δ = 1 .+ [X p] * β              # Mean value
    u = [δ; 0] + ξ                  # Utility
    e = exp.(u)                     # Take exponential
    q = e ./ sum(e)                 # Compute demand
    return q[1:end-1], q[end]
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can try with an example.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p = 2 .* c;
demand(p, X, β, ξ)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ([0.4120077746005573, 0.26650568009936, 0.24027826270165709], 0.08120828259842561)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-supply&#34;&gt;Code Supply&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function profits(p::Vector, c::Vector, X::Matrix, β::Vector, ξ::Vector)::Vector
    &amp;quot;&amp;quot;&amp;quot;Compute profits&amp;quot;&amp;quot;&amp;quot;
    q, _ = demand(p, X, β, ξ)       # Compute demand
    pr = (p - c) .* q               # Compute profits
    return pr
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can try with an example.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;profits(p, c, X, β, ξ)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 3-element Array{Float64,1}:
##  0.20289186252172428
##  0.1596422305025479
##  0.1270874470740512
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-best-reply&#34;&gt;Code Best Reply&lt;/h3&gt;
&lt;p&gt;We first code the best reply of firm $j$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function profits_j(pj::Number, j::Int, p::Vector, c::Vector, X::Matrix, β::Vector, ξ::Vector)::Number
    &amp;quot;&amp;quot;&amp;quot;Compute profits of firm j&amp;quot;&amp;quot;&amp;quot;
    p[j] = pj                       # Insert price of firm j
    pr = profits(p, c, X, β, ξ)     # Compute profits
    return pr[j]
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s test it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;j = 1;
obj_fun(pj) = - profits_j(pj[1], j, copy(p), c, X, β, ξ);
pj = optimize(x -&amp;gt; obj_fun(x), [1.0], LBFGS()).minimizer[1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 1.8019637881982011
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What are the implied profits now?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;Profits old: &amp;quot;,  round.(profits(p, c, X, β, ξ), digits=4))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Profits old: [0.2029, 0.1596, 0.1271]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;p_new = copy(p);
p_new[j] = pj;
print(&amp;quot;Profits new: &amp;quot;,  round.(profits(p_new, c, X, β, ξ), digits=4))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Profits new: [0.3095, 0.2073, 0.1651]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed firm 1 has increased its profits.&lt;/p&gt;
&lt;h3 id=&#34;code-equilibrium&#34;&gt;Code Equilibrium&lt;/h3&gt;
&lt;p&gt;We can now compute equilibrium prices&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function equilibrium(c::Vector, X::Matrix, β::Vector, ξ::Vector)::Vector
    &amp;quot;&amp;quot;&amp;quot;Compute equilibrium prices and profits&amp;quot;&amp;quot;&amp;quot;
    p = 2 .* c;
    dist = 1;
    iter = 0;

    # Until convergence
    while (dist &amp;gt; 1e-8) &amp;amp;&amp;amp; (iter&amp;lt;1000)

        # Compute best reply for each firm
        p1 = copy(p);
        for j=1:length(p)
            obj_fun(pj) = - profits_j(pj[1], j, p, c, X, β, ξ);
            optimize(x -&amp;gt; obj_fun(x), [1.0], LBFGS()).minimizer[1];
        end

        # Update distance
        dist = max(abs.(p - p1)...);
        iter += 1;
    end
    return p
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;code-equilibrium-1&#34;&gt;Code Equilibrium&lt;/h3&gt;
&lt;p&gt;Let’s test it&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Compute equilibrium prices
p_eq = equilibrium(c, X, β, ξ);
print(&amp;quot;Equilibrium prices: &amp;quot;,  round.(p_eq, digits=4))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Equilibrium prices: [1.9764, 1.9602, 1.8366]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# And profits
pi_eq = profits(p_eq, c, X, β, ξ);
print(&amp;quot;Equilibrium profits: &amp;quot;,  round.(pi_eq, digits=4))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Equilibrium profits: [0.484, 0.3612, 0.3077]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected the prices of the first 2 firms are lower and their profits
are higher.&lt;/p&gt;
&lt;h3 id=&#34;dgp&#34;&gt;DGP&lt;/h3&gt;
&lt;p&gt;Let’s generate our Data Generating Process (DGP).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\boldsymbol x \sim exp(V_{x})$&lt;/li&gt;
&lt;li&gt;$\xi \sim N(0, V_{\xi})$&lt;/li&gt;
&lt;li&gt;$w \sim N(0, 1)$&lt;/li&gt;
&lt;li&gt;$\omega \sim N(0, 1)$&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function draw_data(J::Int, K::Int, rangeJ::Vector, varX::Number, varξ::Number)::Tuple
    &amp;quot;&amp;quot;&amp;quot;Draw data for one market&amp;quot;&amp;quot;&amp;quot;
    J_ = rand(rangeJ[1]:rangeJ[2])              # Number of firms (products)
    X_ = rand(Exponential(varX), J_, K)         # Product characteristics
    ξ_ = rand(Normal(0, varξ), J_+1)            # Product-level utility shocks
    w_ = rand(Uniform(0, 1), J_)                # Cost shifters
    ω_ = rand(Uniform(0, 1), J_)                # Cost shocks
    c_ = w_ + ω_                                # Cost
    j_ = sort(sample(1:J, J_, replace=false))   # Subset of firms
    return X_, ξ_, w_, c_, j_
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;equilibrium&#34;&gt;Equilibrium&lt;/h3&gt;
&lt;p&gt;We first compute the equilibrium in one market.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function compute_mkt_eq(J::Int, b::Vector, rangeJ::Vector, varX::Number, varξ::Number)::DataFrame
    &amp;quot;&amp;quot;&amp;quot;Compute equilibrium one market&amp;quot;&amp;quot;&amp;quot;

    # Initialize variables
    K = size(β, 1) - 1
    X_, ξ_, w_, c_, j_ = draw_data(J, K, rangeJ, varX, varξ)

    # Compute equilibrium
    p_ = equilibrium(c_, X_, β, ξ_)      # Equilibrium prices
    q_, q0 = demand(p_, X_, β, ξ_)       # Demand with shocks
    pr_ = (p_ - c_) .* q_               # Profits

    # Save to data
    q0_ = ones(length(j_)) .* q0
    df = DataFrame(j=j_, w=w_, p=p_, q=q_, q0=q0_, pr=pr_)
    for k=1:K
      df[!,&amp;quot;x$k&amp;quot;] = X_[:,k]
      df[!,&amp;quot;z$k&amp;quot;] = sum(X_[:,k]) .- X_[:,k]
    end
    return df
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;simulate-dataset&#34;&gt;Simulate Dataset&lt;/h3&gt;
&lt;p&gt;We can now write the code to simulate the whole dataset.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function simulate_data(J::Int, b::Vector, T::Int, rangeJ::Vector, varX::Number, varξ::Number)
    &amp;quot;&amp;quot;&amp;quot;Simulate full dataset&amp;quot;&amp;quot;&amp;quot;
    df = compute_mkt_eq(J, β, rangeJ, varX, varξ)
    df[!, &amp;quot;t&amp;quot;] = ones(nrow(df)) * 1
    for t=2:T
        df_temp = compute_mkt_eq(J, β, rangeJ, varX, varξ)
        df_temp[!, &amp;quot;t&amp;quot;] = ones(nrow(df_temp)) * t
        append!(df, df_temp)
    end
    CSV.write(&amp;quot;../data/logit.csv&amp;quot;, df)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;simulate-dataset-2&#34;&gt;Simulate Dataset (2)&lt;/h3&gt;
&lt;p&gt;We generate the dataset by simulating many markets that differ by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of firms (and their identity)&lt;/li&gt;
&lt;li&gt;their marginal costs&lt;/li&gt;
&lt;li&gt;their product characteristics&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Set parameters
J = 10;                 # Number of firms
K = 2;                  # Product caracteristics
T = 500;                # Markets
β = [.5, 2, -1];        # Preferences
rangeJ = [2, 6];        # Min and max firms per market
varX = 1;               # Variance of X
varξ = 2;               # Variance of xi

# Simulate
df = simulate_data(J, β, T, rangeJ, varX, varξ);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;What does the data look like? Let’s switch to R!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Read data
df = fread(&amp;quot;../data/logit.csv&amp;quot;)
kable(df[1:6,], digits=4)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;j&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;w&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;p&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;q&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;q0&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;pr&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;x1&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;z1&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;x2&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;z2&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;t&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1491&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.9616&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0932&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0013&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1028&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.4517&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.8219&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.6918&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.6779&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.8352&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.1112&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0193&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0013&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0197&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1328&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.1408&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2075&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5.1622&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2749&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.2789&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2710&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0013&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.3717&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1449&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.1287&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.1493&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.2205&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4118&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.6386&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.6151&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0013&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.5982&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5442&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.7294&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.3212&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.0485&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.6071&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.1457&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0886&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0003&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0972&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.9239&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.4182&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.6551&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;10.0474&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;6&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1615&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.1626&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0003&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1763&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.1657&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.3629&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;13.3396&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;estimation&#34;&gt;Estimation&lt;/h3&gt;
&lt;p&gt;First we need to compute the dependent variable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df$y = log(df$q) - log(df$q0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can estimate the logit model. The true values are $alpha=1$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ols &amp;lt;- lm(y ~ x1 + x2 + p, data=df)
kable(tidy(ols), digits=4)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;term&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;estimate&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;std.error&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;statistic&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-1.3558&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1476&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-9.1874&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;x1&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4176&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0537&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;7.7782&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;x2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.1494&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0719&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;15.9903&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;p&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2406&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0656&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.6664&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3e-04&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The estimate of $\alpha = 1$ is biased (positive and significant) since
$p$ is endogenous. We need instruments.&lt;/p&gt;
&lt;h3 id=&#34;iv-1-cost-shifters&#34;&gt;IV 1: Cost Shifters&lt;/h3&gt;
&lt;p&gt;First set of instruments: &lt;strong&gt;cost shifters&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fm_costiv &amp;lt;- ivreg(y ~ x1 + x2 + p | x1 + x2 + w, data=df)
kable(tidy(fm_costiv), digits=4)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;term&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;estimate&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;std.error&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;statistic&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2698&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4923&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5480&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5837&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;x1&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5249&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0643&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;8.1679&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;x2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.8178&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2064&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;8.8059&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;p&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-0.7034&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2800&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-2.5123&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0121&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now the estimate of $\alpha$ is negative and significant.&lt;/p&gt;
&lt;h3 id=&#34;iv-2-blp-instruments&#34;&gt;IV 2: BLP Instruments&lt;/h3&gt;
&lt;p&gt;Second set of instruments: &lt;strong&gt;product characteristics of other firms in
the same market&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fm_blpiv &amp;lt;- ivreg(y ~ x1 + x2 + p | x1 + x2 + z1 + z2, data=df)
kable(tidy(fm_blpiv), digits=4)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;term&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;estimate&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;std.error&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;statistic&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;p.value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.6616&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5014&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.3139&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;9e-04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;x1&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.6167&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0698&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;8.8380&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;x2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.3901&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2110&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;11.3279&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;p&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-1.5117&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2840&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;-5.3221&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Also the BLP instruments deliver an estimate of $\alpha$ is negative and
significant.&lt;/p&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Coding: BLP (1995)</title>
      <link>https://matteocourthoud.github.io/course/empirical-io/12_blp_1995/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/course/empirical-io/12_blp_1995/</guid>
      <description>&lt;h3 id=&#34;intro&#34;&gt;Intro&lt;/h3&gt;
&lt;p&gt;In this session, I am going to cover demand estimation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compute equilibrium outcomes with RCL demand&lt;/li&gt;
&lt;li&gt;Simulate market-level data
&lt;ul&gt;
&lt;li&gt;Extremely similar to the logit demand simulation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Build the BLP estimator from Berry, Levinsohn, and Pakes
(&lt;a href=&#34;#ref-berry1995automobile&#34;&gt;1995&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;In this first part, we are going to assume that consumer
$i \in \lbrace1,&amp;hellip;,I\rbrace$ utility from good
$j \in \lbrace1,&amp;hellip;,J\rbrace$ in market $t \in \lbrace1,&amp;hellip;,T\rbrace$
takes the form&lt;/p&gt;
&lt;p&gt;$$
u_{ijt} = \boldsymbol x_{jt} \boldsymbol \beta_{it} - \alpha p_{jt} + \xi_{jt} + \epsilon_{ijt}
$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\xi_{jt}$ is type-1 extreme value distributed&lt;/li&gt;
&lt;li&gt;$\boldsymbol \beta_{it}$: has dimension $K$
$$\beta_{it}^k = \beta_0^k + \sigma_k \zeta_{it}^k$$
&lt;ul&gt;
&lt;li&gt;$\beta_0^k$: fixed taste for characteristic $k$ (the usual
$\beta$)&lt;/li&gt;
&lt;li&gt;$\zeta_{it}^k$: random taste, i.i.d. across consumers and
markets $t$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;
&lt;p&gt;We have $J$ firms and each product has $K$ characteristics.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;i = 100;                # Number of consumers
J = 10;                 # Number of firms
K = 2;                  # Product characteristics
T = 100;                # Number of markets
β = [.5, 2, -1];        # Preferences
varζ = 5;               # Variance of the random taste
rangeJ = [2, 6];        # Min and max firms per market
varX = 1;               # Variance of X
varξ = 2;               # Variance of xi
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;demand&#34;&gt;Demand&lt;/h3&gt;
&lt;p&gt;Demand is the main difference w.r.t. the logit model. Now we have
individual shocks $\zeta$ we have to integrate over.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function demand(p::Vector, X::Matrix, β::Vector, ξ::Matrix, ζ::Matrix)::Tuple{Vector, Number}
    &amp;quot;&amp;quot;&amp;quot;Compute demand&amp;quot;&amp;quot;&amp;quot;
    δ = [X p] * (β .+ ζ)                    # Mean value
    δ0 = zeros(1, size(ζ, 2))               # Mean value of the outside option
    u = [δ; δ0] + ξ                         # Utility
    e = exp.(u)                             # Take exponential
    q = mean(e ./ sum(e, dims=1), dims=2)   # Compute demand
    return q[1:end-1], q[end]
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;supply&#34;&gt;Supply&lt;/h3&gt;
&lt;p&gt;Computing profits is instead exactly the same as before. We just have to
save the shocks $\zeta$ to be sure demand is stable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function profits(p::Vector, c::Vector, X::Matrix, β::Vector, ξ::Matrix, ζ::Matrix)::Vector
    &amp;quot;&amp;quot;&amp;quot;Compute profits&amp;quot;&amp;quot;&amp;quot;
    q, _ = demand(p, X, β, ξ, ζ)            # Compute demand
    pr = (p - c) .* q                       # Compute profits
    return pr
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function profits_j(pj::Number, j::Int, p::Vector, c::Vector, X::Matrix, β::Vector, ξ::Matrix, ζ::Matrix)::Number
    &amp;quot;&amp;quot;&amp;quot;Compute profits of firm j&amp;quot;&amp;quot;&amp;quot;
    p[j] = pj                               # Insert price of firm j
    pr = profits(p, c, X, β, ξ, ζ)          # Compute profits
    return pr[j]
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;equilibrium&#34;&gt;Equilibrium&lt;/h3&gt;
&lt;p&gt;We can now compute the equilibrium for a specific market, as before.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function equilibrium(c::Vector, X::Matrix, β::Vector, ξ::Matrix, ζ::Matrix)::Vector
    &amp;quot;&amp;quot;&amp;quot;Compute equilibrium prices and profits&amp;quot;&amp;quot;&amp;quot;
    p = 2 .* c;
    dist = 1;
    iter = 0;

    # Iterate until convergence
    while (dist &amp;gt; 1e-8) &amp;amp;&amp;amp; (iter&amp;lt;1000)

        # Compute best reply for each firm
        p_old = copy(p);
        for j=1:length(p)
            obj_fun(pj) = - profits_j(pj[1], j, p, c, X, β, ξ, ζ);
            optimize(x -&amp;gt; obj_fun(x), [1.0], LBFGS());
        end

        # Update distance
        dist = max(abs.(p - p_old)...);
        iter += 1;
    end
    return p
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;simulating-data&#34;&gt;Simulating Data&lt;/h3&gt;
&lt;p&gt;We are now ready to simulate the data, i.e. equilibrium outcomes across
different markets. We first draw all the variables.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function draw_data(I::Int, J::Int, K::Int, rangeJ::Vector, varζ::Number, varX::Number, varξ::Number)::Tuple
    &amp;quot;&amp;quot;&amp;quot;Draw data for one market&amp;quot;&amp;quot;&amp;quot;
    J_ = rand(rangeJ[1]:rangeJ[2])              # Number of firms (products)
    X_ = rand(Exponential(varX), J_, K)         # Product characteristics
    ξ_ = rand(Normal(0, varξ), J_+1, I)         # Product-level utility shocks
    # Consumer-product-level preference shocks
    ζ_ = [rand(Normal(0,1), 1, I) * varζ; zeros(K,I)]
    w_ = rand(Uniform(0, 1), J_)                # Cost shifters
    ω_ = rand(Uniform(0, 1), J_)                # Cost shocks
    c_ = w_ + ω_                                # Cost
    j_ = sort(sample(1:J, J_, replace=false))   # Subset of firms
    return X_, ξ_, ζ_, w_, c_, j_
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;simulating-data-1&#34;&gt;Simulating Data&lt;/h3&gt;
&lt;p&gt;Then we simulate the data for one market.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function compute_mkt_eq(I::Int, J::Int, β::Vector, rangeJ::Vector, varζ::Number, varX::Number, varξ::Number)::DataFrame
    &amp;quot;&amp;quot;&amp;quot;Compute equilibrium one market&amp;quot;&amp;quot;&amp;quot;

    # Initialize variables
    K = size(β, 1) - 1
    X_, ξ_, ζ_, w_, c_, j_ = draw_data(I, J, K, rangeJ, varζ, varX, varξ)

    # Compute equilibrium
    p_ = equilibrium(c_, X_, β, ξ_, ζ_)    # Equilibrium prices
    q_, q0 = demand(p_, X_, β, ξ_, ζ_)     # Demand with shocks
    pr_ = (p_ - c_) .* q_                       # Profits

    # Save to data
    q0_ = ones(length(j_)) .* q0
    df = DataFrame(j=j_, w=w_, p=p_, q=q_, q0=q0_, pr=pr_)
    for k=1:K
      df[!,&amp;quot;x$k&amp;quot;] = X_[:,k]
      df[!,&amp;quot;z$k&amp;quot;] = sum(X_[:,k]) .- X_[:,k]
    end
    return df
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;simultate-the-data-2&#34;&gt;Simultate the Data (2)&lt;/h3&gt;
&lt;p&gt;We repeat for $T$ markets.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function simulate_data(I::Int, J::Int, β::Vector, T::Int, rangeJ::Vector, varζ::Number, varX::Number, varξ::Number)
    &amp;quot;&amp;quot;&amp;quot;Simulate full dataset&amp;quot;&amp;quot;&amp;quot;
    df = compute_mkt_eq(I, J, β, rangeJ, varζ, varX, varξ)
    df[!, &amp;quot;t&amp;quot;] = ones(nrow(df)) * 1
    for t=2:T
        df_temp = compute_mkt_eq(I, J, β, rangeJ, varζ, varX, varξ)
        df_temp[!, &amp;quot;t&amp;quot;] = ones(nrow(df_temp)) * t
        append!(df, df_temp)
    end
    CSV.write(&amp;quot;../data/blp.csv&amp;quot;, df)
    return df
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;simulate-the-data-3&#34;&gt;Simulate the Data (3)&lt;/h3&gt;
&lt;p&gt;Now let’s run the code&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Simulate
df = simulate_data(i, J, β, T, rangeJ, varζ, varX, varξ);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;What does the data look like? Let’s switch to R!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Read data
df = fread(&amp;quot;../data/blp.csv&amp;quot;)
kable(df[1:6,], digits=4)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;j&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;w&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;p&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;q&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;q0&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;pr&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;x1&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;z1&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;x2&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;z2&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;t&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.6481&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.5918&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2929&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4558&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.8165&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.6531&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.0002&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.7063&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.8207&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.9997&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5.1926&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.2513&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4558&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.8717&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.0002&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.6531&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.8207&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.7063&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5842&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.6999&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0800&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.3919&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1572&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.3591&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;7.1958&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4217&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.1996&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5291&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.5934&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1404&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.3919&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4467&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.3801&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5.1748&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1283&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.4929&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5012&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.4196&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1368&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.3919&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4461&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.2638&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5.2911&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.4408&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.1804&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;8&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.9359&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.2923&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.0863&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.3919&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.1477&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0.5182&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;7.0367&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.0271&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1.5942&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;estimation&#34;&gt;Estimation&lt;/h3&gt;
&lt;p&gt;The BLP estimation procedure&lt;/p&gt;
&lt;h3 id=&#34;from-deltas-to-shares&#34;&gt;From deltas to shares&lt;/h3&gt;
&lt;p&gt;First, we need to compute the shares implied by aspecific vector of
$\delta$s&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function implied_shares(Xt_::Matrix, ζt_::Matrix, δt_::Vector, δ0::Matrix)::Vector
    &amp;quot;&amp;quot;&amp;quot;Compute shares implied by deltas and shocks&amp;quot;&amp;quot;&amp;quot;
    u = [δt_ .+ (Xt_ * ζt_); δ0]                  # Utility
    e = exp.(u)                                 # Take exponential
    q = mean(e ./ sum(e, dims=1), dims=2)       # Compute demand
    return q[1:end-1]
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;inner-loop&#34;&gt;Inner Loop&lt;/h3&gt;
&lt;p&gt;We can now compute the inner loop and invert the demand function: from
shares $q$ to $\delta$s&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function inner_loop(qt_::Vector, Xt_::Matrix, ζt_::Matrix)::Vector
    &amp;quot;&amp;quot;&amp;quot;Solve the inner loop: compute delta, given the shares&amp;quot;&amp;quot;&amp;quot;
    δt_ = ones(size(qt_))
    δ0 = zeros(1, size(ζt_, 2))
    dist = 1

    # Iterate until convergence
    while (dist &amp;gt; 1e-8)
        q = implied_shares(Xt_, ζt_, δt_, δ0)
        δt2_ = δt_ + log.(qt_) - log.(q)
        dist = max(abs.(δt2_ - δt_)...)
        δt_ = δt2_
    end
    return δt_
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;compute-delta&#34;&gt;Compute Delta&lt;/h3&gt;
&lt;p&gt;We can now repeat the inversion for every market and get the vector of
mean utilities $\delta$s from the observed market shares $q$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function compute_delta(q_::Vector, X_::Matrix, ζ_::Matrix, T::Vector)::Vector
    &amp;quot;&amp;quot;&amp;quot;Compute residuals&amp;quot;&amp;quot;&amp;quot;
    δ_ = zeros(size(T))

    # Loop over each market
    for t in unique(T)
        qt_ = q_[T.==t]                             # Quantity in market t
        Xt_ = X_[T.==t,:]                           # Characteristics in mkt t
        δ_[T.==t] = inner_loop(qt_, Xt_, ζ_)        # Solve inner loop
    end
    return δ_
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;compute-xi&#34;&gt;Compute Xi&lt;/h3&gt;
&lt;p&gt;Now that we have $\delta$, it is pretty straightforward to compute
$\xi$. We just need to perform a linear regression (with instruments) of
mean utilities $\delta$ on prices $p$ and product characteristics $X$
and compute the residuals $\xi$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function compute_xi(X_::Matrix, IV_::Matrix, δ_::Vector)::Tuple
    &amp;quot;&amp;quot;&amp;quot;Compute residual, given delta (IV)&amp;quot;&amp;quot;&amp;quot;
    β_ = inv(IV_&#39; * X_) * (IV_&#39; * δ_)           # Compute coefficients (IV)
    ξ_ = δ_ - X_ * β_                           # Compute errors
    return ξ_, β_
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;objective-function&#34;&gt;Objective Function&lt;/h3&gt;
&lt;p&gt;We now have all the ingredients to set up the GMM objective function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function GMM(varζ_::Number)::Tuple
    &amp;quot;&amp;quot;&amp;quot;Compute GMM objective function&amp;quot;&amp;quot;&amp;quot;
    δ_ = compute_delta(q_, X_, ζ_ * varζ_, T)   # Compute deltas
    ξ_, β_ = compute_xi(X_, IV_, δ_)            # Compute residuals
    gmm = ξ_&#39; * Z_ * Z_&#39; * ξ_ / length(ξ_)^2    # Compute ortogonality condition
    return gmm, β_
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;estimation-1&#34;&gt;Estimation (1)&lt;/h3&gt;
&lt;p&gt;First, we need to set up our objects&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Retrieve data
T = Int.(df.t)
X_ = [df.x1 df.x2 df.p]
q_ = df.q
q0_ = df.q0
IV_ = [df.x1 df.x2 df.w]
Z_ = [df.x1 df.x2 df.z1 df.z2]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;estimation-2&#34;&gt;Estimation (2)&lt;/h3&gt;
&lt;p&gt;What would a logit regression estimate?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Compute logit estimate
y = log.(df.q) - log.(df.q0);
β_logit = inv(IV_&#39; * X_) * (IV_&#39; * y);
print(&amp;quot;Estimated logit coefficients: $β_logit&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated logit coefficients: [2.063144844221613, 1.2888511782561123, -0.9824308271558686]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;estimation-3&#34;&gt;Estimation (3)&lt;/h3&gt;
&lt;p&gt;We can now run the BLP machinery&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Draw shocks (less)
ζ_ = [rand(Normal(0,1), 1, i); zeros(K, i)];

# Minimize GMM objective function
varζ_ = optimize(x -&amp;gt; GMM(x[1])[1], [2.0], LBFGS()).minimizer[1];
β_blp = GMM(varζ_)[2];
print(&amp;quot;Estimated BLP coefficients: $β_blp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated BLP coefficients: [0.549234645269979, 1.1243451127088748, -0.6229637255651461]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;references-references&#34;&gt;References [references]&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;
markdown=&#34;1&#34;&gt;
&lt;div id=&#34;ref-berry1995automobile&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Berry, Steven, James Levinsohn, and Ariel Pakes. 1995. “Automobile
Prices in Market Equilibrium.” &lt;em&gt;Econometrica: Journal of the Econometric
Society&lt;/em&gt;, 841–90.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Coding: Rust (1987)</title>
      <link>https://matteocourthoud.github.io/course/empirical-io/17_rust_1987/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/course/empirical-io/17_rust_1987/</guid>
      <description>&lt;h3 id=&#34;setting&#34;&gt;Setting&lt;/h3&gt;
&lt;p&gt;From Rust (&lt;a href=&#34;#ref-rust1988maximum&#34;&gt;1988&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;An agent owns a fleet to buses&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Buses get old over time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The older the bus is, the most costly it is to maintain&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The agent can decide to replace the bus engine with a new one, at a
cost&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic trade-off&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;What is the best moment to replace the engine?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You don’t want to replace an engine too early&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;doesn’t change much&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You don’t want to replace an engine too late&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;avoid unnecessary maintenance costs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;state&#34;&gt;State&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;State&lt;/strong&gt;: mileage of the bus&lt;/p&gt;
&lt;p&gt;$$s_t \in \lbrace 1, &amp;hellip;, 10 \rbrace $$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;State transitions&lt;/strong&gt;: with probability $\lambda$ the mileage of the
bus increases&lt;/p&gt;
&lt;p&gt;$$
s_{t+1} = \begin{cases}
\min \lbrace s_t + 1,10 \rbrace  &amp;amp; \text { with probability } \lambda \newline
s_t &amp;amp; \text { with probability } 1 - \lambda
\end{cases}
$$&lt;/p&gt;
&lt;p&gt;Note that $\lambda$ does not depend on the value of the state&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;actions&#34;&gt;Actions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Action&lt;/strong&gt;: replacement decision $$
a_t \in \lbrace 0, 1 \rbrace
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Payoffs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Per-period maintenance cost&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cost of replacement $$
u\left(s_{t}, a_{t}, \epsilon_{1 t}, \epsilon_{2 t} ; \theta\right)=
\begin{cases}
-\theta_{1} s_{t}-\theta_{2} s_{t}^{2}+\epsilon_{0 t}, &amp;amp; \text { if } a_{t}=0 \newline
-\theta_{3} + \epsilon_{1t}, &amp;amp; \text { if } a_{t}=1
\end{cases}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solving-the-model&#34;&gt;Solving the Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Start with an initial expected value function $V(s_t)=0$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the alternative-specific value function $$
\bar V(s_t) = \begin{cases}
-\theta_1 s_t - \theta_2 s_t^2 + \beta \Big[(1-\lambda) V(s_t) + \lambda V(\min \lbrace s_t+1,10 \rbrace ) \Big] , &amp;amp; \text { if } a_t=0 \newline
-\theta_3 + \beta \Big[(1-\lambda) V(0) + \lambda V(1) \Big] , &amp;amp; \text { if } a_t=1
\end{cases}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the new expected value function $$
V&amp;rsquo;(a_t) = \log \Big( e^{\bar V(a_t|s_t=0)} + e^{\bar V(a_t|s_t=1)} \Big)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat until convergence&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;code&#34;&gt;Code&lt;/h3&gt;
&lt;p&gt;First we set the parameter values.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Set parameters
θ = [0.13; -0.004; 3.1];
λ = 0.82;
β = 0.95;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we set the state space.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# State space
k = 10;
s = Vector(1:k);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;static-utility&#34;&gt;Static Utility&lt;/h3&gt;
&lt;p&gt;First, we can compute static utility. $$
u\left(s_{t}, a_{t}, \epsilon_{1 t}, \epsilon_{2 t} ; \theta\right)=
\begin{cases}
-\theta_{1} s_{t}-\theta_{2} s_{t}^{2}+\epsilon_{0 t}, &amp;amp; \text { if } a_{t}=0 \newline
-\theta_{3} + \epsilon_{1 t}, &amp;amp; \text { if } a_{t}=1
\end{cases}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function compute_U(θ::Vector, s::Vector)::Matrix
    &amp;quot;&amp;quot;&amp;quot;Compute static utility&amp;quot;&amp;quot;&amp;quot;
    u1 = - θ[1]*s - θ[2]*s.^2       # Utility of not investing
    u2 = - θ[3]*ones(size(s))       # Utility of investing
    U = [u1 u2]                     # Combine in a matrix
    return U
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;value-function&#34;&gt;Value Function&lt;/h3&gt;
&lt;p&gt;We can now set up the value function iteration&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function compute_Vbar(θ::Vector, λ::Number, β::Number, s::Vector)::Matrix
    &amp;quot;&amp;quot;&amp;quot;Compute value function by Bellman iteration&amp;quot;&amp;quot;&amp;quot;
    k = length(s)                                 # Dimension of the state space
    U = compute_U(θ, s)                           # Static utility
    index_λ = Int[1:k [2:k; k]];                  # Mileage index
    index_A = Int[1:k ones(k,1)];                 # Investment index
    γ = Base.MathConstants.eulergamma             # Euler&#39;s gamma

    # Iterate the Bellman equation until convergence
    Vbar = zeros(k, 2);
    Vbar1 = Vbar;
    dist = 1;
    iter = 0;
    while dist&amp;gt;1e-8
        V = γ .+ log.(sum(exp.(Vbar), dims=2))     # Compute value
        expV = V[index_λ] * [1-λ; λ]               # Compute expected value
        Vbar1 =  U + β * expV[index_A]             # Compute v-specific
        dist = max(abs.(Vbar1 - Vbar)...);         # Check distance
        iter += 1;
        Vbar = Vbar1                               # Update value function
    end
    return Vbar
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;solving-the-model-1&#34;&gt;Solving the Model&lt;/h3&gt;
&lt;p&gt;We can now solve for the value function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Compute value function
V_bar = compute_Vbar(θ, λ, β, s);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;dgp&#34;&gt;DGP&lt;/h3&gt;
&lt;p&gt;Now that we know how to compute the equilibrium, we can simulate the
data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function generate_data(θ::Vector, λ::Number, β::Number, s::Vector, N::Int)::Tuple
    &amp;quot;&amp;quot;&amp;quot;Generate data from primitives&amp;quot;&amp;quot;&amp;quot;
    Vbar = compute_Vbar(θ, λ, β, s)             # Solve model
    ε = rand(Gumbel(0,1), N, 2)                 # Draw shocks
    St = rand(s, N)                             # Draw states
    A = (((Vbar[St,:] + ε) * [-1;1]) .&amp;gt; 0)      # Compute investment decisions
    δ = (rand(Uniform(0,1), N) .&amp;lt; λ)            # Compute mileage shock
    St1 = min.(St .* (A.==0) + δ, max(s...))    # Compute neSr state
    df = DataFrame(St=St, A=A, St1=St1)         # Dataframe
    CSV.write(&amp;quot;../data/rust.csv&amp;quot;, df)
    return St, A, St1
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;generate-the-data&#34;&gt;Generate the DAta&lt;/h3&gt;
&lt;p&gt;We can now generate the data&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Generate data
N = Int(1e5);
St, A, St1 = generate_data(θ, λ, β, s, N);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How many investment decisions do we observe?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;print(&amp;quot;we observe &amp;quot;, sum(A), &amp;quot; investment decisions in &amp;quot;, N, &amp;quot; observations&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## we observe 19207 investment decisions in 100000 observations
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;the-data&#34;&gt;The Data&lt;/h3&gt;
&lt;p&gt;What does the data look like?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Read data
df = fread(&amp;quot;../data/rust.csv&amp;quot;)
kable(df[1:6,], digits=4)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right&#34;&gt;St&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;A&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;St1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;FALSE&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;9&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;TRUE&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;8&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;TRUE&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;FALSE&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;9&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;FALSE&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;FALSE&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;estimation---lambda&#34;&gt;Estimation - Lambda&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First we can estimate the value of lambda as the probability of
mileage increase&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Conditional on not investing&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And not being in the last state (mileage cannot increase any more)&lt;/p&gt;
&lt;p&gt;$$
\hat \lambda = \mathbb E_n \Big[ (s_{t+1}-s_t) \mid a_{t}=0 \wedge s_{t}&amp;lt;10 \Big]
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Estimate lambda
Δ = St1 - St;
λ_ = mean(Δ[(A.==0) .&amp;amp; (St.&amp;lt;10)]);

print(&amp;quot;Estimated lambda: $λ_ (true = $λ)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated lambda: 0.8206570869594549 (true = 0.82)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;estimation---theta&#34;&gt;Estimation - Theta&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Take a parameter guess $\theta_0$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the alternative-specific value function
$\bar V(s_t ; \hat \lambda, \theta_0)$ by iteration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the implied choice probabilities&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the likelihood $$
\mathcal{L}(\theta) = \prod_{t=1}^{T}\left(\hat{\operatorname{Pr}}\left(a=1 \mid s_{t}, \theta\right) \mathbb{1}\left(a_{t}=1\right)+\left(1-\hat{\operatorname{Pr}}\left(a=0 \mid s_{t}, \theta\right)\right) \mathbb{1}\left(a_{t}=0\right)\right)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat the above to find a minimum of the likelihood function&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;likelihood-function&#34;&gt;Likelihood Function&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function logL_Rust(θ0::Vector, λ::Number, β::Number, s::Vector, St::Vector, A::BitVector)::Number
    &amp;quot;&amp;quot;&amp;quot;Compute log-likelihood functionfor Rust problem&amp;quot;&amp;quot;&amp;quot;
    # Compute value
    Vbar = compute_Vbar(θ0, λ_, β, s)

    # Expected choice probabilities
    EP = exp.(Vbar[:,2]) ./ (exp.(Vbar[:,1]) + exp.(Vbar[:,2]))

    # Likelihood
    logL = sum(log.(EP[St[A.==1]])) + sum(log.(1 .- EP[St[A.==0]]))
    return -logL
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can check the likelihood at the true value:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# True likelihood value
logL_trueθ = logL_Rust(θ, λ, β, s, St, A);
print(&amp;quot;The likelihood at the true parameter is $logL_trueθ&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The likelihood at the true parameter is 45937.866092460084
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;estimating-theta&#34;&gt;Estimating Theta&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Select starting values
θ0 = Float64[0,0,0];

# Optimize
θ_R = optimize(x -&amp;gt; logL_Rust(x, λ, β, s, St, A), θ0).minimizer;
print(&amp;quot;Estimated thetas: $θ_R (true = $θ)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated thetas: [0.12063838656559037, -0.003220197034620527, 3.0865668144650487] (true = [0.13, -0.004, 3.1])
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;starting-values&#34;&gt;Starting Values&lt;/h3&gt;
&lt;p&gt;Starting values are important!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Not all initial values are equally good
θ0 = Float64[1,1,1];

# Optimize
θ_R2 = optimize(x -&amp;gt; logL_Rust(x, λ, β, s, St, A), θ0).minimizer;
print(&amp;quot;Estimated thetas: $θ_R2 (true = $θ)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated thetas: [1.0, 1.0, 1.0] (true = [0.13, -0.004, 3.1])
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hotz--miller&#34;&gt;Hotz &amp;amp; Miller&lt;/h2&gt;
&lt;h3 id=&#34;recap&#34;&gt;Recap&lt;/h3&gt;
&lt;p&gt;Hotz &amp;amp; Miller estimation procedure works as follows&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Estimate the CCPs from the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hotz &amp;amp; Miller inversion $$
\hat V = \Big[I - \beta \ \sum_a P_a .* T_a \Big]^{-1} \ * \ \left( \sum_a P_a \ .* \ \bigg[ u_a + \mathbb E [\epsilon_a] \bigg] \right)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute EP from EV $$
\hat \Pr(a=1 ; \theta) = \frac{\exp (u_1 +\beta T_1 \hat V )}{\sum_{a} \exp (u_a +\beta T_a \hat V )}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the objective function: the (log)likelihood $$
\mathcal{L}(\theta) = \prod_{t=1}^{T}\left(\hat{\operatorname{Pr}}\left(a=1 \mid s_{t}; \theta\right) \mathbb{1}\left(a_{t}=1\right)+\left(1-\hat{\operatorname{Pr}}\left(a=0 \mid s_{t}; \theta\right)\right) \mathbb{1}\left(a_{t}=0\right)\right)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;ccps&#34;&gt;CCPs&lt;/h3&gt;
&lt;p&gt;First, we need to estimate the &lt;strong&gt;Conditional Choice Proabilities (CCP)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;can be done non-parametrically&lt;/li&gt;
&lt;li&gt;i.e. just look at the frequency of investment in each state&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Estimate CCP
P = [mean(A[St.==i]) for i=s];
CCP = [(1 .- P) P]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 10×2 Array{Float64,2}:
##  0.952419  0.0475814
##  0.923046  0.0769535
##  0.894443  0.105557
##  0.853306  0.146694
##  0.819293  0.180707
##  0.788935  0.211065
##  0.747248  0.252752
##  0.717915  0.282085
##  0.6947    0.3053
##  0.678452  0.321548
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;transition-probabilities&#34;&gt;Transition Probabilities&lt;/h3&gt;
&lt;p&gt;NeSr, we need $T$, the matrices of transition probabilities, conditional
on the investment choice.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function compute_T(k::Int, λ_::Number)::Array
    &amp;quot;&amp;quot;&amp;quot;Compute transition matrix&amp;quot;&amp;quot;&amp;quot;
    T = zeros(k, k, 2);

    # Conditional on not investing
    T[k,k,1] = 1;
    for i=1:k-1
        T[i,i,1] = 1-λ_
        T[i,i+1,1] = λ_
    end

    # Conditional on investing
    T[:,1,2] .= 1-λ_;
    T[:,2,2] .= λ_;

    return(T)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;t&#34;&gt;T&lt;/h3&gt;
&lt;p&gt;What form does the transition matrix $T$ take?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Compute T
T = compute_T(k, λ_);

# Conditional on not investing
T[:,:,1]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 10×10 Array{Float64,2}:
##  0.179343  0.820657  0.0       0.0       …  0.0       0.0       0.0
##  0.0       0.179343  0.820657  0.0          0.0       0.0       0.0
##  0.0       0.0       0.179343  0.820657     0.0       0.0       0.0
##  0.0       0.0       0.0       0.179343     0.0       0.0       0.0
##  0.0       0.0       0.0       0.0          0.0       0.0       0.0
##  0.0       0.0       0.0       0.0       …  0.0       0.0       0.0
##  0.0       0.0       0.0       0.0          0.820657  0.0       0.0
##  0.0       0.0       0.0       0.0          0.179343  0.820657  0.0
##  0.0       0.0       0.0       0.0          0.0       0.179343  0.820657
##  0.0       0.0       0.0       0.0          0.0       0.0       1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;t-2&#34;&gt;T (2)&lt;/h3&gt;
&lt;p&gt;Instead, the transitions conditional on investing are&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# T Conditional on investing
T[:,:,2]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 10×10 Array{Float64,2}:
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
##  0.179343  0.820657  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;hotz--miller-inversion&#34;&gt;Hotz &amp;amp; Miller Inversion&lt;/h3&gt;
&lt;p&gt;We now have all the pieces to compute the &lt;strong&gt;expected value function&lt;/strong&gt;
$V$ through the Hotz &amp;amp; Miller &lt;strong&gt;inversion&lt;/strong&gt;. $$
\hat V = \left[I - \beta \ \sum_a P_a .* T_a \right]^{-1} \ * \ \left( \sum_a P_a \ .* \ \bigg[ u_a + \mathbb E [\epsilon_a] \bigg] \right)
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function HM_inversion(CCP::Matrix, T::Array, U::Matrix, β::Number)::Vector
    &amp;quot;&amp;quot;&amp;quot;Perform HM inversion&amp;quot;&amp;quot;&amp;quot;

    # Compute LHS (to be inverted)
    γ = Base.MathConstants.eulergamma
    LEFT = I - β .* (CCP[:,1] .* T[:,:,1] + CCP[:,2] .* T[:,:,2])

    # Compute LHS (not to be inverted)
    RIGHT = γ .+ sum(CCP .* (U .- log.(CCP)) , dims=2)

    # Compute V
    EV_ = inv(LEFT) * RIGHT
    return vec(EV_)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;from-ev-to-ep&#34;&gt;From EV to EP&lt;/h3&gt;
&lt;p&gt;We can now compute the expected policy function from the expected value
function $$
\hat \Pr(a=1 ; \theta) = \frac{\exp (u_1 +\beta T_1 \hat V )}{\sum_{a} \exp (u_a +\beta T_a \hat V )}
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function from_EV_to_EP(EV_::Vector, T::Array, U::Matrix, β::Number)::Vector
    &amp;quot;&amp;quot;&amp;quot;Compute expected policy from expected value&amp;quot;&amp;quot;&amp;quot;
    E = exp.( U + β .* [(T[:,:,1] * EV_) (T[:,:,2] * EV_)] )
    EP_ = E[:,2] ./ sum(E, dims=2)
    return vec(EP_)
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;likelihood&#34;&gt;Likelihood&lt;/h3&gt;
&lt;p&gt;We now have all the pieces to build the likelihood function $$
\mathcal{L}(\theta) = \prod_{t=1}^{T} \left(\hat \Pr \left(a=1 \mid s_{t}; \theta\right) \mathbb{1} \left(a_{t}=1\right) + \left(1-\hat \Pr \left(a=0 \mid s_{t}; \theta\right)\right) \mathbb{1} \left(a_{t}=0\right)\right)
$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function logL_HM(θ0::Vector, λ::Number, β::Number, s::Vector, St::Vector, A::BitVector, T::Array, CCP::Matrix)::Number
    &amp;quot;&amp;quot;&amp;quot;Compute log-likelihood function for HM problem&amp;quot;&amp;quot;&amp;quot;
    # Compute static utility
    U = compute_U(θ0, s)

    # Espected value by inversion
    EV_ = HM_inversion(CCP, T, U, β)

    # Implies choice probabilities
    EP_ = from_EV_to_EP(EV_, T, U, β)

    # Likelihood
    logL = sum(log.(EP_[St[A.==1]])) + sum(log.(1 .- EP_[St[A.==0]]))
    return -logL
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;estimation&#34;&gt;Estimation&lt;/h3&gt;
&lt;p&gt;We can now estimate the parameters&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Optimize
θ0 = Float64[0,0,0];
θ_HM = optimize(x -&amp;gt; logL_HM(x, λ, β, s, St, A, T, CCP), θ0).minimizer;
print(&amp;quot;Estimated thetas: $θ_HM (true = $θ)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated thetas: [0.12064911403839335, -0.003220614484856523, 3.086621855583483] (true = [0.13, -0.004, 3.1])
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;aguirregabiria-mira-2002&#34;&gt;Aguirregabiria, Mira (2002)&lt;/h3&gt;
&lt;p&gt;With Hotz and Miller, we have generated a mapping of the form&lt;/p&gt;
&lt;p&gt;$$
\bar P(\cdot ; \theta) = g(h(\hat P(\cdot) ; \theta); \theta)
$$&lt;/p&gt;
&lt;p&gt;Aguirregabiria and Mira (&lt;a href=&#34;#ref-aguirregabiria2002swapping&#34;&gt;2002&lt;/a&gt;): why
don’t we iterate it?&lt;/p&gt;
&lt;h3 id=&#34;am-likelihood-function&#34;&gt;AM Likelihood Function&lt;/h3&gt;
&lt;p&gt;The likelihood function in Aguirregabiria and Mira
(&lt;a href=&#34;#ref-aguirregabiria2002swapping&#34;&gt;2002&lt;/a&gt;) is extremely similar to Hotz
and Miller (&lt;a href=&#34;#ref-hotz1993conditional&#34;&gt;1993&lt;/a&gt;)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function logL_AM(θ0::Vector, λ::Number, β::Number, s::Vector, St::Vector, A::BitVector, T::Array, CCP::Matrix, K::Int)::Number
    &amp;quot;&amp;quot;&amp;quot;Compute log-likelihood function for AM problem&amp;quot;&amp;quot;&amp;quot;
    # Compute static utility
    U = compute_U(θ0, s)
    EP_ = CCP[:,2]

    # Iterate HM mapping
    for _=1:K
        EV_ = HM_inversion(CCP, T, U, β)    # Expected value by inversion
        EP_ = from_EV_to_EP(EV_, T, U, β)   # Implies choice probabilities
        CCP = [(1 .- EP_) EP_]
    end

    # Likelihood
    logL = sum(log.(EP_[St[A.==1]])) + sum(log.(1 .- EP_[St[A.==0]]))
    return -logL
end;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;estimation-1&#34;&gt;Estimation&lt;/h3&gt;
&lt;p&gt;We can now estimate the parameters&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Set number of iterations
K = 2;

# Optimize
θ0 = Float64[0,0,0];
θ_AM = optimize(x -&amp;gt; logL_AM(x, λ, β, s, St, A, T, CCP, K), θ0).minimizer;
print(&amp;quot;Estimated thetas: $θ_AM (true = $θ)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimated thetas: [0.12063890836521114, -0.0032202282942220464, 3.086571461772538] (true = [0.13, -0.004, 3.1])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not much changes in our case.&lt;/p&gt;
&lt;h3 id=&#34;speed&#34;&gt;Speed&lt;/h3&gt;
&lt;p&gt;We can compare the methods in terms of speed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;# Compare speed
θ0 = Float64[0,0,0];
optimize(x -&amp;gt; logL_Rust(x, λ, β, s, St, A), θ0).time_run
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.5477378368377686
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;optimize(x -&amp;gt; logL_HM(x, λ, β, s, St, A, T, CCP), θ0).time_run
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.3244161605834961
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;optimize(x -&amp;gt; logL_AM(x, λ, β, s, St, A, T, CCP, K), θ0).time_run
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.35499119758605957
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even in this simple example with a very small state space, the
difference is significant.&lt;/p&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;references-references&#34;&gt;References [references]&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;
markdown=&#34;1&#34;&gt;
&lt;div id=&#34;ref-aguirregabiria2002swapping&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Aguirregabiria, Victor, and Pedro Mira. 2002. “Swapping the Nested Fixed
Point Algorithm: A Class of Estimators for Discrete Markov Decision
Models.” &lt;em&gt;Econometrica&lt;/em&gt; 70 (4): 1519–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hotz1993conditional&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Hotz, V Joseph, and Robert A Miller. 1993. “Conditional Choice
Probabilities and the Estimation of Dynamic Models.” &lt;em&gt;The Review of
Economic Studies&lt;/em&gt; 60 (3): 497–529.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rust1988maximum&#34; class=&#34;csl-entry&#34; markdown=&#34;1&#34;&gt;
&lt;p&gt;Rust, John. 1988. “Maximum Likelihood Estimation of Discrete Control
Processes.” &lt;em&gt;SIAM Journal on Control and Optimization&lt;/em&gt; 26 (5): 1006–24.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
