<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="A short guide to a simple and powerful alternative to the bootstrap
In causal inference we do not want just to compute treatment effect, we also want to do inference (duh!" />

  
  <link rel="alternate" hreflang="en-us" href="https://matteocourthoud.github.io/post/bayesian_bootstrap/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#003f5c" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.4f7182ca394d705ee32d9d7750e9aa1d.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-144780600-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-144780600-1', { 'anonymize_ip': true });
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://matteocourthoud.github.io/post/bayesian_bootstrap/" />

  
  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Matteo Courthoud" />
  <meta property="og:url" content="https://matteocourthoud.github.io/post/bayesian_bootstrap/" />
  <meta property="og:title" content="The Bayesian Bootstrap | Matteo Courthoud" />
  <meta property="og:description" content="A short guide to a simple and powerful alternative to the bootstrap
In causal inference we do not want just to compute treatment effect, we also want to do inference (duh!" /><meta property="og:image" content="https://matteocourthoud.github.io/post/bayesian_bootstrap/featured.png" />
    <meta property="twitter:image" content="https://matteocourthoud.github.io/post/bayesian_bootstrap/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2023-07-10T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2023-07-10T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://matteocourthoud.github.io/post/bayesian_bootstrap/"
  },
  "headline": "The Bayesian Bootstrap",
  
  "image": [
    "https://matteocourthoud.github.io/post/bayesian_bootstrap/featured.png"
  ],
  
  "datePublished": "2023-07-10T00:00:00Z",
  "dateModified": "2023-07-10T00:00:00Z",
  
  "publisher": {
    "@type": "Organization",
    "name": "Matteo Courthoud",
    "logo": {
      "@type": "ImageObject",
      "url": "https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "A short guide to a simple and powerful alternative to the bootstrap\nIn causal inference we do not want just to compute treatment effect, we also want to do inference (duh!"
}
</script>

  

  

  
  
  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js" integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css" integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#003f5c",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#003f5c"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "/privacy/"
      }
    })});
  </script>


  





  <title>The Bayesian Bootstrap | Matteo Courthoud</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="cf14b1dea595f3b0054773d1801d4983" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.66d3e0fff6d32c4ece05adee927fbd96.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Courses</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/course/ml-econ/"><span>Machine Learning for Economics</span></a>
            
              <a class="dropdown-item" href="/course/data-science/"><span>Data Science with Python</span></a>
            
              <a class="dropdown-item" href="/course/empirical-io/"><span>PhD Industrial Organization</span></a>
            
              <a class="dropdown-item" href="/course/metrics/"><span>PhD Econometrics</span></a>
            
              <a class="dropdown-item" href="https://pp4rs.github.io/"><span>Programming Practices for Research</span></a>
            
          </div>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/cv"><span>CV</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      

      
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <div class="container-fluid docs">
  <div class="row">

    <div class="col-xl-2 col-lg-2 d-none d-xl-block d-lg-block empty">
    </div>

    <div class="col-2 col-xl-2 col-lg-2 d-none d-lg-block docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#the-bootstrap">The Bootstrap</a></li>
    <li><a href="#the-bayesian-bootstrap">The Bayesian Bootstrap</a></li>
    <li><a href="#examples">Examples</a>
      <ul>
        <li><a href="#mean-of-a-skewed-distribution">Mean of a Skewed Distribution</a></li>
        <li><a href="#no-weighting-no-problem">No Weighting? No Problem</a></li>
        <li><a href="#logistic-regression-with-rare-outcome">Logistic Regression with Rare Outcome</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a>
      <ul>
        <li><a href="#references">References</a></li>
        <li><a href="#code">Code</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>

    <main class="col-xl-8 col-lg-8 docs-content" role="main">
        <article class="article">
        




















  


<div class="article-container pt-3">
  <h1>The Bayesian Bootstrap</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Jul 10, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  
  
  
  

  
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 1540px; max-height: 874px;">
  <div style="position: relative">
    <img src="/post/bayesian_bootstrap/featured.png" alt="" class="featured-image">
    
  </div>
</div>


        <div class="article-container">
          <div class="article-style" align="justify">
            <p><em>A short guide to a simple and powerful alternative to the bootstrap</em></p>
<p>In causal inference we do not want just to compute treatment effect, we also want to do <strong>inference</strong> (duh!). In some cases, it&rsquo;s very easy to compute the asymptotic difference of an estimator, thanks to the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem" target="_blank" rel="noopener"><strong>central limit theorem</strong></a>. This is the case of computing the average treatment effect in AB tests or randomized controlled trials, for example. However, in other settings, inference is more <strong>complicated</strong>. The most frequent setting is the computation of quantities that are not sums or averages, such as the median treatment effect, for example. In these cases, we cannot rely on the central limit theorem. What can we do then?</p>
<p>The <strong>bootstrap</strong> is the answer! It is a very powerful procedure to compute the distribution of an estimator, without needing any knowledge of the data generating process. It is also very <strong>intuitive and simple</strong> to implement: just re-sample your data with replacement a lot of times and compute your estimator on the re-computed sample.</p>
<p>Can we do better? The answer is yes! The <strong>Bayesian Bootstrap</strong> is a powerful procedure that in a lot of setting performs <strong>better</strong> than the bootstrap. In particular, it&rsquo;s usually faster, can give tighter confidence intervals and prevents a lot of corner cases of the bootstrap. In this article we are going to explore this simple but powerful procedure more in detail.</p>
<h2 id="the-bootstrap">The Bootstrap</h2>
<p>Bootstrap is a procedure to compute properties of an estimator by random <strong>re-sampling with replacement</strong> from the data. It was first introduced by <a href="https://www.jstor.org/stable/2958830" target="_blank" rel="noopener">Efron (1979)</a>. The procedure is very simple and consists in the following steps.</p>
<p>Suppose you have access to an i.i.d. sample $\lbrace X_i \rbrace_{i=1}^n$ and you want to compute a statistic $\theta$ using an estimator $\hat \theta(X)$. You can approximate the distribution of $\hat \theta$ by</p>
<ol>
<li>Sample $n$ observations with replacement from your sample $\lbrace \tilde X_i \rbrace_{i=1}^n$</li>
<li>Compute the estimator $\hat \theta_{bootstrap}(\tilde X)$</li>
<li>Repeat steps 1 and 2 a large number of times</li>
</ol>
<p>The distribution of $\hat \theta_{bootstrap}$ is a good approximation of the distribution of $\hat \theta$.</p>
<p><strong>Why is the bootstrap so powerful?</strong></p>
<p>First of all, it&rsquo;s <strong>easy to implement</strong>. It does not require you to do anything more than what you were already doing: estimating $\theta$. You just need to do it <em>a lot of times</em>. Indeed, the main disadvantage of the bootstrap is its <strong>computational speed</strong>. If estimating $\theta$ once is slow, bootstrapping it is prohibitive.</p>
<p>Second, the bootstrap makes <strong>no distributional assumption</strong>. It only assumes a representative sample from your population, where observations are independent from each other. This assumption might be violated when observations are tightly connected with each other, such when studying social networks.</p>
<p><strong>Is bootstrap just weighting?</strong></p>
<p>In the end, what we are doing is assigning <strong>integer weights</strong> to our observations, such that their sum adds up to $n$. Such distribution is the <a href="https://en.wikipedia.org/wiki/Multinomial_distribution" target="_blank" rel="noopener"><strong>multinomial distribution</strong></a>.</p>
<p>Let&rsquo;s have a look at what a multinomial distribution look like by drawing a sample of size 10.000.</p>
<pre><code class="language-python">%matplotlib inline
%config InlineBackend.figure_format = 'retina'
</code></pre>
<pre><code class="language-python">from src.utils import *
</code></pre>
<pre><code class="language-python">N = 10_000
np.random.seed(1)
bootstrap_weights = np.random.multinomial(N, np.ones(N)/N)
np.sum(bootstrap_weights)
</code></pre>
<pre><code>10000
</code></pre>
<p>First of all, we check that indeed the weights sum up to 1000, or equivalently, we generated a re-sample of the same size of the data.</p>
<p>We can now plot the <strong>distribution of weights</strong>.</p>
<pre><code class="language-python">sns.countplot(bootstrap_weights, color='C0').set(title='Bootstrap Weights');
</code></pre>
<p><img src="img/bayesian_bootstrap_9_0.png" alt="png"></p>
<p>As we can see, around 3600 observations got zero weight, however a couple of observations got a weights of 6. Or equivalently, around 3600 observations did not get re-sampled while a couple of observations got samples as many as 6 times.</p>
<p>Now you might have a spontaneous question: why not use <strong>continuous weights</strong> instead of discrete ones?</p>
<p>Very good question! The <strong>Bayesian Bootstrap</strong> is the answer.</p>
<h2 id="the-bayesian-bootstrap">The Bayesian Bootstrap</h2>
<p>The Bayesian bootstrap was introduced by <a href="https://www.jstor.org/stable/2240875" target="_blank" rel="noopener">Rubin (1981)</a> and it&rsquo;s based on a very simple <strong>idea</strong>: why not draw a smoother distribution of weights? The continuous equivalent of the multinomial distribution is the <a href="https://en.wikipedia.org/wiki/Dirichlet_distribution" target="_blank" rel="noopener"><strong>Dirichelet distribution</strong></a>. Below I plot the probability distribution of Multinomial and Dirichelet weights for a single observation (they are Poisson and Gamma distributed, respectively).</p>
<pre><code class="language-python">from scipy.stats import gamma, poisson

x1 = np.arange(0, 8, 0.001)
x2 = np.arange(0, 8, 1)
sns.barplot(x2, poisson.pmf(x2, mu=1), color='C0', label='Multinomial Weights'); 
plt.plot(x1, gamma.pdf(x1, a=1.0001), color='C1', label='Dirichlet Weights');
plt.legend()
plt.title('Distribution of Bootstrap Weights');
</code></pre>
<p><img src="img/bayesian_bootstrap_13_0.png" alt="png"></p>
<p>The Bayesian Bootstrap has <strong>many advantages</strong>.</p>
<ul>
<li>The first and most intuitive one is that it delivers estimates that are much more <strong>smooth</strong> than the normal bootstrap, because of its continuous weighting scheme.</li>
<li>Moreover, the continuous weighting scheme <strong>prevents corner cases</strong> from emerging, since no observation will ever receive zero weight. For example, in linear regression, no problem of <a href="https://en.wikipedia.org/wiki/Multicollinearity" target="_blank" rel="noopener">collinearity</a> emerges, if there wasn&rsquo;t one in the original sample.</li>
<li>Lastly, being a Bayesian method, we gain <strong>interpretation</strong>: the estimated distribution of the estimator can be interpreted as the <a href="https://en.wikipedia.org/wiki/Posterior_probability" target="_blank" rel="noopener">posterior distribution</a> with an <a href="https://en.wikipedia.org/wiki/Prior_probability" target="_blank" rel="noopener">uninformative prior</a>.</li>
</ul>
<p>Let&rsquo;s now draw a set a Dirichlet weights.</p>
<pre><code class="language-python">bayesian_weights = np.random.dirichlet(alpha=np.ones(N), size=1)[0] * N
np.sum(bayesian_weights)
</code></pre>
<pre><code>10000.000000000005
</code></pre>
<p>The weights naturally sum to (approximately) 1, so we have to scale them by a factor N.</p>
<p>As before, we can plot the distribution of weights, with the difference that now we have continuous weights, so we have to approximate the distribution.</p>
<pre><code class="language-python">sns.histplot(bayesian_weights, color='C1').set(title='Dirichlet Weights');
</code></pre>
<p><img src="img/bayesian_bootstrap_17_0.png" alt="png"></p>
<p>As you might have noticed, the Dirichelet distirbution has a parameter $\alpha$ that we have set to 1 for all observations. What does it do?</p>
<p>The $\alpha$ parameter essentially governs both the absolute and relative probability of being samples. Increasing $\alpha$ for all observations makes the distribution less skewed so that all observations have a more similar weight. For $\alpha \to \infty$, all observations receiver the same weight and we are back to the original sample.</p>
<p>How should we pick $\alpha$? <a href="https://link.springer.com/book/10.1007/978-1-4612-0795-5" target="_blank" rel="noopener">Shao and Tu (1995)</a> suggest the following.</p>
<blockquote>
<p><em>The distribution of the random weight vector does not have to be restricted to the Diri(l, &hellip; , 1). Later investigations found that the weights having a scaled Diri(4, &hellip; ,4) distribution give better approximations (Tu and Zheng, 1987)</em></p>
</blockquote>
<p>Let&rsquo;s have a look at how a Dirichelet distribution with $\alpha = 4$ for all observations compare to our previous distribution with $\alpha = 1$ for all observations.</p>
<pre><code class="language-python">bayesian_weights2 = np.random.dirichlet(np.ones(N) * 4, 1)[0] * N
sns.histplot(bayesian_weights, color='C1')
sns.histplot(bayesian_weights2, color='C2').set(title='Comparing Dirichlet Weights');
plt.legend([r'$\alpha = 1$', r'$\alpha = 4$']);
</code></pre>
<p><img src="img/bayesian_bootstrap_19_0.png" alt="png"></p>
<p>The new distribution is much less skewed and more concentrated around the average value of 1.</p>
<h2 id="examples">Examples</h2>
<p>Let&rsquo;s have a look at a couple of examples, where we compare both inference procedures.</p>
<h3 id="mean-of-a-skewed-distribution">Mean of a Skewed Distribution</h3>
<p>First, let&rsquo;s have a look at one of the simplest and most common estimators: the <strong>sample mean</strong>.</p>
<pre><code class="language-python">np.random.seed(2)
X = pd.Series(np.random.pareto(2, 100))
sns.histplot(X).set(title='Sample from Pareto Distribution');
</code></pre>
<p><img src="img/bayesian_bootstrap_25_0.png" alt="png"></p>
<pre><code class="language-python">def classic_boot(df, estimator, seed=1):
    df_boot = df.sample(n=len(df), replace=True, random_state=seed)
    estimate = estimator(df_boot)
    return estimate
</code></pre>
<pre><code class="language-python">classic_boot(X, np.mean)
</code></pre>
<pre><code>0.7079805545831946
</code></pre>
<pre><code class="language-python">def bayes_boot(df, estimator, seed=1):
    np.random.seed(seed)
    w = np.random.dirichlet(np.ones(len(df)), 1)[0]
    result = estimator(df, weights=w)
    return result
</code></pre>
<pre><code class="language-python">bayes_boot(X, np.average)
</code></pre>
<pre><code>1.0378495251293498
</code></pre>
<pre><code class="language-python">from joblib import Parallel, delayed

def bootstrap(boot_method, df, estimator, K):
    r = Parallel(n_jobs=8)(delayed(boot_method)(df, estimator, seed=i) for i in range(K))
    return r
</code></pre>
<pre><code class="language-python">def compare_boot(df, boot1, boot2, estimator, title, K=1000):
    s1 = bootstrap(boot1, df, estimator, K)
    s2 = bootstrap(boot2, df, estimator, K)
    df = pd.DataFrame({'Estimate': s1 + s2,
                       'Estimator': ['Classic']*K + ['Bayes']*K})
    sns.histplot(data=df, x='Estimate', hue='Estimator')
    plt.legend([f'Bayes:   {np.mean(s2):.2f} ({np.std(s2):.2f})',
                f'Classic: {np.mean(s1):.2f} ({np.std(s1):.2f})'])
    plt.title(f'Bootstrap Estimates of {title}')
</code></pre>
<pre><code class="language-python">compare_boot(X, classic_boot, bayes_boot, np.average, 'Sample Mean')
</code></pre>
<p><img src="img/bayesian_bootstrap_32_0.png" alt="png"></p>
<p>In this setting, both procedures give a very similar answer.</p>
<p>Which one is faster?</p>
<pre><code class="language-python">import time

def compare_time(df, boot1, boot2, estimator, K=1000):
    t1, t2 = np.zeros(K), np.zeros(K)
    for k in range(K):
        
        # Classic bootstrap
        start = time.time()
        boot1(df, estimator)
        t1[k] = time.time() - start
    
        # Bayesian bootstrap
        start = time.time()
        boot2(df, estimator)
        t2[k] = time.time() - start
    
    print(f&quot;Bayes wins {np.mean(t1 &gt; t2)*100}% of the time (by {np.mean((t1 - t2)/t1*100):.2f}%)&quot;)
</code></pre>
<pre><code class="language-python">compare_time(X, classic_boot, bayes_boot, np.average)
</code></pre>
<pre><code>Bayes wins 99.8% of the time (by 82.89%)
</code></pre>
<p>The Bayesian bootstrap is faster than the classical bootstrap 100% of the simulations, and by an impressive 83%!</p>
<h3 id="no-weighting-no-problem">No Weighting? No Problem</h3>
<p>What if we have an estimator that does not accept weights, such as the median? We can do <strong>two-level sampling</strong>.</p>
<pre><code class="language-python">def twolv_boot(df, estimator, seed=1):
    np.random.seed(seed)
    w = np.random.dirichlet(np.ones(len(df))*4, 1)[0]
    df_boot = df.sample(n=len(df)*10, replace=True, weights=w, random_state=seed)
    result = estimator(df_boot)
    return result
</code></pre>
<pre><code class="language-python">np.random.seed(1)
X = pd.Series(np.random.normal(0, 10, 1000))
compare_boot(X, classic_boot, twolv_boot, np.median, 'Sample Median')
</code></pre>
<p><img src="img/bayesian_bootstrap_40_0.png" alt="png"></p>
<p>In this setting, the Bayesian Bootstrap is also <strong>more precise</strong> than the classical bootstrap.</p>
<h3 id="logistic-regression-with-rare-outcome">Logistic Regression with Rare Outcome</h3>
<p>Let&rsquo;s now explore the first of two settings in which the classical bootstrap might fall into <strong>corner cases</strong>. Suppose we observed a feature $x$, normally distributed, and a binary outcome $y$. We are interested in the relationship between the two variables.</p>
<pre><code class="language-python">N = 100
np.random.seed(1)
x = np.random.normal(0, 1, N)
y = np.rint(np.random.normal(x, 1, N) &gt; 2)
df = pd.DataFrame({'x': x, 'y': y})
df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.624345</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.611756</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.528172</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.072969</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.865408</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
<p>In this case, we observe a positive outcome only in 10 observations out of 100.</p>
<pre><code class="language-python">np.sum(df['y'])
</code></pre>
<pre><code>10.0
</code></pre>
<p>Since the outcome is binary, we fit a <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="noopener"><strong>logistic regression</strong></a> model.</p>
<pre><code class="language-python">smf.logit('y ~ x', data=df).fit(disp=False).summary().tables[1]
</code></pre>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   -4.0955</td> <td>    0.887</td> <td>   -4.618</td> <td> 0.000</td> <td>   -5.834</td> <td>   -2.357</td>
</tr>
<tr>
  <th>x</th>         <td>    2.7664</td> <td>    0.752</td> <td>    3.677</td> <td> 0.000</td> <td>    1.292</td> <td>    4.241</td>
</tr>
</table>
<p>Can we bootstrap the distribution of our estimator? Let&rsquo;s try to compute the logistic regression coefficient over 1000 bootstrap samples.</p>
<pre><code class="language-python">estimate_logit = lambda df: smf.logit('y ~ x', data=df).fit(disp=False).params[1]
for i in range(1000):
    try:
        classic_boot(df, estimate_logit, seed=i)
    except Exception as e:
        print(f'Error for bootstrap number {i}: {e}')
</code></pre>
<pre><code>Error for bootstrap number 92: Perfect separation detected, results not available
Error for bootstrap number 521: Perfect separation detected, results not available
Error for bootstrap number 545: Perfect separation detected, results not available
Error for bootstrap number 721: Perfect separation detected, results not available
Error for bootstrap number 835: Perfect separation detected, results not available
</code></pre>
<p>For 5 samples out of 1000, we are <strong>unable</strong> to compute the estimate. This would not have happened with then bayesian bootstrap.</p>
<p>This might seem like an innocuous issue in this case: we can just drop those observations. Let&rsquo;s conclude with a much more dangerous example.</p>
<p>Suppose we observed a binary feature $x$ and a continuous outcome $y$. We are again interested in the relationship between the two variables.</p>
<pre><code class="language-python">N = 100
np.random.seed(1)
x = np.random.binomial(1, 5/N, N)
y = np.random.normal(1 + 2*x, 1, N)
df = pd.DataFrame({'x': x, 'y': y})
df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1.315635</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>-1.022201</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0.693796</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1.827975</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1.230095</td>
    </tr>
  </tbody>
</table>
</div>
<p>Let&rsquo;s compare the two bootstrap estimators of the regression coefficient of $y$ on $x$.</p>
<pre><code class="language-python">estimate_beta = lambda df, **kwargs: smf.wls('y ~ x', data=df, **kwargs).fit().params[1]
compare_boot(df, classic_boot, bayes_boot, estimate_beta, 'beta')
</code></pre>
<p><img src="img/bayesian_bootstrap_55_0.png" alt="png"></p>
<p>The classic bootstrap procedure estimates a 50% larger variance of our estimator. Why? If we look more closely, we seen that in almost 20 re-samples, we get a very unusual estimate of zero!</p>
<p>The problem is that in some samples we might not have have <strong>any observations</strong> with $x=1$. Therefore, in these re-samples, the estimated coefficient is zero. This does not happen with the Bayesian bootstrap, since it does not drop any observation.</p>
<p>The problematic part here is that we are not getting any error message or warning. This bias is very sneaky and could easily go <strong>unnoticed</strong>!</p>
<h2 id="conclusion">Conclusion</h2>
<p>The article was inspired by the following tweet by Brown University professor <a href="https://sites.google.com/site/aboutpeterhull/home" target="_blank" rel="noopener">Peter Hull</a></p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Ok, so I come bearing good news for ~93% of you: esp. those bootstraping complex models (e.g. w/many FEs)<br><br>Instead of resampling, which can be seen as reweighting by a random integer W that may be zero, you can reweight by a random non-zero non-integer W <a href="https://t.co/Rpm1GmomHg">https://t.co/Rpm1GmomHg</a></p>&mdash; Peter Hull (@instrumenthull) <a href="https://twitter.com/instrumenthull/status/1487469316010389516?ref_src=twsrc%5Etfw">January 29, 2022</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Indeed, besides being a simple and intuitive procedure, the Bayesian Bootstrap is not part of the standard econometrics curriculum in economic graduate schools.</p>
<h3 id="references">References</h3>
<p>[1] B. Efron <a href="https://www.jstor.org/stable/2958830" target="_blank" rel="noopener">Bootstrap Methods: Another Look at the Jackknife</a> (1979), <em>The Annals of Statistics</em>.</p>
<p>[2] D. Rubin, <a href="https://www.jstor.org/stable/2240875" target="_blank" rel="noopener">The Bayesian Bootstrap</a> (1981), <em>The Annals of Statistics</em>.</p>
<p>[3] A. Lo, <a href="https://www.jstor.org/stable/2241087" target="_blank" rel="noopener">A Large Sample Study of the Bayesian Bootstrap</a> (1987), <em>The Annals of Statistics</em>.</p>
<p>[4] J. Shao, D. Tu, <a href="https://link.springer.com/book/10.1007/978-1-4612-0795-5" target="_blank" rel="noopener">Jacknife and Bootstrap</a> (1995), <em>Springer</em>.</p>
<h3 id="code">Code</h3>
<p>You can find the original Jupyter Notebook here:</p>
<p><a href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/bayes_boot.ipynb" target="_blank" rel="noopener">https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/bayes_boot.ipynb</a></p>

          </div>
          


















  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://matteocourthoud.github.io/"><img class="avatar mr-3 avatar-circle" src="/author/avatar_hu365eedc833ccd5578a90de7c849ec45e_385094_270x270_fill_q75_lanczos_center.jpg" alt=""></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://matteocourthoud.github.io/"></a></h5>
      
      <p class="card-text">I hold a PhD in economics from the University of Zurich. Now I work at the intersection of economics, data science and statistics. I regularly write about causal inference on <a href="https://medium.com/@matteo.courthoud" target="_blank" rel="noopener">Medium</a>.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://medium.com/@matteo.courthoud" target="_blank" rel="noopener">
        <i class="fab fa-medium"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/matteo-courthoud-7335198a/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/MatteoCourthoud/" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/matteocourthoud" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://open.spotify.com/user/1180947523" target="_blank" rel="noopener">
        <i class="fab fa-spotify"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>
















  
  




        </div>
        </article>
    </main>
  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  

  
  







</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/julia.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.4ea9cc8d09c5c158656ac1a804743b34.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
