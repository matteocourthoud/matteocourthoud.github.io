<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="Standard Setting When we design an A/B test or, more generally, an experiment, the standard steps are the following
  Define a null hypothesis $H_0$
 usually the null is a zero effect of the experiment on a metric of interest    Define a significance level $\alpha$" />

  
  <link rel="alternate" hreflang="en-us" href="https://matteocourthoud.github.io/post/optimal_stopping/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#003f5c" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.54afc4f4589fb91aec4b1cdd90ab2e05.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-144780600-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-144780600-1', { 'anonymize_ip': true });
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://matteocourthoud.github.io/post/optimal_stopping/" />

  
  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Matteo Courthoud" />
  <meta property="og:url" content="https://matteocourthoud.github.io/post/optimal_stopping/" />
  <meta property="og:title" content="Optimal Test Stopping | Matteo Courthoud" />
  <meta property="og:description" content="Standard Setting When we design an A/B test or, more generally, an experiment, the standard steps are the following
  Define a null hypothesis $H_0$
 usually the null is a zero effect of the experiment on a metric of interest    Define a significance level $\alpha$" /><meta property="og:image" content="https://matteocourthoud.github.io/post/optimal_stopping/featured.png" />
    <meta property="twitter:image" content="https://matteocourthoud.github.io/post/optimal_stopping/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-04-15T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-04-15T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://matteocourthoud.github.io/post/optimal_stopping/"
  },
  "headline": "Optimal Test Stopping",
  
  "image": [
    "https://matteocourthoud.github.io/post/optimal_stopping/featured.png"
  ],
  
  "datePublished": "2022-04-15T00:00:00Z",
  "dateModified": "2022-04-15T00:00:00Z",
  
  "publisher": {
    "@type": "Organization",
    "name": "Matteo Courthoud",
    "logo": {
      "@type": "ImageObject",
      "url": "https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Standard Setting When we design an A/B test or, more generally, an experiment, the standard steps are the following\n  Define a null hypothesis $H_0$\n usually the null is a zero effect of the experiment on a metric of interest    Define a significance level $\\alpha$"
}
</script>

  

  

  
  
  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js" integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css" integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#003f5c",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#003f5c"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "/privacy/"
      }
    })});
  </script>


  





  <title>Optimal Test Stopping | Matteo Courthoud</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="0b40b79a667a0362644e1579efb424d3" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.6edaf3b475ce43de30d98828aea698be.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Courses</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/course/ml-econ/"><span>Machine Learning for Economics</span></a>
            
              <a class="dropdown-item" href="/course/data-science/"><span>Data Science with Python</span></a>
            
              <a class="dropdown-item" href="/course/empirical-io/"><span>PhD Industrial Organization</span></a>
            
              <a class="dropdown-item" href="/course/metrics/"><span>PhD Econometrics</span></a>
            
              <a class="dropdown-item" href="https://pp4rs.github.io/"><span>Programming Practices for Research</span></a>
            
          </div>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link  active" href="/post/"><span>Posts</span></a>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/cv"><span>CV</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      

      
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <div class="container-fluid docs">
  <div class="row">

    <div class="col-xl-2 col-lg-2 d-none d-xl-block d-lg-block empty">
    </div>

    <div class="col-2 col-xl-2 col-lg-2 d-none d-lg-block docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#standard-setting">Standard Setting</a></li>
    <li><a href="#peaking">Peaking</a></li>
    <li><a href="#likelihood-ratio-test">Likelihood Ratio Test</a>
      <ul>
        <li><a href="#special-case-testing-mean-of-normal-distribution">Special Case: testing mean of normal distribution</a></li>
      </ul>
    </li>
    <li><a href="#sequential-probability-ratio-test">Sequential Probability Ratio Test</a>
      <ul>
        <li><a href="#special-case-testing-null-effect">Special Case: testing null effect</a></li>
        <li><a href="#simulation">Simulation</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
    </div>

    <main class="col-xl-8 col-lg-8 docs-content" role="main">
        <article class="article">
        




















  


<div class="article-container pt-3">
  <h1>Optimal Test Stopping</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Apr 15, 2022
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  
  
  
  

  
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 1218px; max-height: 817px;">
  <div style="position: relative">
    <img src="/post/optimal_stopping/featured.png" alt="" class="featured-image">
    
  </div>
</div>


        <div class="article-container">
          <div class="article-style" align="justify">
            <h2 id="standard-setting">Standard Setting</h2>
<p>When we design an A/B test or, more generally, an experiment, the standard steps are the following</p>
<ol>
<li>
<p>Define a <strong>null hypothesis</strong> $H_0$</p>
<ul>
<li>usually the null is a zero effect of the experiment on a metric of interest</li>
</ul>
</li>
<li>
<p>Define a <strong>significance level</strong> $\alpha$</p>
<ul>
<li>usually equal to 0.05, it represents the maximum probability of rejecting the null hypothesis when it is true</li>
</ul>
</li>
<li>
<p>Define an <strong>alternative hypothesis</strong> $H_1$</p>
<ul>
<li>usually the minimum effect that we would like to detect</li>
</ul>
</li>
<li>
<p>Define a <strong>power level</strong> $\beta$</p>
<ul>
<li>usually equal to 0.8, it represents the minimum probability of rejecting the null hypothesis, when the alternative is true</li>
</ul>
</li>
<li>
<p>Pick a <strong>test statistic</strong> whose distribution is known under both hypotheses</p>
<ul>
<li>usually the sample average of a metric of interest</li>
</ul>
</li>
<li>
<p>Compute the minimum <strong>sample size</strong></p>
<ul>
<li>in order to achieve the desired power level, given all the test parameters</li>
</ul>
</li>
</ol>
<p>Then, we <strong>run the test</strong> and, depending on the realized value of the test statistic, we decide whether to <strong>reject</strong> the null hypothesis or not, depending on whether the p-value is lower than the significance level.</p>
<p>Rejecting the null hypothesis does not imply accepting the alternative hypothesis.</p>
<h2 id="peaking">Peaking</h2>
<p>Suppose that half-way through the experiment we were to <strong>peak at the data</strong>, and notice that the p-value is lower than the significant level. Should we stop the experiment? If we do, what happens?</p>
<p>The answer is that the test would not achieve the desired significance level or, in other terms, our confidence intervals would have the <strong>wrong coverage</strong>.</p>
<p>Let&rsquo;s see what I mean with a <strong>example</strong>. Suppose our <strong>data generating process</strong> is a standard normal distribution with zero mean and unit variance $X \sim N(0,1)$.</p>
<p>Suppose that the variance is known while the mean is not. The <strong>hypothesis</strong> that we wish to test is</p>
<p>$$
\begin{align}
H_0: \quad &amp; \mu = 0 ,
\newline
H_1: \quad &amp; \mu = 0.1
\end{align}
$$</p>
<p>After each observation $n$, we compute the <strong>test statistic</strong></p>
<p>$$
t = \sqrt{n} \frac{\bar X - \mu}{\sigma}
$$</p>
<p>where $\bar X$ is the sample mean from a sample $X_1, X_2, &hellip;, X_n$, of size $n$, $\sigma$ is the standard deviation of the population, and $\mu$ is the population mean. Under the null hypothesis of zero mean, the test statistic is distributed as a standard normal.</p>
<pre><code class="language-python">%matplotlib inline
%config InlineBackend.figure_format = 'retina'
</code></pre>
<pre><code class="language-python">from src.utils import *
</code></pre>
<pre><code class="language-python">tstat = lambda x: np.mean(x) * np.sqrt(len(x))
</code></pre>
<p>Suppose we want a test with significance level $\alpha=0.05$ and power $\beta=0.8$. What sample size do we need?</p>
<p>$$
N : \quad 0 + z_{0.95} * \frac{\sigma}{\sqrt{N}} = 0.1 - z_{0.8} * \frac{\sigma}{\sqrt{N}}
$$</p>
<p>so that</p>
<p>$$
N = \left( \frac{z_{0.95} + z_{0.8}}{0.1 * \sigma} \right)^2
$$</p>
<p>where $z_{p}$ is the CDF inverse (or percent point function) at $p$.</p>
<pre><code class="language-python">from scipy.stats import norm

N = ( (norm.ppf(0.95) + norm.ppf(0.8)) / 0.1 )**2
print(f&quot;Sample size: {N}&quot;)
</code></pre>
<pre><code>Sample size: 618.2557232019765
</code></pre>
<p>We need at least $N=619$ observations.</p>
<pre><code class="language-python">def experiment(f_stat, mu=0, N=619, seed=1):
    np.random.seed(seed)
    n = np.arange(1, N+1)
    x = np.random.normal(mu, 1, N)
    stat = [f_stat(x[:i]) for i in n]
    df = pd.DataFrame({'n': n, 'x': x, 'stat': stat})
    return df
</code></pre>
<p>Let&rsquo;s have a look at what a sample looks like.</p>
<pre><code class="language-python">df = experiment(tstat)
df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>x</th>
      <th>stat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1.624345</td>
      <td>1.624345</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>-0.611756</td>
      <td>0.716009</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>-0.528172</td>
      <td>0.279678</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>-1.072969</td>
      <td>-0.294276</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0.865408</td>
      <td>0.123814</td>
    </tr>
  </tbody>
</table>
</div>
<p>We can now plot the time trend of the test statistic over the sampling process. I also mark the likes at $-1.96$ and $1.96$ for statistical significance.</p>
<pre><code class="language-python">def plot_experiment(df, ybounds, **kwargs):
    sns.lineplot(data=df, x='n', y='stat', **kwargs)
    for ybound in ybounds:
        sns.lineplot(x=df['n'], y=ybound, lw=1, color='black')
    plt.title('T-statistic with sequential sampling')
</code></pre>
<pre><code class="language-python">plot_experiment(df, ybounds=[-1.96, 1.96])
</code></pre>
<p><img src="img/optimal_stopping_16_0.png" alt="png"></p>
<p>In this case, the test never achieves statistical significance. Therefore, peaking does not have an effect. We would not have stopped the experiment prematurely.</p>
<p>What would happen if we were repeating the experiment many times? Let&rsquo;s simulate this procedure $K=100$ times.</p>
<pre><code class="language-python">def simulate_experiments(f_stat, ybounds, early_stop=False, mu=0, K=100, **kwargs):
    stops = np.zeros(K)
    for k in range(K):
        # Draw data
        df = experiment(f_stat, mu=mu, seed=k)
        vals = df['stat'].values[100:]
        
        # If early stop, plot violations
        if early_stop:
            violations = (vals &gt; max(ybounds)) + (vals &lt; min(ybounds))
        if early_stop and any(violations):
            end = 101+np.where(violations)[0][0]
            plot_experiment(df.iloc[100:end, :], ybounds, **kwargs)
            stops[k] = end * np.sign(df['stat'].values[end])
        
        # Otherwise, check last value
        elif (vals[-1] &gt; max(ybounds)) or (vals[-1] &lt; min(ybounds)):
            plot_experiment(df.iloc[100:, :], ybounds, **kwargs)
            stops[k] = len(df) * np.sign(vals[-1])
        
        # Plot all other observations
        else: 
            plot_experiment(df[df['n']&gt;100], ybounds, color='grey', alpha=0.1, lw=1)
    plt.title(f&quot;{sum(stops!=0)} significant results ({sum(stops&gt;0)/sum(stops!=0)*100:.4}% up)&quot;);
    return stops
</code></pre>
<pre><code class="language-python">simulate_experiments(tstat, ybounds=[-1.96, 1.96], early_stop=False);
</code></pre>
<p><img src="img/optimal_stopping_19_0.png" alt="png"></p>
<p>In the figure above, I have highlighted the experiments that would be statistically significant <strong>without peaking</strong>, i.e. given the value of the test statistic <strong>at the end of the sampling</strong> process. Only 3 simulations are statistically significant. This means a coverage of 97% which is very close to the expected coverage of 95%.</p>
<p>What if instead we were stopping any time we were seeing a significant result?</p>
<pre><code class="language-python">simulate_experiments(tstat, ybounds=[-1.96, 1.96], early_stop=True, lw=1);
</code></pre>
<p><img src="img/optimal_stopping_21_0.png" alt="png"></p>
<p>In the figure above, I have highlighted the experiments that would be statistically significant <strong>with constant peaking</strong> from the 100th observation onwards. 25 simulations are statistically significant. This means a coverage of 75% which is very far from the expected coverage of 95%. Peaking distorts coverage of the confidence interval.</p>
<p>Potential solutions are:</p>
<ol>
<li><strong>sequential probability ratio tests</strong></li>
<li><strong>sequential triangular testing</strong></li>
<li><strong>group sequential testing</strong></li>
</ol>
<p>Before analyzing these sequential testing procedures, we first need to introduce the <strong>likelihood ratio test</strong>.</p>
<h2 id="likelihood-ratio-test">Likelihood Ratio Test</h2>
<p>A statistical test is fully specified when the distribution of the data is known under both the null and the alternative hypotheses. For example</p>
<p>$$
\begin{align}
H_0: \quad &amp; \theta=\theta_0 ,
\newline
H_1: \quad &amp; \theta=\theta_1 .
\end{align}
$$</p>
<p>If instead the alternative was more generally $H_1: \ \theta \neq \theta_0$, as common in hypothesis testing, we wouldn&rsquo;t know the distribution of the data under the alternative hypothesis.</p>
<p>When a statistical test is fully specified, we can compute the likelihood ratio as the the ratio of the likelihood function under the two hypotheses.</p>
<p>$$
\Lambda (X) = \frac{\mathcal L (\theta_0 \ | \ X)}{\mathcal L (\theta_1 \ | \ X)}
$$</p>
<p>The likelihood-ratio test provides a decision rule as follows:</p>
<ul>
<li>If $\Lambda &gt;c$, do not reject $H_{0}$;</li>
<li>If $\Lambda &lt;c$, reject $H_{0}$;</li>
<li>If $\Lambda =c$, reject with probability $q$</li>
</ul>
<p>The values $c$ and $q$ are usually chosen to obtain a specified significance level $\alpha$.</p>
<p>The <strong>Neyman–Pearson lemma</strong> states that this likelihood-ratio test is the most powerful among all level $\alpha$ tests for this case.</p>
<h3 id="special-case-testing-mean-of-normal-distribution">Special Case: testing mean of normal distribution</h3>
<p>Let&rsquo;s go back to our example where data is coming from a normal distribution with unknown mean $\mu$ and known variance $\sigma^2$ and we want to perform the following test</p>
<p>$$
\begin{align}
H_0: \quad &amp; \mu = 0 ,
\newline
H_1: \quad &amp; \mu = 0.1
\end{align}
$$</p>
<p>The likelihood of the normal distribution with unknown mean $\mu$ and known variance $\sigma^2$ is</p>
<p>$$
\mathcal L(\mu) = \left( \frac{1}{\sqrt{2 \pi} \sigma } \right)^n e^{- \sum_{i=1}^{n} \frac{(X_i - \mu)^2}{2 \sigma^2}}
$$</p>
<p>So that the likelihood ratio under the two hypotheses is</p>
<p>$$
\Lambda = \frac{\mathcal L (0, \sigma^2)}{\mathcal L (0.1, \sigma^2)} = \frac{e^{- \sum_{i=1}^{n} \frac{(X_i)^2}{2 \sigma^2}}}{e^{- \sum_{i=1}^{n} \frac{(X_i - 0.1)^2}{2 \sigma^2}}}
$$</p>
<h2 id="sequential-probability-ratio-test">Sequential Probability Ratio Test</h2>
<p>Given a pair of fully specified hypotheses, say $H_{0}$ and $H_{1}$, the <strong>first step</strong> of the sequential probability ratio test is to calculate the log likelihood ratio test $\log \Lambda_{i}$, as new data arrive: with $S_{0}=0$, then, for $i=1,2,&hellip;,$</p>
<p>$$
S_{n} = S_{n-1} + \log \Lambda_{n}
$$</p>
<p>The stopping rule is a simple thresholding scheme:</p>
<ul>
<li>$a&lt;S_{i}&lt;b$: continue monitoring (critical inequality)</li>
<li>$S_{i}\geq b$: Accept $H_{1}$</li>
<li>$S_{i}\leq a$: Accept $H_{0}$</li>
</ul>
<p>where $a$ and $b$ ($a&lt;0&lt;b&lt;\infty$) depend on the desired type I and type II errors, $\alpha$  and $\beta$. They may be chosen as follows:</p>
<p>$$
A \approx \log {\frac  {\beta }{1-\alpha }} \quad \text{and} \quad  B \approx \log {\frac  {1-\beta }{\alpha }}
$$</p>
<p>The equations are approximations because of the discrete nature of the data generating process.</p>
<h3 id="special-case-testing-null-effect">Special Case: testing null effect</h3>
<p>Let&rsquo;s go back to our example where data is coming from a normal distribution with unknown mean $\mu$ and known variance $\sigma^2$ and hypotheses $H_0: \ \mu = 0$ and $H_1: \ \mu = 0.1$.</p>
<p>We have seen that the likelihood ratio with a sample of size $n$ is</p>
<p>$$
\Lambda = \frac{\mathcal L (0, \sigma^2)}{\mathcal L (0.1, \sigma^2)} = \frac{e^{- \sum_{i=1}^{n} \frac{(X_i)^2}{2 \sigma^2}}}{e^{- \sum_{i=1}^{n} \frac{(X_i - 0.1)^2}{2 \sigma^2}}}
$$</p>
<p>Therefore, the log-likelihood is</p>
<p>$$
\log (\Lambda) = \left( \sum_{i=1}^{n} \frac{(X_i - 0.1)^2}{2 \sigma^2} \right) - \left( \sum_{i=1}^{n} \frac{(X_i)^2}{2 \sigma^2} \right)
$$</p>
<h3 id="simulation">Simulation</h3>
<p>We are now ready to perform some simulations. First, let&rsquo;s code the <strong>log likelihood ratio test statistic</strong>.</p>
<pre><code class="language-python">log_lr = lambda x: (np.sum((x)**2) - np.sum((x - 0.1)**2) ) / 2
</code></pre>
<p>We now repeat the same experiment we did at the beginning, with one difference: we will compute the log likelihood ratio as a statistic. The data generating process has $\mu=0$, as under the null hypothesis.</p>
<pre><code class="language-python">df = experiment(log_lr)
df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>x</th>
      <th>stat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1.624345</td>
      <td>0.157435</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>-0.611756</td>
      <td>0.091259</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>-0.528172</td>
      <td>0.033442</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>-1.072969</td>
      <td>-0.078855</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0.865408</td>
      <td>0.002686</td>
    </tr>
  </tbody>
</table>
</div>
<p>Let&rsquo;s now compute the optimal bounds, given significance level $\alpha=0.05$ and power $\beta=0.8$.</p>
<pre><code class="language-python">A = np.log(0.8 / 0.05)
B = np.log(0.95 / 0.2)
print(f'Optimal bounds : [{A}, {B}]')
</code></pre>
<pre><code>Optimal bounds : [2.772588722239781, 1.5581446180465497]
</code></pre>
<p>Since significance and (one minus) power are different, the bound for the null hypothesis is much wider than the bound for the alternative hypothesis. This means that, in case of a true effect of $\mu=0.05$, we will be more likely to accept the null hypothesis $H_0: \mu = 0$ than the alternative $H_1: \mu = 1$.</p>
<p>We can plot the distribution of the likelihood ratio over samples drawn under the null hypothesis $H_0: \mu = 0$.</p>
<pre><code class="language-python">plot_experiment(df[2:], ybounds=[A,-B])
plt.annotate('$H_1: \mu = 0.1$', xy=(0.9*N, A+0.1));
plt.annotate('$H_0: \mu = 0$', xy=(0.9*N, -B-0.2));
</code></pre>
<p><img src="img/optimal_stopping_39_0.png" alt="png"></p>
<p>In this particular case, the test is inconclusive within our sampling framework. We need to <strong>collect more data</strong> in order to come to a decision.</p>
<p>What would happen if we were to run the test $K=100$ times?</p>
<pre><code class="language-python">stops1 = simulate_experiments(log_lr, ybounds=[-B,A], early_stop=True, lw=1.5)
plt.annotate('$H_1: \mu = 0.1$', xy=(0.9*N, A+0.1));
plt.annotate('$H_0: \mu = 0$', xy=(0.9*N, -B-0.2));
</code></pre>
<p><img src="img/optimal_stopping_41_0.png" alt="png"></p>
<p>We get a decision for 91 simulations out of 100 and for 87 of them, it&rsquo;s the correct decision. Therefore, our test coverage is 96%, very close to the desired 95%.</p>
<p>However, the biggest advantage now is that the average <strong>sample size is much smaller</strong>.</p>
<pre><code class="language-python">duration = (np.sum(np.abs(stops1)) + N*(100-sum(stops1!=0))) / len(stops1)
print(f'Average experiment duration: {duration}')
</code></pre>
<pre><code>Average experiment duration: 266.1430150881779
</code></pre>
<p>To reach a conclusion in 90/100 experiments we need just 1/4 of the samples!</p>
<p>What would happen if instead the alternative hypothesis $H_1: \mu = 0.1$ was true?</p>
<pre><code class="language-python">stops2 = simulate_experiments(log_lr, ybounds=[-B,A], early_stop=True, mu=0.1, lw=1)
plt.annotate('$H_1: \mu = 0.1$', xy=(0.9*N, A+0.1));
plt.annotate('$H_0: \mu = 0$', xy=(0.9*N, -B-0.2));
</code></pre>
<p><img src="img/optimal_stopping_45_0.png" alt="png"></p>
<p>In this case, we make the correct decision only 81% of the times, as expected since the power of the test was 80%.</p>
<p>Also in this case, we have significant savings in terms of average sample size.</p>
<pre><code class="language-python">duration = (np.sum(np.abs(stops2)) + N*(100-sum(stops2!=0))) / len(stops2)
print(f'Average experiment duration: {duration:0}')
</code></pre>
<pre><code>Average experiment duration: 377.71625910443487
</code></pre>
<p>To reach a conclusion in 78/100 experiments we need just 1/3 of the samples!</p>
<h2 id="references">References</h2>
<ul>
<li><a href="http://people.missouristate.edu/songfengzheng/Teaching/MTH541/Lecture%20notes/LRT.pdf" target="_blank" rel="noopener">Lecture Notes</a> on Likelihood Ratio Tests</li>
<li><a href="https://medium.com/netflix-techblog/improving-experimentation-efficiency-at-netflix-with-meta-analysis-and-optimal-stopping-d8ec290ae5be" target="_blank" rel="noopener">Improving Experimentation Efficiency</a> by Netflix on Medium</li>
<li><a href="https://en.wikipedia.org/wiki/Likelihood-ratio_test" target="_blank" rel="noopener">Likelihood-ratio test</a> Wikipedia article</li>
<li><a href="https://en.wikipedia.org/wiki/Sequential_probability_ratio_test" target="_blank" rel="noopener">Sequential probability ratio test</a> Wikipedia article</li>
</ul>

          </div>
          








<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://matteocourthoud.github.io/post/optimal_stopping/&amp;text=Optimal%20Test%20Stopping" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://matteocourthoud.github.io/post/optimal_stopping/&amp;t=Optimal%20Test%20Stopping" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Optimal%20Test%20Stopping&amp;body=https://matteocourthoud.github.io/post/optimal_stopping/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://matteocourthoud.github.io/post/optimal_stopping/&amp;title=Optimal%20Test%20Stopping" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Optimal%20Test%20Stopping%20https://matteocourthoud.github.io/post/optimal_stopping/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://t.me/share/url?url=https://matteocourthoud.github.io/post/optimal_stopping/&amp;text=%7btext%7d" target="_blank" rel="noopener" class="share-btn-telegram">
          <i class="fab fa-telegram"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://matteocourthoud.github.io/"><img class="avatar mr-3 avatar-circle" src="/author/avatar_hu365eedc833ccd5578a90de7c849ec45e_385094_270x270_fill_q75_lanczos_center.jpg" alt=""></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://matteocourthoud.github.io/"></a></h5>
      
      <p class="card-text">My research fields are empirical Industrial Organization and Competition Policy. My research interests include the relationship between competition and innovation, big data, artificial intelligence, platform markets, peer to peer services.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://medium.com/@matteo.courthoud" target="_blank" rel="noopener">
        <i class="fab fa-medium"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/matteo-courthoud-7335198a/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/MatteoCourthoud/" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/matteocourthoud" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://open.spotify.com/user/1180947523" target="_blank" rel="noopener">
        <i class="fab fa-spotify"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>
















  
  




        </div>
        </article>
    </main>
  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  
  <p class="powered-by">
    Theme edited by Matteo Courthoud© - Want to have a similar website? <a href="https://matteocourthoud.github.io/post/website/">Guide here</a>.
  </p>
  

  
  







</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/julia.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.cf8ca859a9b74f8b1cd804621b13e5f1.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
