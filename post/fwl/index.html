<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="An introduction to the Frisch-Waugh-Lowell theorem and how to use it to gain intuition in linear regressions
The Frisch-Waugh-Lowell theorem is a simple but yet powerful theorem that allows us to reduce multivariate regressions to univariate ones." />

  
  <link rel="alternate" hreflang="en-us" href="https://matteocourthoud.github.io/post/fwl/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#003f5c" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto+Mono&family=Source+Sans+Pro:wght@200;300;400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.4f7182ca394d705ee32d9d7750e9aa1d.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-144780600-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-144780600-1', { 'anonymize_ip': true });
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/index.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://matteocourthoud.github.io/post/fwl/" />

  
  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Matteo Courthoud" />
  <meta property="og:url" content="https://matteocourthoud.github.io/post/fwl/" />
  <meta property="og:title" content="The FWL Theorem, Or How To Make All Regressions Intuitive | Matteo Courthoud" />
  <meta property="og:description" content="An introduction to the Frisch-Waugh-Lowell theorem and how to use it to gain intuition in linear regressions
The Frisch-Waugh-Lowell theorem is a simple but yet powerful theorem that allows us to reduce multivariate regressions to univariate ones." /><meta property="og:image" content="https://matteocourthoud.github.io/post/fwl/featured.png" />
    <meta property="twitter:image" content="https://matteocourthoud.github.io/post/fwl/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-05-16T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-05-16T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://matteocourthoud.github.io/post/fwl/"
  },
  "headline": "The FWL Theorem, Or How To Make All Regressions Intuitive",
  
  "image": [
    "https://matteocourthoud.github.io/post/fwl/featured.png"
  ],
  
  "datePublished": "2022-05-16T00:00:00Z",
  "dateModified": "2022-05-16T00:00:00Z",
  
  "publisher": {
    "@type": "Organization",
    "name": "Matteo Courthoud",
    "logo": {
      "@type": "ImageObject",
      "url": "https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "An introduction to the Frisch-Waugh-Lowell theorem and how to use it to gain intuition in linear regressions\nThe Frisch-Waugh-Lowell theorem is a simple but yet powerful theorem that allows us to reduce multivariate regressions to univariate ones."
}
</script>

  

  

  
  
  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js" integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css" integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#003f5c",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#003f5c"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "/privacy/"
      }
    })});
  </script>


  





  <title>The FWL Theorem, Or How To Make All Regressions Intuitive | Matteo Courthoud</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="b872a2396c23c56ce0402d4af67bebc7" >

  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.66d3e0fff6d32c4ece05adee927fbd96.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Matteo Courthoud</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Courses</span><span class="caret"></span>
          </a>
          <div class="dropdown-menu">
            
              <a class="dropdown-item" href="/course/ml-econ/"><span>Machine Learning for Economics</span></a>
            
              <a class="dropdown-item" href="/course/data-science/"><span>Data Science with Python</span></a>
            
              <a class="dropdown-item" href="/course/empirical-io/"><span>PhD Industrial Organization</span></a>
            
              <a class="dropdown-item" href="/course/metrics/"><span>PhD Econometrics</span></a>
            
              <a class="dropdown-item" href="https://pp4rs.github.io/"><span>Programming Practices for Research</span></a>
            
          </div>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/cv"><span>CV</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      

      
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <div class="container-fluid docs">
  <div class="row">

    <div class="col-xl-2 col-lg-2 d-none d-xl-block d-lg-block empty">
    </div>

    <div class="col-2 col-xl-2 col-lg-2 d-none d-lg-block docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#the-theorem">The Theorem</a>
      <ul>
        <li><a href="#interpretation">Interpretation</a></li>
      </ul>
    </li>
    <li><a href="#example">Example</a>
      <ul>
        <li><a href="#verifying-the-theorem">Verifying the Theorem</a></li>
        <li><a href="#projection">Projection</a></li>
        <li><a href="#multiple-controls">Multiple Controls</a></li>
      </ul>
    </li>
    <li><a href="#applications">Applications</a>
      <ul>
        <li><a href="#data-visualization">Data Visualization</a></li>
        <li><a href="#computational-speed">Computational Speed</a></li>
        <li><a href="#inference-and-machine-learning">Inference and Machine Learning</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
    </div>

    <main class="col-xl-8 col-lg-8 docs-content" role="main">
        <article class="article">
        




















  


<div class="article-container pt-3">
  <h1>The FWL Theorem, Or How To Make All Regressions Intuitive</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    May 16, 2022
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  
  
  
  

  
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 1152px; max-height: 642px;">
  <div style="position: relative">
    <img src="/post/fwl/featured.png" alt="" class="featured-image">
    
  </div>
</div>


        <div class="article-container">
          <div class="article-style" align="justify">
            <p><em>An introduction to the Frisch-Waugh-Lowell theorem and how to use it to gain intuition in linear regressions</em></p>
<p>The Frisch-Waugh-Lowell theorem is a <strong>simple</strong> but yet <strong>powerful</strong> theorem that allows us to reduce multivariate regressions to <strong>univariate</strong> ones. This is extremely useful when we are interested in the relationship between two variables, but we still need to control for other factors, as it is often the case in <strong>causal inference</strong>.</p>
<p>In this blog post, I am going to introduce the Frisch-Waugh-Lowell theorem and illustrate some interesting applications.</p>
<h2 id="the-theorem">The Theorem</h2>
<p>The theorem was first published by <a href="https://www.jstor.org/stable/1907330" target="_blank" rel="noopener">Ragnar Frisch and Frederick Waugh in 1933</a>. However, since its proof was lengthy and cumbersome, <a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1963.10480682" target="_blank" rel="noopener">Michael Lovell in 1963</a> provided a very simple and intuitive proof and his name was added to the theorem name.</p>
<p>The theorem states that, when estimating a model of the form</p>
<p>$$
y_i = \beta_1 x_{i,1} + \beta_2 x_{i,2} + \varepsilon_i
$$</p>
<p>then, the following estimators of $\beta_1$ are equivalent:</p>
<ul>
<li>the OLS estimator obtained by regressing $y$ on $x_1$ and $x_2$</li>
<li>the OLS estimator obtained by regressing $y$ on $\tilde x_1$
<ul>
<li>where $\tilde x_1$ is the residual from the regression of $x_1$ on $x_2$</li>
</ul>
</li>
<li>the OLS estimator obtained by regressing $\tilde y$ on $\tilde x_1$
<ul>
<li>where $\tilde y$ is the residual from the regression of $y$ on $x_2$</li>
</ul>
</li>
</ul>
<h3 id="interpretation">Interpretation</h3>
<p>What did we actually <strong>learn</strong>?</p>
<p>The <strong>Frisch-Waugh-Lowell theorem</strong> is telling us that there are multiple ways to estimate a single regression coefficient. One possibility is to run the full regression of $y$ on $x$, as usual.</p>
<p>However, we can also regress $x_1$ on $x_2$, take the residuals, and regress $y$ only those residuals. The first part of this process is sometimes referred to as <strong>partialling-out</strong> (or <em>orthogonalization</em>, or <em>residualization</em>) of $x_1$ with respect to $x_2$. The idea is that we are isolating the variation in $x_1$ that is <em>orthogonal</em> to $x_2$. Note that $x_2$ can be also be multi-dimensional (i.e. include multiple variables and not just one).</p>
<p>Why would one ever do that?</p>
<p>This seems like a way more <strong>complicated</strong> procedure. Instead of simply doing the regression in 1 step, now we need to do 2 or even 3 steps. It&rsquo;s not intuitive at all. The main advantage comes from the fact that we have reduced a multivariate regression to a univariate one, making more tractable and more intuitive.</p>
<p>We will later explore more in detail three <strong>applications</strong>:</p>
<ul>
<li>data visualization</li>
<li>computational speed</li>
<li>further applications for inference</li>
</ul>
<p>However, let&rsquo;s first explore the theorem more in detail with an example.</p>
<h2 id="example">Example</h2>
<p>Suppose we were a retail chain, owning many different stores in different locations. We come up with a brilliant <strong>idea to increase sales</strong>: give away discounts in the form of <strong>coupons</strong>. We print a lot of coupons and we distribute them around.</p>
<p>To understand whether our marketing strategy worked, in each store, we check the average daily <code>sales</code> and which percentage of shoppers used a <code>coupon</code>. However, there is one <strong>problem</strong>: we are worried that higher income people are less likely to use the discount, but usually they spend more. To be safe, we also record the average <code>income</code> in the neighborhood of each store.</p>
<p>We can represent the data generating process with a <strong>Directed Acyclic Graph</strong> (DAG). If you are not familiar with DAGs, I have written a short introduction to <a href="https://medium.com/towards-data-science/controls-b63dc69e3d8c" target="_blank" rel="noopener">Directed Acyclic Graphs here</a>.</p>
<pre><code class="language-mermaid">flowchart LR
classDef included fill:#DCDCDC,stroke:#000000,stroke-width:2px;
classDef excluded fill:#ffffff,stroke:#000000,stroke-width:2px;
classDef unobserved fill:#ffffff,stroke:#000000,stroke-width:2px,stroke-dasharray: 5 5;

X1((coupons))
X2((income))
X3((weekday))
Y((sales))


X1 --&gt; Y
X2 --&gt; X1
X2 --&gt; Y
X3 --&gt; Y

class X1,X2,X3,Y excluded;
</code></pre>
<p>Let&rsquo;s load and inspect the <strong>data</strong>. I import the data generating process from <code>src.dgp</code> and some plotting functions and libraries from <code>src.utils</code>.</p>
<pre><code class="language-python">%matplotlib inline
%config InlineBackend.figure_format = 'retina'
</code></pre>
<pre><code class="language-python">from src.utils import *
from src.dgp import dgp_store_coupons

df = dgp_store_coupons().generate_data(N=50)
df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sales</th>
      <th>coupons</th>
      <th>income</th>
      <th>dayofweek</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>821.7</td>
      <td>0.199</td>
      <td>66.243</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>602.3</td>
      <td>0.245</td>
      <td>43.882</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>655.1</td>
      <td>0.162</td>
      <td>44.718</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>625.8</td>
      <td>0.269</td>
      <td>39.270</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>696.6</td>
      <td>0.186</td>
      <td>58.654</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
<p>We have information on <strong>50 stores</strong>, for which we observe the percentage of customers that use <code>coupons</code>, daily <code>sales</code> (in thousand $), average <code>income</code> of the neighborhood (in thousand $), and <code>day of the week</code>.</p>
<p>Suppose we were directly regressing <code>sales</code> on <code>coupon</code> usage. What would we get? I represent the <strong>result</strong> of the regression graphically, using <code>seaborn</code> <code>regplot</code>.</p>
<pre><code class="language-python">sns.regplot(x=&quot;coupons&quot;, y=&quot;sales&quot;, data=df, ci=False, line_kws={'color':'r', 'label':'linear fit'})
plt.legend()
plt.title(f&quot;Sales and coupon usage&quot;);
</code></pre>
<p><img src="img/fwl_12_0.png" alt="png"></p>
<p>It looks like coupons were a <strong>bad idea</strong>: in stores where coupons are used more, we observe lower sales.</p>
<p>However, it might just be that people with higher income are using less coupons, while also spending more. If this was true, it could <strong>bias</strong> our results. In terms of the DAG, it means that we have a <strong>backdoor path</strong> passing through <code>income</code>, generating a non-causal relationship.</p>
<pre><code class="language-mermaid">flowchart LR
classDef included fill:#DCDCDC,stroke:#000000,stroke-width:2px;
classDef excluded fill:#ffffff,stroke:#000000,stroke-width:2px;
classDef unobserved fill:#ffffff,stroke:#000000,stroke-width:2px,stroke-dasharray: 5 5;

X1((coupons))
X2((income))
X3((weekday))
Y((sales))


X1 --&gt; Y
X2 --&gt; X1
X2 --&gt; Y
X3 --&gt; Y

class X1,Y included;
class X2,X3 excluded;

linkStyle 1,2 stroke:#ff0000,stroke-width:4px;
</code></pre>
<p>In order to recover the causal effect of <code>coupons</code> on <code>sales</code> we need to <strong>condition</strong> our analysis on <code>income</code>. This will <strong>block</strong> the non-causal path passing through <code>income</code>, leaving only the direct path from <code>coupons</code> to <code>sales</code> open, allowing us to estimate the causal effect.</p>
<pre><code class="language-mermaid">flowchart LR
classDef included fill:#DCDCDC,stroke:#000000,stroke-width:2px;
classDef excluded fill:#ffffff,stroke:#000000,stroke-width:2px;
classDef unobserved fill:#ffffff,stroke:#000000,stroke-width:2px,stroke-dasharray: 5 5;


X1((coupons))
X2((income))
X3((weekday))
Y((sales))


X1 --&gt; Y
X2 -.-&gt; X1
X2 -.-&gt; Y
X3 --&gt; Y

class X1,X2,Y included;
class X3 excluded;

linkStyle 0 stroke:#00ff00,stroke-width:4px;
</code></pre>
<p>Let&rsquo;s implement this, by including <code>income</code> in the regression.</p>
<pre><code class="language-python">smf.ols('sales ~ coupons + income', df).fit().summary().tables[1]
</code></pre>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>  161.4982</td> <td>   33.253</td> <td>    4.857</td> <td> 0.000</td> <td>   94.601</td> <td>  228.395</td>
</tr>
<tr>
  <th>coupons</th>   <td>  218.7548</td> <td>   50.058</td> <td>    4.370</td> <td> 0.000</td> <td>  118.052</td> <td>  319.458</td>
</tr>
<tr>
  <th>income</th>    <td>    9.5094</td> <td>    0.480</td> <td>   19.818</td> <td> 0.000</td> <td>    8.544</td> <td>   10.475</td>
</tr>
</table>
<p>Now the estimated effect of <code>coupons</code> on <code>sales</code> is positive and significant. Coupons were actually a <strong>good idea</strong> after all.</p>
<h3 id="verifying-the-theorem">Verifying the Theorem</h3>
<p>Let&rsquo;s now verify that the Frisch-Waugh-Lowell theorem actually holds. In particular, we want to check whether we get the <strong>same coefficient</strong> if, instead of regressing <code>sales</code> on <code>coupons</code> and <code>income</code>, we were</p>
<ul>
<li>regressing <code>coupons</code> on <code>income</code></li>
<li>computing the residuals <code>coupons_tilde</code>, i.e. the variation in <code>coupons</code> <strong>not</strong> explained by <code>income</code></li>
<li>regressing <code>sales</code> on <code>coupons_tilde</code></li>
</ul>
<pre><code class="language-python">df['coupons_tilde'] = smf.ols('coupons ~ income', df).fit().resid

smf.ols('sales ~ coupons_tilde - 1', df).fit().summary().tables[1]
</code></pre>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>coupons_tilde</th> <td>  218.7548</td> <td> 1275.236</td> <td>    0.172</td> <td> 0.865</td> <td>-2343.929</td> <td> 2781.438</td>
</tr>
</table>
<p>Yes, the coefficient is the same! However, the <strong>standard errors</strong> now have increased a lot and the estimated coefficient is not significantly different from zero anymore.</p>
<p>A better approach is to add a further step and repeat the same procedure also for <code>sales</code>:</p>
<ul>
<li>regressing <code>sales</code> on <code>income</code></li>
<li>computing the residuals <code>sales_tilde</code>, i.e. the variation in <code>sales</code> <strong>not</strong> explained by <code>income</code></li>
</ul>
<p>and finally regress <code>sales_tilde</code> on <code>coupons_tilde</code>.</p>
<pre><code class="language-python">df['sales_tilde'] = smf.ols('sales ~ income', df).fit().resid

smf.ols('sales_tilde ~ coupons_tilde - 1', df).fit().summary().tables[1]
</code></pre>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>coupons_tilde</th> <td>  218.7548</td> <td>   49.025</td> <td>    4.462</td> <td> 0.000</td> <td>  120.235</td> <td>  317.275</td>
</tr>
</table>
<p>The coefficient is still exactly the same, but now also the standard errors are almost identical.</p>
<h3 id="projection">Projection</h3>
<p>What is <strong>partialling-out</strong> (or residualization, or orthogonalization) actually doing? What is happening when we take the residuals of <code>coupons</code> with respect to <code>income</code>?</p>
<p>We can <strong>visualize</strong> the procedure in a plot. First, let&rsquo;s actually display the <strong>residuals</strong> of <code>coupons</code> with respect to income.</p>
<pre><code class="language-python">df[&quot;coupons_hat&quot;] = smf.ols('coupons ~ income', df).fit().predict()
ax = sns.regplot(x=&quot;income&quot;, y=&quot;coupons&quot;, data=df, ci=False, line_kws={'color':'r', 'label':'linear fit'})
ax.vlines(df[&quot;income&quot;], np.minimum(df[&quot;coupons&quot;], df[&quot;coupons_hat&quot;]), np.maximum(df[&quot;coupons&quot;], df[&quot;coupons_hat&quot;]), 
           linestyle='--', color='k', alpha=0.5, linewidth=1, label=&quot;residuals&quot;);
plt.legend()
plt.title(f&quot;Coupons usage, income and residuals&quot;);
</code></pre>
<p><img src="img/fwl_24_0.png" alt="png"></p>
<p>The <strong>residuals</strong> are the vertical dotted lines between the data and the linear fit, i.e. the part of the variation in <code>coupons</code> unexplained by <code>income</code>.</p>
<p>By <strong>partialling-out</strong>, we are removing the linear fit from the data and keeping only the residuals. We can visualize this procedure with a gif. I import the code from the <code>src.figures</code> file that you can find <a href="https://github.com/matteocourthoud/Blog-Posts/blob/main/src/figures.py" target="_blank" rel="noopener">here</a>.</p>
<pre><code class="language-python">from src.figures import gif_projection

gif_projection(x='income', y='coupons', df=df, gifname=&quot;gifs/fwl.gif&quot;)
</code></pre>
<p><img src="gifs/fwl.gif" alt="fwl"></p>
<p>The original distribution of the data is on the left in <em>blue</em>, the partialled-out data in on the right in <em>green</em>. As we can see, partialling-out removes both the level and the trend in <code>coupons</code> that is explained by <code>income</code>.</p>
<h3 id="multiple-controls">Multiple Controls</h3>
<p>We can use the Frisch-Waugh-Theorem also when we have <strong>multiple control variables</strong>. Suppose that we wanted to also include <code>day of the week</code> in the regression, to increase precision.</p>
<pre><code class="language-python">smf.ols('sales ~ coupons + income + dayofweek', df).fit().summary().tables[1]
</code></pre>
<table class="simpletable">
<tr>
         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>      <td>  124.2721</td> <td>   28.764</td> <td>    4.320</td> <td> 0.000</td> <td>   66.182</td> <td>  182.362</td>
</tr>
<tr>
  <th>dayofweek[T.2]</th> <td>    7.7703</td> <td>   14.607</td> <td>    0.532</td> <td> 0.598</td> <td>  -21.729</td> <td>   37.270</td>
</tr>
<tr>
  <th>dayofweek[T.3]</th> <td>   15.0895</td> <td>   11.678</td> <td>    1.292</td> <td> 0.204</td> <td>   -8.495</td> <td>   38.674</td>
</tr>
<tr>
  <th>dayofweek[T.4]</th> <td>   28.2762</td> <td>    9.868</td> <td>    2.866</td> <td> 0.007</td> <td>    8.348</td> <td>   48.204</td>
</tr>
<tr>
  <th>dayofweek[T.5]</th> <td>   44.0937</td> <td>   10.214</td> <td>    4.317</td> <td> 0.000</td> <td>   23.467</td> <td>   64.720</td>
</tr>
<tr>
  <th>dayofweek[T.6]</th> <td>   50.7664</td> <td>   13.130</td> <td>    3.866</td> <td> 0.000</td> <td>   24.249</td> <td>   77.283</td>
</tr>
<tr>
  <th>dayofweek[T.7]</th> <td>   57.3142</td> <td>   12.413</td> <td>    4.617</td> <td> 0.000</td> <td>   32.245</td> <td>   82.383</td>
</tr>
<tr>
  <th>coupons</th>        <td>  192.0262</td> <td>   39.140</td> <td>    4.906</td> <td> 0.000</td> <td>  112.981</td> <td>  271.071</td>
</tr>
<tr>
  <th>income</th>         <td>    9.8152</td> <td>    0.404</td> <td>   24.314</td> <td> 0.000</td> <td>    9.000</td> <td>   10.630</td>
</tr>
</table>
<p>We can perform the same procedure as before, but instead of <strong>partialling-out</strong> only <code>income</code>, now we partial out both <code>income</code> and <code>day of the week</code>.</p>
<pre><code class="language-python">df['coupons_tilde'] = smf.ols('coupons ~ income + dayofweek', df).fit().resid
df['sales_tilde'] = smf.ols('sales ~ income + dayofweek', df).fit().resid
smf.ols('sales_tilde ~ coupons_tilde - 1', df).fit().summary().tables[1]
</code></pre>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>coupons_tilde</th> <td>  192.0262</td> <td>   35.803</td> <td>    5.363</td> <td> 0.000</td> <td>  120.078</td> <td>  263.974</td>
</tr>
</table>
<p>We still get exactly the same coefficient!</p>
<h2 id="applications">Applications</h2>
<p>Let&rsquo;s now inspect some useful applications of the FWL theorem.</p>
<h3 id="data-visualization">Data Visualization</h3>
<p>One of the advantages of the Frisch-Waugh-Theorem is that it allows us to estimate the coefficient of interest from a <strong>univariate</strong> regression, i.e. with a single explanatory variable (or feature).</p>
<p>Therefore, we can now represent the relationship of interest <strong>graphically</strong>. Let&rsquo;s plot the residual <code>sales</code> against the residual <code>coupons</code>.</p>
<pre><code class="language-python">sns.regplot(x=&quot;coupons_tilde&quot;, y=&quot;sales_tilde&quot;, data=df, ci=False, line_kws={'color':'r', 'label':'linear fit'})
plt.legend()
plt.title(f&quot;Residual sales and residual coupons&quot;);
</code></pre>
<p><img src="img/fwl_39_0.png" alt="png"></p>
<p>Now it&rsquo;s evident from the graph that the <strong>conditional relationship</strong> between <code>sales</code> and <code>coupons</code> is positive.</p>
<p>One problem with this approach is that the variables are <strong>hard to interpret</strong>: we now have negative values for both <code>sales</code> and <code>coupons</code>. Weird.</p>
<p>Why did it happen? It happened because when we partialled-out the variables, we included the <strong>intercept</strong> in the regression, effectively de-meaning the variables (i.e. normalizing their values so that their mean is zero).</p>
<p>We can <strong>solve</strong> this problem by <strong>scaling</strong> both variables, adding their mean.</p>
<pre><code class="language-python">df['coupons_tilde_scaled'] = df['coupons_tilde'] + np.mean(df['coupons'])
df['sales_tilde_scaled'] = df['sales_tilde'] + np.mean(df['sales'])
</code></pre>
<p>Now the magnitudes of the two variables are interpretable again.</p>
<pre><code class="language-python">sns.regplot(x=&quot;coupons_tilde_scaled&quot;, y=&quot;sales_tilde_scaled&quot;, data=df, ci=False, line_kws={'color':'r', 'label':'linear fit'})
plt.legend()
plt.title(f&quot;Residual sales scaled and residual coupons scaled&quot;);
</code></pre>
<p><img src="img/fwl_43_0.png" alt="png"></p>
<p>Is this a <strong>valid</strong> approach or did it alter our estimates? We can can check it by running the regression with the scaled partialled-out variables.</p>
<pre><code class="language-python">smf.ols('sales_tilde_scaled ~ coupons_tilde_scaled', df).fit().summary().tables[1]
</code></pre>
<table class="simpletable">
<tr>
            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>            <td>  641.6486</td> <td>   10.017</td> <td>   64.054</td> <td> 0.000</td> <td>  621.507</td> <td>  661.790</td>
</tr>
<tr>
  <th>coupons_tilde_scaled</th> <td>  192.0262</td> <td>   36.174</td> <td>    5.308</td> <td> 0.000</td> <td>  119.294</td> <td>  264.758</td>
</tr>
</table>
<p>The coefficient is exactly the same as before!</p>
<h3 id="computational-speed">Computational Speed</h3>
<p>Another application of the Frisch-Waugh-Lovell theorem is to increase the computational speed of linear estimators. For example it is used to compute efficient linear estimators in presence of high-dimensional fixed effects (<code>day of the week</code> in our example).</p>
<p>Some packages that exploit the Frisch-Waugh-Lovell theorem include</p>
<ul>
<li><a href="http://scorreia.com/software/reghdfe/" target="_blank" rel="noopener">reghdfe in Stata</a></li>
<li><a href="https://pyhdfe.readthedocs.io/en/stable/index.html" target="_blank" rel="noopener">pyhdfe in Python</a></li>
</ul>
<p>However, it&rsquo;s important to also mention the <a href="https://cran.r-project.org/web/packages/fixest/index.html" target="_blank" rel="noopener">fixest</a> package in R, which is also exceptionally efficient in running regressions with high dimensional fixed effects.</p>
<h3 id="inference-and-machine-learning">Inference and Machine Learning</h3>
<p>Another important application of the FWL theorem sits at the intersection of <strong>machine learning</strong> and <strong>causal inference</strong>. I am referring to the work on post-double selection by <a href="https://academic.oup.com/restud/article-abstract/81/2/608/1523757" target="_blank" rel="noopener">Belloni, Chernozhukov, Hansen (2013)</a> and the follow up work on &ldquo;double machine learning&rdquo; by <a href="https://academic.oup.com/ectj/article/21/1/C1/5056401" target="_blank" rel="noopener">Chernozhukov, Chetverikov, Demirer, Duflo, Hansen, Newey, Robins (2018)</a>.</p>
<p>I plan to cover both applications in future posts, but I wanted to start with the basics. Stay tuned!</p>
<h2 id="references">References</h2>
<p>[1] R. Frisch and F. V. Waugh, <a href="https://www.jstor.org/stable/1907330" target="_blank" rel="noopener">Partial Time Regressions as Compared with Individual Trends</a> (1933), <em>Econometrica</em>.</p>
<p>[2] M. C. Lowell, <a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1963.10480682" target="_blank" rel="noopener">Seasonal Adjustment of Economic Time Series and Multiple Regression Analysis</a> (1963), <em>Journal of the American Statistical Association</em>.</p>

          </div>
          


















  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://matteocourthoud.github.io/"><img class="avatar mr-3 avatar-circle" src="/author/avatar_hu365eedc833ccd5578a90de7c849ec45e_385094_270x270_fill_q75_lanczos_center.jpg" alt=""></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://matteocourthoud.github.io/"></a></h5>
      
      <p class="card-text">I hold a PhD in economics from the University of Zurich. Now I work at the intersection of economics, data science and statistics. I regularly write about causal inference on <a href="https://medium.com/@matteo.courthoud" target="_blank" rel="noopener">Medium</a>.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://medium.com/@matteo.courthoud" target="_blank" rel="noopener">
        <i class="fab fa-medium"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/matteo-courthoud-7335198a/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/MatteoCourthoud/" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/matteocourthoud" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://open.spotify.com/user/1180947523" target="_blank" rel="noopener">
        <i class="fab fa-spotify"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>
















  
  




        </div>
        </article>
    </main>
  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  

  
  







</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.4/mermaid.min.js" integrity="sha512-as1BF4+iHZ3BVO6LLDQ7zrbvTXM+c/1iZ1qII/c3c4L8Rn5tHLpFUtpaEtBNS92f+xGsCzsD7b62XP3XYap6oA==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/julia.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.4ea9cc8d09c5c158656ac1a804743b34.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
