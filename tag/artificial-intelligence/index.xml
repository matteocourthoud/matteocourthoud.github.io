<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Artificial Intelligence | Matteo Courthoud</title>
    <link>https://matteocourthoud.github.io/tag/artificial-intelligence/</link>
      <atom:link href="https://matteocourthoud.github.io/tag/artificial-intelligence/index.xml" rel="self" type="application/rss+xml" />
    <description>Artificial Intelligence</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Theme edited by Matteo Courthoud© - Want to have a similar website? [Guide here](https://matteocourthoud.github.io/post/website/).</copyright><lastBuildDate>Mon, 25 Oct 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://matteocourthoud.github.io/media/icon_hu03e9b3967b83fd39296ec9da5ff1ea05_201175_512x512_fill_lanczos_center_3.png</url>
      <title>Artificial Intelligence</title>
      <link>https://matteocourthoud.github.io/tag/artificial-intelligence/</link>
    </image>
    
    <item>
      <title>Algorithmic Collusion on Online Marketplaces</title>
      <link>https://matteocourthoud.github.io/project/alg_platform/</link>
      <pubDate>Mon, 25 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/project/alg_platform/</guid>
      <description>&lt;p&gt;The use of algorithms to set prices is particularly popular in online marketplaces, where sellers need to take quick decisions in complex dynamic environments. In this article, I investigate the role of online marketplaces in facilitating or preventing collusion among sellers that use pricing algorithms. In particular, I investigate a platform that has the ability to give prominence to certain products and automates this decision through a reinforcement learning algorithm, that maximizes the platform&amp;rsquo;s profits. Depending on whether the business model of the platform is more aligned with consumer welfare or with sellers&amp;rsquo; profits (e.g., if it collects quantity or profit fees), the platform either prevents or facilitates collusion among algorithmic sellers. If the platform is also active as a seller, the so-called dual role, it is able to both induce sellers to set high prices and appropriate most of the profits. Importantly, self-preferencing only happens during the learning phase and not in equilibrium. I investigate a potential solution: separating the sales and marketplace divisions. The policy is effective but does not fully restore the competitive outcome when the fee is distortive, as in the case of a revenue fee.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Algorithmic Collusion Detection</title>
      <link>https://matteocourthoud.github.io/project/alg_detection/</link>
      <pubDate>Sun, 12 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://matteocourthoud.github.io/project/alg_detection/</guid>
      <description>&lt;p&gt;Reinforcement learning algorithms are gradually replacing humans in many decision-making processes, such as pricing in high-frequency markets. Recent studies on algorithmic pricing have shown that algorithms can learn sophisticated grim-trigger strategies with the intent of keeping supra-competitive prices. This paper focuses on algorithmic collusion detection. One frequent suggestion is to look at the inputs of the strategies, for example at whether the algorithms condition their prices on previous competitors&amp;rsquo; prices. The first part of the paper shows that this approach might not be sufficient to detect collusion since the algorithms can learn reward-punishment schemes that are fully independent of the rival’s actions. The mechanism that ensures the stability of supra-competitive prices is self-punishment.&lt;/p&gt;
&lt;p&gt;The second part of the paper explores a novel test for algorithmic collusion detection. The test builds on the intuition that as algorithms are able to learn to collude, they might be able to learn to exploit collusive strategies. In fact, since they are not designed to learn sub-game perfect equilibrium strategies, there is the possibility that their strategies could be exploited. When one algorithm is unilaterally retrained, keeping the collusive strategies of its competitor fixed, it learns more profitable strategies. Usually, these strategies are more competitive, but not always. Since this change in strategies happens only when algorithms are colluding, retraining can be used as a test to detect algorithmic collusion.&lt;/p&gt;
&lt;p&gt;To make the test implementable, the last part of the paper studies whether one could get the same insights on collusive behavior using only observational data, from a single algorithm. The result is a unilateral empirical test for algorithmic collusion that does not require any assumptions neither on the algorithms themselves nor on the underlying environment. The key insight is that algorithms, during their learning phase, produce natural experiments that allow an observer to estimate their behavior in counterfactual scenarios. The simulations show that, at least in a controlled experimental setting, the test is extremely successful in detecting algorithmic collusion.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
